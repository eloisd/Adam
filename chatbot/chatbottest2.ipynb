{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2 Adam Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change documents from .pdf with images to .txt without images and explanation instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "class StorageAgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    base_path_txt: str\n",
    "    base_path_pdf: str\n",
    "    missing_txt: List[Document]\n",
    "    missing_pdf: List[str]\n",
    "    rephrased_documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def init(state: StorageAgentState):\n",
    "    print(\"Entering init\")\n",
    "    state[\"base_path_txt\"] = \"data_txt\"\n",
    "    state[\"base_path_pdf\"] = \"data_pdf\"\n",
    "    state[\"missing_txt\"] = []\n",
    "    state[\"missing_pdf\"] = []\n",
    "    state[\"rephrased_documents\"] = []\n",
    "    \n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "    return state\n",
    "\n",
    "def find_missing_txt_files(state: StorageAgentState):\n",
    "    \"\"\"\n",
    "    Identifies PDF files in pdf_dir that don't have corresponding TXT files in txt_dir.\n",
    "    \n",
    "    Args:\n",
    "        pdf_dir (str): Directory containing PDF files (default: \"data_pdf\")\n",
    "        txt_dir (str): Directory containing TXT files (default: \"data_txt\")\n",
    "    \n",
    "    Returns:\n",
    "        list: List of missing TXT filenames (without path, but with .txt extension)\n",
    "    \"\"\"\n",
    "    print(\"Entering find_missing_txt_files\")\n",
    "    pdf_dir = state[\"base_path_pdf\"]\n",
    "    txt_dir = state[\"base_path_txt\"]\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(pdf_dir, exist_ok=True)\n",
    "    os.makedirs(txt_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of PDF files\n",
    "    pdf_files = []\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            pdf_files.append(filename)\n",
    "    \n",
    "    # Get list of TXT files\n",
    "    txt_files = []\n",
    "    for filename in os.listdir(txt_dir):\n",
    "        if filename.lower().endswith('.txt'):\n",
    "            txt_files.append(filename)\n",
    "    \n",
    "    # Convert PDF filenames to expected TXT filenames\n",
    "    expected_txt_files = [os.path.splitext(pdf)[0] + '.txt' for pdf in pdf_files]\n",
    "    \n",
    "    # Find missing TXT files\n",
    "    counter = 0\n",
    "    for i, txt in enumerate(expected_txt_files):\n",
    "        if txt not in txt_files:\n",
    "            i -= counter\n",
    "            state[\"missing_txt\"].append({\"page_content\": \"\", \"metadata\": {\"path\": \"\", \"topic\": \"Deep Learning\", \"doc_type\": \"cours\", \"doc_subject\": \"\"}})\n",
    "            state[\"missing_txt\"][i][\"metadata\"][\"path\"] = os.path.join(txt_dir, txt)\n",
    "            state[\"missing_txt\"][i][\"metadata\"][\"doc_subject\"] = os.path.splitext(txt)[0]\n",
    "            state[\"missing_pdf\"].append(os.path.join(pdf_dir,os.path.splitext(txt)[0] + '.pdf'))\n",
    "        else:\n",
    "            counter += 1\n",
    "    print(f\"Found {len(pdf_files)} PDF files in '{pdf_dir}'\")\n",
    "    print(f\"Found {len(txt_files)} TXT files in '{txt_dir}'\")\n",
    "    print(f\"Missing {len(state[\"missing_txt\"])} TXT files\")\n",
    "    print(\"Missing TXT files:\", state[\"missing_txt\"])\n",
    "    print(\"PDFs needing processing:\", state[\"missing_pdf\"])\n",
    "    \n",
    "    return state\n",
    "\n",
    "def get_missing_pdf_paths(state: StorageAgentState):\n",
    "    \"\"\"\n",
    "    Returns the full paths of PDF files that don't have corresponding TXT files.\n",
    "    \n",
    "    Args:\n",
    "        pdf_dir (str): Directory containing PDF files (default: \"data_pdf\")\n",
    "        txt_dir (str): Directory containing TXT files (default: \"data_txt\")\n",
    "    \n",
    "    Returns:\n",
    "        list: List of full paths to PDF files that need processing\n",
    "    \"\"\"\n",
    "    print(\"Entering get_missing_pdf_paths\")\n",
    "    pdf_dir = state[\"base_path_pdf\"]\n",
    "\n",
    "    missing_txt_files = state[\"missing_txt\"]\n",
    "\n",
    "    # Convert missing TXT filenames back to PDF filenames\n",
    "    missing_pdf_files = [os.path.splitext(txt)[0] + '.pdf' for txt in missing_txt_files]\n",
    "\n",
    "    # Create full paths\n",
    "    state[\"missing_pdf\"] = [os.path.join(pdf_dir, pdf) for pdf in missing_pdf_files]\n",
    "    # for i, pdf in enumerate(missing_pdf_files):\n",
    "    #     state[\"missing_pdf\"].append({\"page_content\": \"\", \"metadata\": {\"path\": \"\", \"topic\": \"Deep Learning\", \"doc_type\": \"cours\", \"doc_subject\": \"\"}})\n",
    "    #     state[\"missing_pdf\"][i][\"metadata\"][\"path\"] = os.path.join(pdf_dir, pdf)\n",
    "    print(\"PDFs needing processing:\", state[\"missing_pdf\"])\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "import mimetypes\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Function to convert PDF to images and encode them\n",
    "# def pdf_to_base64_images(pdf_path):\n",
    "#     images = []\n",
    "#     pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "#     for page_number in range(len(pdf_document)):\n",
    "#         page = pdf_document.load_page(page_number)\n",
    "#         pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom for better resolution\n",
    "        \n",
    "#         # Convert to PIL Image\n",
    "#         img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        \n",
    "#         # Convert to base64\n",
    "#         buffered = io.BytesIO()\n",
    "#         img.save(buffered, format=\"PNG\")\n",
    "#         img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        \n",
    "#         images.append(img_base64)\n",
    "    \n",
    "#     return images\n",
    "\n",
    "def pdf_to_base64_images(pdf_path):  # Limit pages to avoid context limits\n",
    "    images = []\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "    for page_number in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # Higher resolution\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        \n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        img.save(buffered, format=\"PNG\", quality=85)  # JPEG for better compatibility\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        \n",
    "        images.append(img_base64)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def create_txt_content(state: StorageAgentState):\n",
    "    for i in range(len(state[\"missing_pdf\"])):\n",
    "        # Path to your PDF\n",
    "        print(f\"Processing: {state[\"missing_txt\"][i][\"metadata\"]['doc_subject']}\")\n",
    "        pdf_path = state[\"missing_pdf\"][i]\n",
    "        base64_images = pdf_to_base64_images(pdf_path)\n",
    "\n",
    "\n",
    "        # Create content list with all PDF pages as images\n",
    "        content= [\n",
    "            {\"type\": \"text\", \"text\": f\"Tu es expert en {state[\"missing_txt\"][i][\"metadata\"]['topic']}.\\n\"\n",
    "            f\"Voici un {state[\"missing_txt\"][i][\"metadata\"]['doc_type']} sur {state[\"missing_txt\"][i][\"metadata\"]['doc_subject']}.\\n\"\n",
    "            \"Il y a dans ce document des images explicatives et des formules mathématiques.\\n\"\n",
    "            \"Ton but est de faire un fichier texte qui redit exactement tout ce qui est expliqué dans ce \"\n",
    "            \"document en incluant les formules mathématiques et les explications que les images peuvent apporter.\\n\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "\n",
    "        # Add each page as an image\n",
    "        for img_base64 in base64_images:\n",
    "            content.append({\n",
    "                \"type\": \"image\",\n",
    "                \"source\": {\n",
    "                    \"type\": \"base64\",\n",
    "                    \"media_type\": \"image/png\",\n",
    "                    \"data\": img_base64\n",
    "                }\n",
    "\n",
    "                # \"type\": \"image_url\",\n",
    "                # \"image_url\": {\n",
    "                #     \"url\": f\"data:application/pdf;base64,{base64_pdf}\"\n",
    "                # }\n",
    "\n",
    "                # \"type\": \"image_url\",\n",
    "                # \"image_url\": {\n",
    "                #     \"url\": f\"data:image/jpeg;base64,{img_base64}\"\n",
    "                # }\n",
    "            })\n",
    "\n",
    "\n",
    "        # Initialize Claude through LangChain\n",
    "        llm = ChatAnthropic(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=9092,\n",
    "        )\n",
    "        # llm = ChatOpenAI(\n",
    "        #     model=\"gpt-4o-mini\",\n",
    "        # )\n",
    "        # llm = ChatGoogleGenerativeAI(\n",
    "        #     model=\"models/gemini-2.0-flash-exp\",\n",
    "        # )\n",
    "        # Create a message with the PDF pages as images\n",
    "        message = HumanMessage(content=content)\n",
    "\n",
    "        # Get response\n",
    "        response = llm.invoke([message])\n",
    "        print(response.content)\n",
    "        state[\"missing_txt\"][i][\"page_content\"] = response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_txt_files(state: StorageAgentState):\n",
    "    print(\"Entering create_txt_files\")\n",
    "    for i in range(len(state[\"missing_pdf\"])):\n",
    "        with open(state[\"missing_txt\"][i][\"metadata\"][\"path\"], \"w\") as f:\n",
    "            f.write(state[\"missing_txt\"][i][\"page_content\"])\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Workflow\n",
    "storage_workflow = StateGraph(StorageAgentState)\n",
    "storage_workflow.add_node(\"init\", init)\n",
    "storage_workflow.add_node(\"find_missing_txt_files\", find_missing_txt_files)\n",
    "storage_workflow.add_node(\"create_txt_content\", create_txt_content)\n",
    "storage_workflow.add_node(\"create_txt_files\", create_txt_files)\n",
    "\n",
    "storage_workflow.add_edge(\"init\", \"find_missing_txt_files\")\n",
    "storage_workflow.add_edge(\"find_missing_txt_files\", \"create_txt_content\")\n",
    "storage_workflow.add_edge(\"create_txt_content\", \"create_txt_files\")\n",
    "storage_workflow.add_edge(\"create_txt_files\", END)\n",
    "storage_workflow.set_entry_point(\"init\")\n",
    "storage_graph = storage_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        storage_graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering init\n",
      "Entering find_missing_txt_files\n",
      "Found 9 PDF files in 'data_pdf'\n",
      "Found 9 TXT files in 'data_txt'\n",
      "Missing 0 TXT files\n",
      "Missing TXT files: []\n",
      "PDFs needing processing: []\n",
      "Entering create_txt_files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [],\n",
       " 'base_path_txt': 'data_txt',\n",
       " 'base_path_pdf': 'data_pdf',\n",
       " 'missing_txt': [],\n",
       " 'missing_pdf': [],\n",
       " 'rephrased_documents': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_topic_content_rag = \"How is the weather?\"\n",
    "input_data = {\"question\": HumanMessage(content=off_topic_content_rag)}\n",
    "storage_graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 9}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Others tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def pdf_to_text(text,topic, doc_type, doc_subject):\n",
    "    # Anthropic\n",
    "    claude37 = \"claude-3-7-sonnet-20250219\"\n",
    "\n",
    "    # OpenAI\n",
    "    gpt4o = \"gpt-4o\"\n",
    "\n",
    "    # model = ChatOpenAI(model=gpt4o)\n",
    "    model = ChatAnthropic(model=claude37)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tu es expert en {topic}.\\n\"\n",
    "    \"Voici un {doc_type} sur {doc_subject}.\\n\"\n",
    "    \"Il y a dans ce document des images explicatives et des formules mathématiques.\\n\"\n",
    "    \"Ton but est de faire un fichier texte qui redit exactement tout ce qui est expliqué dans ce \"\n",
    "    \"document en incluant les formules mathématiques et les explications que les images peuvent apporter.\\n\\n\"\n",
    "    \"{text}\"\n",
    "    )\n",
    "\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    chain = (\n",
    "        {\"topic\": RunnablePassthrough()}\n",
    "        | {\"doc_type\": RunnablePassthrough()}\n",
    "        | {\"doc_subject\": RunnablePassthrough()}\n",
    "        | {\"text\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | model\n",
    "        | output_parser\n",
    "    )\n",
    "\n",
    "    response = chain.invoke({\"text\": text})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Function to encode PDF as base64\n",
    "def encode_pdf_to_base64(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        return base64.b64encode(pdf_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = \"data_pdf/Leçon #1 - Introduction.pdf\"\n",
    "base64_pdf = encode_pdf_to_base64(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='(Verse 1)\\nThe code was dark, the data deep, a labyrinth of lore,\\nNo human mind could hope to keep the knowledge at its core.\\nThe models strained, the queries choked, the answers slow and thin,\\nA better way, the people hoped, to let the wisdom win.\\n\\n(Chorus)\\nThen LangChain came, a shining star, to weave a magic thread,\\nConnecting chains both near and far, the words the models said.\\nFrom documents vast, to APIs bright, a knowledge river flowed,\\nLangChain forged the path of light, where understanding growed.\\n\\n(Verse 2)\\nWith chains of prompt and memory, and agents keen and bold,\\nIt navigated complexity, a story to be told.\\nIt parsed the texts, it learned the facts, it reasoned and it planned,\\nAnd offered insights, free from cracks, a helper close at hand.\\n\\n(Chorus)\\nFor LangChain came, a shining star, to weave a magic thread,\\nConnecting chains both near and far, the words the models said.\\nFrom documents vast, to APIs bright, a knowledge river flowed,\\nLangChain forged the path of light, where understanding growed.\\n\\n(Bridge)\\nNo longer bound by model size, or datasets locked away,\\nLangChain opened up the skies, and ushered in the day.\\nOf personalized, intelligent grace, a learning, growing friend,\\nTo help us navigate this space, and on its help depend.\\n\\n(Verse 3)\\nThe developers, with eager hearts, embraced this powerful tool,\\nAnd built on it with clever arts, to break each learning rule.\\nFrom chatbots wise to data dives, the applications spread,\\nLangChain helped knowledge come alive, and filled the world with bread.\\n\\n(Chorus)\\nAnd LangChain shines, a guiding star, that weaves a magic thread,\\nConnecting chains both near and far, the words the models said.\\nFrom documents vast, to APIs bright, a knowledge river flowed,\\nLangChain forged the path of light, where understanding growed.\\n\\n(Outro)\\nSo raise a glass, to LangChain’s might, a legend in the code,\\nThat brings the future into sight, and lightens every load.\\nThe data sings, the models soar, the knowledge flows so free,\\nThanks to LangChain, forevermore, for all eternity!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run-29294ceb-c625-4bd2-938c-5e3dc4c10491-0', usage_metadata={'input_tokens': 7, 'output_tokens': 500, 'total_tokens': 507, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "llm.invoke(\"Sing a ballad of LangChain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bien sûr, voici le contenu textuel du cours sur les neurones artificiels, en incluant les formules et les explications des images.\n",
      "\n",
      "**NEURONES ARTIFICIELS**\n",
      "\n",
      "Par Kévin Bouchard Ph.D.\n",
      "Professeur titulaire en intelligence artificielle et apprentissage automatique\n",
      "Laboratoire d'Intelligence Ambiante pour la reconnaissance d'activités (LIARA)\n",
      "Directeur de l'Espace innovation en technologies numériques Hydro-Québec\n",
      "Président du Regroupement québécois des maladies orphelines (RQMO)\n",
      "Université du Québec à Chicoutimi\n",
      "www.kevin-bouchard.ca  Kevin_Bouchard@uqac.ca\n",
      "\n",
      "**CONTENU DE LA LEÇON #2**\n",
      "\n",
      "Vous apprendrez:\n",
      "* Comment fonctionne un seul neurone artificiel (ou réviserez)\n",
      "* Comment on entraîne un Adaline et le passage vers l'optimisation\n",
      "* Nous essaierons également de définir l'apprentissage profond comme un sous-domaine de l'intelligence artificielle\n",
      "\n",
      "Contenu spécifique:\n",
      "* Retour sur le Perceptron\n",
      "* Exercices\n",
      "* Adaline et le gradient\n",
      "* Retour sur Logistic Regression\n",
      "* Exemples de code\n",
      "\n",
      "**UN BREF HISTORIQUE DES PERCEPTRONS**\n",
      "\n",
      "* Retour en 1943: McCulloch & Pitts publient le *MCP Neuron*\n",
      "* *A logical Calculus of the Ideas Immanent in Nervous Activity*\n",
      "* Cellules nerveuses interconnectées\n",
      "* Transmettent des signaux électriques et chimiques\n",
      "* Simple porte logique!\n",
      "\n",
      "L'image montre une cellule nerveuse avec les éléments suivants:\n",
      "* Entrées (Dendrites)\n",
      "* Noyau\n",
      "* Axone\n",
      "* Gaine de Myéline\n",
      "* Termination Axonale\n",
      "* Sorties\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "* Rosenblatt 1957: Apprendre les poids optimaux à multiplier avec les entrées afin de déterminer si le neurone s'active ou non\n",
      "* Utile pour la classification binaire (ML supervisé)\n",
      "    * 1 positif\n",
      "    * -1 négatif\n",
      "* z est l'entrée nette composé d'une combinaison linéaire d'entrées x et de poids w (somme pondérée)\n",
      "\n",
      "Formule:\n",
      "\n",
      "w =  [w1, w2, ..., wm]^T  x = [x1, x2, ..., xm]^T  z = w1x1 + ... + wmxm\n",
      "\n",
      "Fonction d'activation:\n",
      "\n",
      "Φ(z) = 1 si z >= θ\n",
      "        -1 sinon\n",
      "\n",
      "* La classification se définie par une fonction d'activation φ(z) avec un threshold θ\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "* x représente l'entrée\n",
      "* Grosso modo, l'instance avec ses m features\n",
      "* Il peut s'agir d'une instance d'apprentissage ou d'une instance à classer\n",
      "* La classe est déterminée en fonction de ce qu'on appelle une fonction d'activation\n",
      "* La fonction d'activation du Perceptron s'appelle Heaviside ou encore fonction par palier (step-wise function)\n",
      "* Elle est représentée par φ( ) et prend z en entrée avec un seuil θ\n",
      "\n",
      "Formule:\n",
      "\n",
      "w =  [w1, w2, ..., wm]^T  x = [x1, x2, ..., xm]^T  z = w1x1 + ... + wmxm\n",
      "\n",
      "Fonction d'activation:\n",
      "\n",
      "Φ(z) = 1 si z >= θ\n",
      "        -1 sinon\n",
      "\n",
      "L'image montre la fonction de Heaviside:\n",
      "* Sur l'axe des x, on a z.\n",
      "* Sur l'axe des y, on a φ(z).\n",
      "* φ(z) = -1 pour z < 0\n",
      "* φ(z) = 1 pour z >= 0\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "* L'équation peut être écrite plus simplement apprendre le seuil θ comme un paramètre supplémentaire\n",
      "* Pour ce faire, nous définissons un paramètre w0 = θ avec une caractéristique fictive x0 = 1\n",
      "\n",
      "Formule:\n",
      "\n",
      "z = w0x0 + w1x1 + ... + wmxm = w^T x = ∑(de j=0 à m) wjXj = w^T x\n",
      "\n",
      "* T est ajouté dans la forme vectorielle pour signifier transposé\n",
      "* E.g.: z = [1 2 3] * [4 5 6] = 1 * 4 + 2 * 5 + 3 * 6 = 32\n",
      "* Note: w0 est ce qu'on appelle le biais\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "L'image montre la fonction d'activation φ(w^T x) qui donne 1 si w^T x >= 0 et -1 sinon.\n",
      "\n",
      "L'image montre un plan avec deux classes:\n",
      "* Les points rouges sont séparés des croix bleues par une ligne droite.\n",
      "* Les points rouges sont du côté où φ(w^T x) < 0.\n",
      "* Les croix bleues sont du côté où φ(w^T x) >= 0.\n",
      "\n",
      "**FONCTIONNEMENT DE L'APPRENTISSAGE**\n",
      "\n",
      "1. Initialisation des poids à 0 (ou un petit nombre aléatoire)\n",
      "2. Tant qu'il y a des mauvaises classifications:\n",
      "    1. Pour chaque exemple d'entraînement x^(i):\n",
      "        1. Classer x^(i) avec les modèles courant pour obtenir la sortie estimée ŷ^(i)\n",
      "        2. Mettre à jour les poids\n",
      "\n",
      "* La mise à jour des poids wj ∈ w est wj = wj + Δwj\n",
      "* Δwj calculé selon la règle d'apprentissage du perceptron:\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δwj = η(y^(i) - ŷ^(i))x^(i)j\n",
      "\n",
      "* η est le fameux « Learning rate » dans l'intervalle [0.0, 1.0]\n",
      "\n",
      "**FONCTIONNEMENT DE L'APPRENTISSAGE**\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δwj = η(y^(i) - ŷ^(i))x^(i)j\n",
      "\n",
      "* Exemples:\n",
      "    * Δw1 = 1(1 - 1) * 1 = 0  Prédiction positive correcte!\n",
      "    * Δw1 = 1(-1 - (-1)) * 1 = 0  Prédiction négative correcte!\n",
      "    * Δw1 = 1(1 - (-1)) * 4 = 8\n",
      "    * Δw1 = 1(-1 - 1) * 0.5 = -1\n",
      "    * Δw1 = 0.1(1 - (-1)) * 4 = 0.8\n",
      "\n",
      "* Le poids ne changera pas si la prédiction est correcte!\n",
      "* Il varie autrement en fonction de la valeur de x^(i)j dans le vecteur d'entraînement i\n",
      "\n",
      "**BILAN**\n",
      "\n",
      "* Si pas séparable linéairement, Perceptron MàJ à l'infini\n",
      "* Nombre max de passes à travers l'ensemble (epochs)\n",
      "\n",
      "L'image montre trois cas:\n",
      "* Linearly separable: les deux classes peuvent être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "\n",
      "L'image montre le fonctionnement d'un perceptron:\n",
      "* Entrées: 1, x1, x2, ..., xm\n",
      "* Poids: w0, w1, w2, ..., wm\n",
      "* Net input function: ∑ (somme pondérée des entrées et des poids)\n",
      "* Activation function: Heaviside\n",
      "* Output\n",
      "\n",
      "**BILAN**\n",
      "\n",
      "* Dans l'ensemble, le perceptron original met en place les principaux éléments des réseaux de neurones\n",
      "* Le perceptron est un modèle linéaire\n",
      "* Si pas séparable linéairement, Perceptron MàJ à l'infini\n",
      "* Nombre max de passes à travers l'ensemble (epochs)\n",
      "\n",
      "L'image montre trois cas:\n",
      "* Linearly separable: les deux classes peuvent être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "\n",
      "L'image montre le fonctionnement d'un perceptron:\n",
      "* Entrées: 1, x1, x2, ..., xm\n",
      "* Poids: w0, w1, w2, ..., wm\n",
      "* Net input function: ∑ (somme pondérée des entrées et des poids)\n",
      "* Activation function: Heaviside\n",
      "* Output\n",
      "\n",
      "**EXERCICES**\n",
      "\n",
      "* Faisons des entraînements de Perceptron ensemble\n",
      "* Supposons un Perceptron entraîné sur l'ensemble des Iris\n",
      "* Poids: [-0.311, -3.091, 3.443, -3.292]\n",
      "* Biais: -1.0\n",
      "* Tentez le calcul avec les instances suivantes (et votre ordinateur!!)\n",
      "* Instance Versicolor: [0.311, -0.592, 0.535, 0.001]\n",
      "* Instance Virginica: [-0.174, 1.71, -1.17, -1.184]\n",
      "* z = -1 + 0.311 * 0.311 - 3.091 * -0.592 + 3.443 * 0.535 + 0.001 * -3.292 = 2.572\n",
      "* z = -1 - 0.311 * -0.174 - 3.091 * 1.71 + 3.443 * -1.17 - 3.292 * -1.184 = -6.362\n",
      "\n",
      "**EXEMPLE AVEC LES IRIS**\n",
      "\n",
      "* À partir du code, voici un moment spécifique dans l'exécution\n",
      "* Modèle actuel: [ 0. -0.24 0.14 -0.7 -0.3 ]\n",
      "* Fleur: [4.6 3.1 1.5 0.2] Type: Iris-setosa\n",
      "* z = 0.0 * 1 + [ -0.24 0.14 -0.7 -0.3 ] * [4.6 3.1 1.5 0.2] = -1.78\n",
      "* Update = 0.1 * ( 1 - (-1) ) = 0.2\n",
      "* Poids MàJ: [ -0.24 0.14 -0.7 -0.3 ] + [4.6 3.1 1.5 0.2] * 0.2 = [ 0.68 0.76 -0.4 -0.26 ]\n",
      "* On voit le calcul de l'entrée nette (en prenant le biais)\n",
      "* Le calcul de la mise à jour\n",
      "* La mise à jour elle-même\n",
      "\n",
      "**ONE-VS-ALL**\n",
      "\n",
      "* Les algorithmes de classification binaires tel que le perceptron peuvent être étendu aux problèmes multi classes par diverses stratégies\n",
      "* Le *One-vs-All* consiste à créer un classeur par classe où toute autre instance est considérée de classe négative\n",
      "* La classification consiste ensuite à passer un nouvel exemple dans tous les classeurs de façon à trouver celui qui se déclenche\n",
      "* Attention! En général, on préfère plutôt avoir une sortie en termes de niveau de confiance où l'on cherche le max\n",
      "* Difficile avec des données mal balancées\n",
      "* Difficile de s'assurer que la gamme de niveaux de confiance ne varie pas trop d'un classeur à l'autre\n",
      "\n",
      "**ONE-VS-ONE**\n",
      "\n",
      "* Il existe une autre stratégie populaire pour d'autres types de classeurs qui ne sont pas multiclasses par défaut\n",
      "* Le One-vs-One est une des stratégies populaires utilisées dans Scikit-Learn\n",
      "* Un classeur par pair de classe\n",
      "* Vote sur la totalité des classeurs\n",
      "* Le vote se fait sur l'entièreté des Tc =  c(c-1)/2 classeurs\n",
      "* E.g.: pour 10 classes => 10(10 - 1)/2 = 45 classeurs\n",
      "* Scikit-Learn explique de long en large les stratégies implémentées selon l'algorithme:\n",
      "* https://scikit-learn.org/stable/modules/multiclass.html\n",
      "\n",
      "**ADAPTIVE LINEAR NEURONS**\n",
      "\n",
      "Adaline: Un autre type de NN simple couche\n",
      "-MàJ des poids selon une fonction d'activation linéaire!\n",
      "\n",
      "**ADALINE**\n",
      "\n",
      "L'image montre le fonctionnement d'un Adaline:\n",
      "* Entrées: 1, x1, x2, ..., xm\n",
      "* Poids: w0, w1, w2, ..., wm\n",
      "* Net input function: ∑ (somme pondérée des entrées et des poids)\n",
      "* Activation function: Identité (linéaire)\n",
      "* Quantizer: Heaviside\n",
      "* Output\n",
      "\n",
      "* La fonction d'activation linéaire φ(z) est simplement la fonction d'identité de l'entrée nette φ(w^T x) = w^T x\n",
      "* Elle sert à mettre à jour les poids\n",
      "* Cependant, un élément similaire à la fonction Heaviside parfois nommé « Quantizer » permet la prédiction de la classe\n",
      "* Les sorties sont des valeurs *continues!* (plutôt que binaires)\n",
      "\n",
      "**FONCTION DE COÛTS**\n",
      "\n",
      "* Clé en ML: optimisation d'une fonction objective (souvent *cost* ou *loss function*)\n",
      "* Ceci n'est pas un cours d'optimisation, mais nous devrons comprendre quelques éléments\n",
      "* Pour Adaline, fonction de coûts à minimiser\n",
      "* Apprendre les poids en tant que *Sum of Squared Errors* (SSE) entre les sorties et les vraies classes\n",
      "\n",
      "Formule:\n",
      "\n",
      "J(w) = 1/2 ∑ (y^(i) - φ(z^(i)))^2\n",
      "\n",
      "*Le ½ est ajouté pour faciliter le calcul du gradient (1/n classes)\n",
      "\n",
      "**ALGORITHME DU GRADIENT**\n",
      "\n",
      "* Puisque J(w) est une fonction convexe, nous pouvons faire l'optimisation grâce à l'algorithme *gradient descent*.\n",
      "* Regarde la « pente » des états voisins\n",
      "* Bouge dans la direction la plus abrupte\n",
      "* Trouvée par la dérivée partielle (voir diapo 15)\n",
      "* Learning rule: w := w + Δw\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δwj = -η ∂J/∂wj = η ∑ (y^(i) - φ(z^(i))) xj^(i)\n",
      "\n",
      "L'image montre un algorithme de Hill-climbing:\n",
      "* Exploration locale\n",
      "* G(n) (cost) de chaque voisin\n",
      "* On choisit le voisin qui améliore le plus\n",
      "\n",
      "**ALGORITHME DU GRADIENT**\n",
      "\n",
      "* La dérivée d'une fonction mesure comment elle change à un point donné\n",
      "* Elle quantifie le *taux de variation* de la fonction par rapport à une ou plusieurs variables\n",
      "* La dérivée de f(x) à un point spécifique x = a est directement la pente de la tangente à ce point (taux de variation instantané)\n",
      "\n",
      "Formule:\n",
      "\n",
      "f'(a) = lim(h->0) (f(a + h) - f(a))/h\n",
      "\n",
      "* Par exemple, si f(x) = 3x^2 + 4x et x = 1, alors pour h vers 0 nous aurons ≈ 2\n",
      "* E.g. h = 0.1, f'(1) = 2.3 mais h = 0.00001, f'(1) = 2.00003\n",
      "\n",
      "**POURQUOI EST-CE PERTINENT?**\n",
      "\n",
      "L'image montre une courbe de coût J(w) en fonction du poids w. On voit un point de départ (initial weight) et le gradient qui pointe vers le minimum global (Global cost minimum).\n",
      "\n",
      "* La différentiation peut nous dire comment varier les paramètres d'une fonction\n",
      "* Évidemment, nos fonctions sont plus complexes, car elles contiennent |w| paramètres\n",
      "* Le gradient d'une fonction f(x1, x2, ..., xn) est un *vecteur* qui contient les *dérivées partielles* de f par rapport à chacune des variables xi\n",
      "\n",
      "Formule:\n",
      "\n",
      "∇f = (∂f/∂x1, ∂f/∂x2, ..., ∂f/∂xn)\n",
      "\n",
      "* Par exemple, pour f(x,y) = x^2 + y^2 le gradient serait le vecteur ∇f = [2x, 2y]\n",
      "* Bref, le gradient de notre fonction de coûts est le vecteur de taille |w|\n",
      "* Donc, w := w + Δw\n",
      "\n",
      "**DÉRIVÉE PARTIELLE DE SSE**\n",
      "\n",
      "Formule:\n",
      "\n",
      "J(w) = 1/2 ∑ (y^(i) - φ(z^(i)))^2\n",
      "\n",
      "* Pour trouver la dérivée partielle ∂J/∂wj (comment J change en fonction du poids)\n",
      "* On applique la règle de la chaîne pour le terme au carré:\n",
      "\n",
      "∂J/∂wj (y^(i) - φ(z^(i)))^2 = 2(y^(i) - φ(z^(i))) * ∂J/∂wj (y^(i) - φ(z^(i)))\n",
      "\n",
      "∂J/∂wj = 1/2 ∑ 2(y^(i) - φ(z^(i))) * ∂J/∂wj (y^(i) - φ(z^(i)))\n",
      "\n",
      "* De plus le 2 annule le ½\n",
      "\n",
      "∂J/∂wj = ∑ (y^(i) - φ(z^(i))) * ∂J/∂wj (y^(i) - φ(z^(i)))\n",
      "\n",
      "**DÉRIVÉE PARTIELLE DE SSE**\n",
      "\n",
      "Formule:\n",
      "\n",
      "J(w) = 1/2 ∑ (y^(i) - φ(z^(i)))^2\n",
      "\n",
      "* La fonction φ(z^(i)) peut être remplacée par la somme pour toutes les instances\n",
      "\n",
      "∂J/∂wj = ∑ (y^(i) - φ(z^(i))) ∂/∂wj (y^(i) - ∑ xj^(i))\n",
      "\n",
      "* Comme y^(i) est une constante, nous cherchons plutôt ∂/∂wj φ(z^(i))\n",
      "\n",
      "∂φ(z^(i))/∂wj = φ'(z^(i)) * ∂z^(i)/∂wj\n",
      "\n",
      "* Puisque z^(i) = ∑ wj xj^(i), alors ∂φ(z^(i))/∂wj = xj^(i)\n",
      "\n",
      "∂J/∂wj = ∑ (y^(i) - φ(z^(i))) (-xj^(i)) = -∑ (y^(i) - φ(z^(i)))xj^(i)\n",
      "\n",
      "**RETOUR AU GRADIENT**\n",
      "\n",
      "* Bref nous avons maintenant: ∂J/∂wj = -∑ (y^(i) - φ(z^(i)))xj^(i)\n",
      "* Nous avons dit précédemment que la mise à jour des poids Δw = -η ∂J/∂wj\n",
      "* Donc ultimement, si vous souhaitez implémenter Adaline avec le gradient:\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δw = η ∑ (y^(i) - φ(z^(i)))xj^(i)\n",
      "\n",
      "* En code c'est encore plus simple:\n",
      "\n",
      "output = self.activation(X)\n",
      "errors = (y - output)\n",
      "self.w_[1:] += self.eta * X.T.dot(errors)\n",
      "self.w_[0] += self.eta * errors.sum()\n",
      "\n",
      "**EXPLICATION DU CODE**\n",
      "\n",
      "output = self.activation(X)\n",
      "\n",
      "* Calcul l'entrée nette pour chaque instance\n",
      "\n",
      "errors = (y - output)\n",
      "\n",
      "* Deux vecteurs de la taille du dataset\n",
      "* Donne en retour un vecteur d'erreurs de la même taille où chaque vraie classe se voit soustraire l'entrée\n",
      "* E.g. y=1, z=0.234 alors 1-0.234\n",
      "\n",
      "self.w_[1:] += self.eta * X.T.dot(errors)\n",
      "\n",
      "* On multiplie le learning rate avec X\n",
      "* X est un tableau de dimension instances par features\n",
      "* .T transpose X afin de pouvoir le multiplier par notre vecteur d'erreurs\n",
      "* Ça donne un vecteur de taille features, soit 1 élément par w!!\n",
      "\n",
      "self.w_[0] += self.eta * errors.sum()\n",
      "\n",
      "* Fait la somme des erreurs * le learning rate et l'addition au biais\n",
      "\n",
      "**PRODUIT CROISÉ (DOT) - RAPPEL**\n",
      "\n",
      "* Attention! Cette ligne ne donne pas la même chose:  X.*errors\n",
      "* On multiplie chaque élément du vecteur par les éléments de la matrice et on reste en instances x features!!\n",
      "* Tandis que le produit croisé change la dimension\n",
      "* Si X ∈ R^(nxf) et errors ∈ R^n alors X^T e:\n",
      "\n",
      "Formule:\n",
      "\n",
      "X^T e = [∑(i=1 à n) x1,i ei, ∑(i=1 à n) x2,i ei, ..., ∑(i=1 à n) xf,i ei]\n",
      "\n",
      "**GRADIENT**\n",
      "\n",
      "*Haut: Visualisation de l'algorithme du gradient à 1 paramètre\n",
      "*Bas: SSE en fonction des epochs\n",
      "\n",
      "L'image du haut montre la fonction de coût en fonction d'un paramètre, avec le gradient et la dérivée qui convergent vers le minimum.\n",
      "\n",
      "L'image du milieu montre des données labellisées et la sortie du modèle.\n",
      "\n",
      "L'image du bas montre la somme des erreurs au carré (Sum-squared-error) en fonction du nombre d'epochs. On voit que l'erreur diminue au fur et à mesure que le nombre d'epochs augmente.\n",
      "\n",
      "**RÉSUMÉ**\n",
      "\n",
      "* Même si la règle d'apprentissage φ(z^(i)) ressemble à celle du perceptron, z^(i) = w^T x est un nombre réel\n",
      "* Dans le perceptron, c'est en entier naturel de classe 1 ou -1\n",
      "* Enfin, la MàJ des poids se fait sur le dataset en entier!\n",
      "* Dans le perceptron, c'est plutôt incrémental (instance par instance)\n",
      "* L'algorithme du gradient bénéficie du *feature scaling*\n",
      "* Le calcul est plus rapide!!\n",
      "* sklearn.preprocessing.scale (standardisation)\n",
      "* Sinon avec un tenseur Torch:\n",
      "\n",
      "data = torch.tensor([[1.0, 2.0, 5.0], [4.0, 5.0, 6.0]])\n",
      "means = data.mean(dim=0, keepdim=True)\n",
      "stds = data.std(dim=0, keepdim=True)\n",
      "normalized_data = (data - means) / stds\n",
      "\n",
      "**ALLER UN PEU PLUS LOIN...**\n",
      "\n",
      "**HYPERPARAMÈTRES**\n",
      "\n",
      "* η, le « Learning rate » et le nombre d'« epochs » sont ce qu'on appelle des hyperparamètres\n",
      "* Il n'y a pas de valeurs parfaites\n",
      "* Un learning rate trop haut peut empêcher de converger\n",
      "* Un learning rate trop faible fera tourner l'algorithme longtemps (besoin de rouler un grand nombre d'\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mimetypes\n",
    "import fitz  # PyMuPDF for PDF to image conversion\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Function to convert PDF to images and encode them\n",
    "def pdf_to_base64_images(pdf_path):  # Limit pages to avoid context limits\n",
    "    images = []\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Limit number of pages if PDF is too long\n",
    "    num_pages = len(pdf_document)\n",
    "    \n",
    "    for page_number in range(num_pages):\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # Higher resolution\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        \n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        img.save(buffered, format=\"JPEG\", quality=85)  # JPEG for better compatibility\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        \n",
    "        images.append(img_base64)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = \"data_pdf/Leçon #2 - Neurone artificiel.pdf\"\n",
    "base64_images = pdf_to_base64_images(pdf_path)\n",
    "\n",
    "# Initialize Gemini through LangChain\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"models/gemini-2.0-flash\",\n",
    "    max_tokens=5120\n",
    "\n",
    ")\n",
    "\n",
    "# Build content with all PDF pages as images\n",
    "content = []\n",
    "content.append({\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"Tu es expert en deep learning.\\n\"\n",
    "            \"Voici un cours sur l'introduction au deep learning.\\n\"\n",
    "            \"Il y a dans ce document des images explicatives et des formules mathématiques.\\n\"\n",
    "            \"Ton but est de faire un fichier texte qui redit exactement tout ce qui est expliqué dans ce \"\n",
    "            \"document en incluant les formules mathématiques et les explications que les images peuvent apporter.\\n\"\n",
    "})\n",
    "\n",
    "# Add each page as an image\n",
    "for img_base64 in base64_images:\n",
    "    content.append({\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{img_base64}\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Create a message with the PDF pages as images\n",
    "message = HumanMessage(content=content)\n",
    "\n",
    "# Get response\n",
    "response = llm.invoke([message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# GRAPH NEURAL NETWORKS\n",
      "\n",
      "Par Kévin Bouchard Ph.D.\n",
      "Professeur titulaire en intelligence artificielle et apprentissage automatique\n",
      "Laboratoire d'Intelligence Ambiante pour la reconnaissance d'activités (LIARA)\n",
      "Directeur de l'Espace innovation en technologies numériques Hydro-Québec\n",
      "Président du Regroupement québécois des maladies orphelines (RQMO)\n",
      "Université du Québec à Chicoutimi\n",
      "www.Kevin-Bouchard.ca        Kevin_Bouchard@uqac.ca\n",
      "\n",
      "## TABLE DES MATIÈRES\n",
      "\n",
      "1. Motivation\n",
      "2. Types de graphes\n",
      "3. Applications dans les graphes\n",
      "4. Node embeddings\n",
      "5. GNN\n",
      "\n",
      "## HISTORIQUE DES GNN\n",
      "\n",
      "- Les graphes attirent l'intérêt des chercheurs en mathématique et en informatique depuis très longtemps\n",
      "- La première application concrète des réseaux de neurones aux graphes date de 1997 - A. Sperduti and A. Starita\n",
      "- Cependant, la première référence connu au GNN vient de Gori et al. (2005), puis de Scarselli et al. (2009) et enfin de Gallicchio et al. (2010)\n",
      "  - Ces GNN tombaient dans la catégorie des réseaux récurrents (RecGNN)\n",
      "  - Ils souffrent donc des mêmes problèmes à l'entraînement!\n",
      "- Les GNN sont réellement devenus populaires suite à l'adaptation de la convolution par Bruna et al (2013) – ConvGNN\n",
      "- Depuis, il existe des GNN exploitant tous les types d'unité: GAE, Transformeur, etc.\n",
      "\n",
      "## MOTIVATION\n",
      "\n",
      "- Nous avons vu jusqu'à présent qu'il faut parfois prendre en considération le format des données afin de bien tirer avantage d'informations qui peuvent s'y cacher\n",
      "  - Par exemple, les informations de nature spatiale sont particulièrement bien exploitées à l'aide des convolutions\n",
      "  - Et celles de nature séquentielle/temporelle à l'aide d'unités récurrentes\n",
      "- Les graphes eux incorporent de l'information relationnelle, pas toujours bien capturées par une structure en grille dont le nombre de voisins est fixé à l'avance\n",
      "  - Les CNN et RNN se concentrent sur la capture d'informations d'un nœud unique (pixel, mot, etc.)\n",
      "  - Ils ne capturent pas bien l'information contextuelle des nœuds voisins et de leurs liens\n",
      "\n",
      "## GRAPHES\n",
      "\n",
      "- Les graphs se retrouvent naturellement un peu partout autour de nous\n",
      "\n",
      "Les domaines représentés dans les images incluent:\n",
      "- Chaîne alimentaire\n",
      "- Événements\n",
      "- Réseaux informatiques\n",
      "- Métro/train\n",
      "- Propagation de maladies\n",
      "- Réseaux sociaux\n",
      "\n",
      "Ce ne sont que quelques exemples!\n",
      "\n",
      "- Les domaines complexes possèdent une structure relationnelle riche, qui peut être représentée par un graphe relationnel\n",
      "- Comment tirer avantage de la structure relationnelle?\n",
      "\n",
      "Exemples illustrés:\n",
      "- Knowledge Graphs\n",
      "- Regulatory Networks\n",
      "- Scene Graphs\n",
      "- Code Graphs\n",
      "- Molecules\n",
      "- 3D Shapes\n",
      "\n",
      "## MAIS QU'EST-CE QU'UN GRAPHE?\n",
      "\n",
      "- Un graphe est une structure G = (V, E) définit par un ensemble de noeuds V et d'arêtes E entre ces nœuds\n",
      "- Une arête allant de v ∈ V vers un noeud u ∈ V se définit comme (v, u) ∈ E\n",
      "- Les nœuds peuvent être creux ou encore posséder une structure\n",
      "  - La structure peut être un ensemble de caractéristiques\n",
      "  - E.g.: réseau social, le nœud représente un utilisateur et ses caractéristiques les activités de l'utilisateur sur le réseau\n",
      "- Les arêtes peuvent avoir une direction, un poids et possiblement lier un nœud à lui-même\n",
      "  - Elles peuvent même avoir leurs propres caractéristiques!\n",
      "\n",
      "## MATRICE D'ADJACENCE\n",
      "\n",
      "- Les graphes peuvent être représentés sous un format facile à utiliser qu'on appelle la matrice d'adjacence\n",
      "- Celle-ci est généralement concaténé à l'ensemble des vecteurs de caractéristiques des nœuds\n",
      "- La matrice d'adjacence d'un réseau est A ∈ ℝ^(|V|×|V|)\n",
      "  - |V| est le nombre de nœuds dans le graphe\n",
      "  - Celle-ci est initialisée avec des 0\n",
      "- Nous présentons simplement la présence d'un lien avec A[v, u] = 1 si (v, u) ∈ E\n",
      "\n",
      "## TYPES DE GRAPHE ET LEUR MATRICE D'ADJACENCE\n",
      "\n",
      "[L'image montre différents types de graphes avec leurs matrices d'adjacence correspondantes:\n",
      "- Directed graph (graphe orienté)\n",
      "- Undirected graph (graphe non orienté)\n",
      "- Knowledge graph (graphe de connaissance)\n",
      "- Weighted graph (graphe pondéré)]\n",
      "\n",
      "## TÂCHES POSSIBLES\n",
      "\n",
      "- Classification de nœuds\n",
      "- Prédiction de noeuds\n",
      "- Prédiction de graphes\n",
      "- Génération de graphes\n",
      "- Même chose mais de sous-ensembles de graphes!\n",
      "- Même chose mais de liens!\n",
      "\n",
      "## ALPHAFOLD: PRÉDICTION DE NOEUDS\n",
      "\n",
      "- Prédire de manière computationnelle la structure 3D d'une protéine uniquement à partir de sa séquence d'acides aminés\n",
      "- Pour chaque nœud, prédire ses coordonnées 3D\n",
      "- L'idée est d'utiliser un graphe spatial\n",
      "  - Nœuds: Acides aminées dans une séquence de protéines\n",
      "  - Arêtes: Proximité entre les acides aminées\n",
      "\n",
      "## ALPHAFOLD: PRÉDICTION DE NOEUDS\n",
      "\n",
      "[Description de l'architecture AlphaFold montrant:\n",
      "- MSA embedding\n",
      "- Sequence-residue edges\n",
      "- Embed & outer sum\n",
      "- Residue-residue edges\n",
      "- Structure module\n",
      "- Pairwise distances\n",
      "- 3D structure]\n",
      "\n",
      "## RECOMMANDATION: PRÉDICTION DE LIENS\n",
      "\n",
      "- Les utilisateurs interagissent avec des articles\n",
      "  - Regarder des films, acheter des produits dérivés, écouter de la musique\n",
      "  - Noeuds : Utilisateurs et articles\n",
      "  - Arêtes : Interactions utilisateur-article\n",
      "- Objectif : Recommander des articles que les utilisateurs pourraient aimer\n",
      "\n",
      "[Image illustrant des utilisateurs connectés à différents items avec des interactions existantes et des recommandations \"You might also like\"]\n",
      "\n",
      "## INTERACTION DE MÉDICAMENTS\n",
      "\n",
      "- De nombreux patients prennent plusieurs médicaments pour traiter des maladies complexes ou coexistantes\n",
      "- Tâche : Étant donné une paire de médicaments, prédire les effets secondaires indésirables\n",
      "  - Nœuds: médicaments et protéines\n",
      "  - Arêtes: interactions\n",
      "\n",
      "[Image montrant un réseau d'interactions médicament-protéine avec différents effets secondaires]\n",
      "\n",
      "## TRAFFIC: PRÉDICTIONS DE GRAPHES\n",
      "\n",
      "[Image de Google Maps montrant un itinéraire]\n",
      "\n",
      "- Nœuds: segments de route\n",
      "- Arêtes: connectivité entre les segments de route\n",
      "\n",
      "[Diagramme montrant le processus de prédiction de trafic utilisant des données de voyage anonymisées, analyses et GNN]\n",
      "\n",
      "## GOOGLE MAPS ETA IMPROVEMENTS AROUND THE WORLD\n",
      "\n",
      "[Carte mondiale montrant les pourcentages d'amélioration des ETA (temps d'arrivée estimé) dans différentes villes]\n",
      "\n",
      "Avec leur approche basée sur les GNN, DeepMind ont significativement amélioré les prédictions de trafic!\n",
      "\n",
      "## OUTILS POPULAIRES\n",
      "\n",
      "- PyTorch Geometric\n",
      "  - Expressément pour PyTorch\n",
      "  - Bon nombre de cours et turoriaux: https://pytorch-geometric.readthedocs.io/en/latest/get_started/colabs.html\n",
      "\n",
      "- Deep Graph Library\n",
      "  - Fonctionne avec PyTorch, Tensorflow et Apache MXNet\n",
      "  - https://www.dgl.ai/\n",
      "\n",
      "## NODE EMBEDDING\n",
      "\n",
      "Il s'agit d'encoder les nœuds dans un espace latent!\n",
      "\n",
      "## POURQUOI?\n",
      "\n",
      "- La similarité entre les embeddings de plusieurs nœuds indique leur similarité dans le réseau\n",
      "- Cela permet d'encoder automatiquement l'information du réseau\n",
      "  - Pour un graphe G(V, E) avec V noeauds et E arêtes\n",
      "  - Des nœuds v₁, v₂ auront des embeddings plus proches dans l'espace vectoriel à faible dimension\n",
      "- Peut donc servir à différents types de tâches liés aux graphes\n",
      "  - Classification de nœuds\n",
      "  - Prédiction de liens\n",
      "  - Classification de graphes\n",
      "  - Etc.\n",
      "\n",
      "## COMPOSANTS CLÉS\n",
      "\n",
      "- Nous avons besoin d'un encodeur Enc(v) = z_v\n",
      "  - Sa version la plus simple est d'avoir une matrice Z ∈ ℝ^(d×|V|)\n",
      "  - C'est elle que nous devons apprendre!\n",
      "- Une fonction de similarité ou une distance\n",
      "  - La similarité cosinus\n",
      "  - Une des distances de Minkowski\n",
      "  - Ou encore plus simplement le produit scalaire (dot product): a · b = ∑ aᵢbᵢ\n",
      "- Nous couvrirons les encodeurs profonds par la suite avec nos GNN\n",
      "\n",
      "## MÉTHODES D'ENCODAGE\n",
      "\n",
      "- Les méthodes sans caractéristiques sont dites par proximité\n",
      "- On trouve les marches aléatoires (Random Walk)\n",
      "- Ou encore les marches biaisées (Biased Random Walk)\n",
      "- Nos embeddings seront indépendants de la tâche, ce qui est avantageux pour la généralisation\n",
      "- De plus, ils sont entraînés par auto-apprentissage ou apprentissage non-supervisé\n",
      "\n",
      "- Les méthodes basées sur les caractéristiques sont plus classiques:\n",
      "  - Autoencodeurs profonds→ on peut entraîner un AE pour compresser les attributs\n",
      "  - Factorisation matricielle→ on peut utiliser la décomposition en valeur singulière pour factoriser une matrice d'attributs des nœuds en dimension inférieure\n",
      "\n",
      "## RANDOM WALK\n",
      "\n",
      "- Supposons le vecteur z_u et la probabilité P(v|z_u) de visiter un nœud v au hasard en partant de u\n",
      "- z_v^T z_u ≈ la probabilité que v et u co-apparaissent lors d'une marche aléatoire\n",
      "  1. Estimer la probabilité P(v|u) avec une marche aléatoire fixe et limitée (courte)\n",
      "  2. Pour chaque nœud u, gardons N_R(u) l'ensemble des nœuds visités (avec répétitions)\n",
      "  3. Optimiser les embeddings pour encoder ces statistiques de marche aléatoire\n",
      "\n",
      "- On peut faire ceci simplement en minimisant le négatif des probabilités log (similaire à notre NLL):\n",
      "  L = ∑ ∑ -log(P(v|z_u))\n",
      "      u∈V v∈N_R(u)\n",
      "\n",
      "- On utilise les mêmes techniques: rétropropagation et gradient!\n",
      "\n",
      "## APPRENTISSAGE\n",
      "\n",
      "- Avec cette technique, ce sont vraiment les embeddings z ∈ Z que nous cherchons à trouver\n",
      "- Il faut initialiser z_u ∀u ∈ V avec des valeurs aléatoires (e.g. uniforme -1..1)\n",
      "- Ensuite, pour un certain nombre d'itérations ou jusqu'à convergence\n",
      "- Pour tout nœud u\n",
      "  - Nous calculons la dérivée partielle ∂L/∂z_u\n",
      "  - Faisons un pas opposé à la dérivée z_u = z_u - η ∂L/∂z_u\n",
      "\n",
      "- DeepWalk (2013): https://arxiv.org/abs/1403.6652\n",
      "\n",
      "## BIASED RANDOM WALK\n",
      "\n",
      "- On peut améliorer cette idée en ajoutant de l'échantillonnage et en biaisant la marche aléatoire\n",
      "- Il existe toutes sortes de stratégies pour trouver le voisinage des noeuds, mais regardons Node2Vec qui combine BFS et DFS\n",
      "- L'idée est d'avoir une bonne balance entre la vue locale et la vue globale du graphe\n",
      "  - Si limite à taille 3 N_BFS(u) = {s₁, s₂, s₃} alors que N_DFS(u) = {s₄, s₅, s₆}\n",
      "  - Les deux ont une vue limitée!\n",
      "- Avec Node2Vec, nous utilisons le paramètre de retour p pour revenir au nœud précédent\n",
      "  - Et le paramètre de ratio (BFS/DFS) q pour revenir vers le nœud précédent ou s'en éloigner\n",
      "\n",
      "## NODE2VEC\n",
      "\n",
      "- Ici on arrive de t vers v et le graphique montre les probabilités de transition vers chaque nœud voisin\n",
      "  - N_R(u) sont les nœuds visités par la marche biaisée\n",
      "  - Si p petit alors similaire à BFS\n",
      "  - Si q petit alors similaire à DFS\n",
      "\n",
      "[Image montrant l'algorithme Node2Vec et ses résultats comparés à d'autres méthodes]\n",
      "\n",
      "## [Image montrant le processus Node2Vec]\n",
      "\n",
      "- Dans l'implémentation, la partie Node2Vec sert à construire le dataset pour appliquer directement un Word2Vec\n",
      "- https://github.com/aditya-grover/node2vec\n",
      "\n",
      "## EN RÉSUMÉ\n",
      "\n",
      "- Idée principale : Représenter les noeuds de façon à ce que les distances dans l'espace vectoriel reflètent les similarités entre les noeuds dans le réseau d'origine\n",
      "- Différentes notions de similarité entre les noeuds :\n",
      "  - Naïve : Similaires si deux noeuds sont connectés\n",
      "  - Approches basées sur les marches aléatoires\n",
      "- Clustering: on applique notre algorithme favori sur les z_i ∈ Z\n",
      "- Classification de nœud: Entraîne un classeur à prédire l'étiquette du nœud i à partir de z_i en constituant un dataset X = [[z_i,1, z_i,2, ...][z_j,1, z_j,2, ...] ...] , y\n",
      "- Prédiction d'arête: prédire l'arête (i, j) à partir de (z_i, z_j )\n",
      "\n",
      "## GRAPHE EMBEDDING?\n",
      "\n",
      "- Comment peut-on directement faire un embedding pour des structures de graphes entiers?\n",
      "  - I.e.: Transformer le graphe G en z_G afin de faire des tâches liées à la structure\n",
      "  - E.g.: Classification de la toxicité des molécules\n",
      "- Méthodes naïves:\n",
      "  - Utilisation du node embedding et moyenne z_G = ∑_v∈G z_v\n",
      "  - Introduire un « nœud virtuel » pour représenter le (sous-)graphe et appliquer une technique standard d'embedding de graphe.\n",
      "\n",
      "DiffPool: clustering hiérarchique + avg des nodes embeddings\n",
      "\n",
      "## GRAPH NEURAL NETWORK\n",
      "\n",
      "Les embeddings creux comportent quelques limitations...\n",
      "Il faut O(|V|d) paramètres minimums et il n'y a aucun partage entre les noeuds; les nœuds ont nécessairement une représentation unique\n",
      "\n",
      "## LIMITES\n",
      "\n",
      "- Si le nœud 5 est ajouté suite à l'entraînement, nous ne pouvons pas trouver son embedding\n",
      "  - Très commun dans les problèmes réels\n",
      "  - E.g.: ajout d'un utilisateur dans un réseau social\n",
      "- Même si les nœuds 2 et 12 sont similaires structurellement, on ne capture pas cette information\n",
      "  - Ils ont des embeddings très différents\n",
      "- On ne peut pas exploiter les caractéristiques avec les méthodes vues\n",
      "  - Pas très pratique en machine learning!\n",
      "\n",
      "## PROPRIÉTÉ DÉSIRABLE\n",
      "\n",
      "- La représentation de graphes devrait être la même pour deux ordres de plan\n",
      "  - Réfère à l'ordre de visite des voisins\n",
      "  - Pour |V| nœuds, |V|! plans possibles\n",
      "- Si nous apprenons une fonction f qui associe un graphe G = (A, X) à un vecteur ℝ^d\n",
      "  - f(A₁, X₁) = f(A₂, X₂) - A et X sont généralement concaténés!\n",
      "  - X est la matrice de caractéristiques de nœuds\n",
      "  - A est la matrice d'adjacence vue précédemment\n",
      "\n",
      "[Image illustrant deux ordres de plan différents pour le même graphe]\n",
      "\n",
      "## ÉTAPES GÉNÉRIQUES\n",
      "\n",
      "[Image montrant le processus générique d'un GNN avec:\n",
      "1. Find graph structure\n",
      "2. Specify graph type and scale\n",
      "3. Design loss function\n",
      "4. Build model using computational modules]\n",
      "\n",
      "## INTUITION: AGRÉGATION DU VOISINAGE\n",
      "\n",
      "- Générer l'embedding à partir du voisinage local\n",
      "\n",
      "[Images illustrant le processus d'agrégation de voisinage pour générer les embeddings]\n",
      "\n",
      "## INTUITION: AGRÉGATION DU VOISINAGE\n",
      "\n",
      "[Image montrant comment chaque nœud définit un graphe de calcul selon son voisinage]\n",
      "\n",
      "Réseaux de neurones\n",
      "\n",
      "## INTUITION: AGRÉGATION DU VOISINAGE\n",
      "\n",
      "h_v^0 = x_v (Caractéristiques du nœud v)\n",
      "\n",
      "h_v^(k+1) = φ(W_k ∑_(u∈N(v)) h_u^(k)/|N(v)| + B_k h_v^(k)), ∀k ∈ {0, ..., K-1}\n",
      "\n",
      "z_v = h_v^(K) (Embedding après K couches d'agrégation de voisinage)\n",
      "\n",
      "- Activation non-linéaire\n",
      "- Matrices de poids\n",
      "- Moyenne des embeddings des voisins de la couche précédente (Permutation invariant)\n",
      "- Embedding du nœud à la couche k (pour l'auto-transformation)\n",
      "- Nombre total de couche\n",
      "\n",
      "## GNN INVARIANCE\n",
      "\n",
      "- Avec un nœud spécifique, on considère que les GNN sont invariables aux permutations\n",
      "\n",
      "[Image montrant un graphe avec ses nœuds et la notion de poids partagés]\n",
      "\n",
      "Poids partagés\n",
      "\n",
      "Moyenne des embeddings des voisins aux couches précédentes – invariable aux permutations\n",
      "\n",
      "## GNN ÉQUIVARIANCE\n",
      "\n",
      "- En considérant tous les nœuds, on dit qu'ils sont équivariant par permutation\n",
      "\n",
      "[Image montrant comment la permutation des entrées entraîne une permutation correspondante des sorties]\n",
      "\n",
      "## GNN ÉQUIVARIANCE\n",
      "\n",
      "1. Les lignes des caractéristiques d'entrée des nœuds et les embeddings de sortie sont alignés\n",
      "2. Nous savons que le calcul de l'embedding d'un nœud donné avec GNN est invariant\n",
      "3. Donc, après permutation, la position d'un nœud donné dans la matrice de caractéristiques d'entrée est modifiée, et l'embedding de sortie d'un nœud donné reste le même (les couleurs des caractéristiques du nœud et de l'embedding sont associées)\n",
      "\n",
      "- Attention! En pratique, ce n'est pas toujours strictement vrai dû à la dépendance des caractéristiques\n",
      "\n",
      "## CONVOLUTIONS\n",
      "\n",
      "- Un CNN peut être considéré comme un cas spécifique de GNN\n",
      "- Par exemple, une couche d'un CNN peut être formulé comme:\n",
      "  h_v^(l+1) = φ(∑_(u∈N(v)∪v) W_l^u h_u^(l))\n",
      "- Où N(v) représente les 8 pixels voisin de v pour une convolution 3 × 3\n",
      "- La différence clé est que le CNN a un voisinage de taille fixe et suit un ordre spécifique!\n",
      "- Le CNN n'est pas invariant/équivariant aux permutations!\n",
      "  - Changer l'ordre des voisins peut changer la sortie (avec raison)!\n",
      "\n",
      "## CONVOLUTIONS\n",
      "\n",
      "- Cependant, pour les cas spécifiques gérables par les CNN ne nous aident pas vraiment avec nos graphes pour les raisons évoquées en début de présentation\n",
      "- Ainsi, les GNN les plus communs utilisent leur propre version de l'opération de convolution\n",
      "  h_v^(k+1) = φ(W_k ∑_(u∈N(v)∪v) h_u^(k)/√(|N(u)||N(v)|))\n",
      "\n",
      "- ConvGNN pour classification de noeuds\n",
      "  - Chaque couche de conv, agrège l'information du voisinage\n",
      "  - La représentation finale contient de l'information des voisinages plus éloignés\n",
      "\n",
      "## EXEMPLE\n",
      "\n",
      "- L'ensemble de données Cora comprend des publications scientifiques classées sous 7 classes\n",
      "- Le graphe comprend 5429 arêtes liant les articles par leurs citations\n",
      "- Chaque nœud est une publication contenant des 0/1 pour la présence ou l'absence de chacun des 1433 mots uniques\n",
      "  - Il s'agit de la longueur du vecteur de caractéristiques!\n",
      "- Voir le code de GCN vanille\n",
      "\n",
      "## EXEMPLE\n",
      "\n",
      "- Ce GCN suppose qu'il n'y a pas de features sur les arêtes!\n",
      "- Il a features × units + bias poids\n",
      "- Soit 1433 × 16 + 16 = 22944 et 16 × 7 + 7 = 119\n",
      "\n",
      "[Code montrant l'implémentation d'un GCN pour le dataset Cora]\n",
      "\n",
      "## RETOUR À LA CONCEPTION\n",
      "\n",
      "## ENTRAÎNEMENT DES GNN\n",
      "\n",
      "- De façon supervisé, nous minimisons simplement ℒ(y, f_Θ(z_v))\n",
      "  - La perte peut être la SSE si y est continue\n",
      "  - Sinon la cross entropie si y est discret\n",
      "  - Θ représente la totalité des paramètres à apprendre\n",
      "\n",
      "Est-ce que le médicament est sécuritaire?\n",
      "\n",
      "ℒ = -∑_(v∈V) y_v log(σ(z_v^T θ)) + (1-y_v)log(1-σ(z_v^T θ))\n",
      "\n",
      "Node embedding                   Paramètres\n",
      "                                Classe du noeud\n",
      "\n",
      "## CONCEPTION\n",
      "\n",
      "- Nous avons vu rapidement tout à l'heure les principaux éléments pour la conception des GNN\n",
      "- En réalité, la clé et la variété se situe au niveau de l'agrégagion\n",
      "- On peut même dire que concrètement, c'est celle-ci qui fait d'un GNN un GNN!\n",
      "\n",
      "(1) Définir une fonction d'agrégation de voisinage\n",
      "(2) Choisir une fonction de perte sur les embeddings pour l'optimisation avec rétropropagation\n",
      "\n",
      "## CONCEPTION\n",
      "\n",
      "[Image montrant l'entraînement sur un batch de nœuds]\n",
      "\n",
      "(3) Entraînement sur une batch de noeuds\n",
      "\n",
      "- On construit dynamiquement les graphes de calcul des nœuds d'entraînement\n",
      "  - Ils sont hétérogènes!\n",
      "\n",
      "## CONCEPTION\n",
      "\n",
      "- De la même façon que pour les CNN et les RNN, les GNN partage leurs paramètres\n",
      "- Ce partage permet d'avoir des graphes de calcul hétérogènes et généré dynamiquement!\n",
      "- De plus, il permet de généraliser à des nouveaux nœuds !\n",
      "\n",
      "[Image montrant le partage de paramètres entre différents nœuds du graphe]\n",
      "\n",
      "## SAMPLING MODULE\n",
      "\n",
      "- Un inconvénient majeur de la plupart des architectures de GNN est leur évolutivité\n",
      "- En général, le vecteur de caractéristiques de chaque noeud dépend de l'intégralité de son voisinage\n",
      "- Cela peut s'avérer inefficace pour les graphes gigantesques avec des voisinages importants\n",
      "- Pour résoudre ce problème, des modules d'échantillonnage ont été intégrés\n",
      "- L'idée principale des modules d'échantillonnage est qu'au lieu d'utiliser toutes les informations de voisinage, on peut en échantillonner un sous-ensemble pour effectuer la propagation\n",
      "\n",
      "## EXEMPLE GRAPHSAGE\n",
      "\n",
      "- Un des premiers à introduire l'échantillonnage\n",
      "  - Implémenté sur Tensorflow avec Adam\n",
      "  - Testé sur le dataset Reddit (232 925 sujets avec un étiquette correspondant à 50 communautés et des liens entre les sujets si un user est en commun)\n",
      "\n",
      "[Image montrant le processus en 3 étapes: échantillonnage du voisinage, agrégation, prédiction]\n",
      "\n",
      "## EXEMPLE GRAPHSAGE\n",
      "\n",
      "- Le point délicat est que nous entraînons également la fonction d'agrégation en même temps que nos matrices de poids apprenables\n",
      "- Les auteurs ont expérimenté 3 fonctions d'agrégation différentes :\n",
      "  - un agrégateur de moyenne\n",
      "  - un agrégateur LSTM\n",
      "  - un agrégateur max pooling\n",
      "- Dans les 3 cas, les fonctions contiennent des paramètres appris qui sont optimisés pendant l'entraînement\n",
      "- De cette façon, le réseau apprendra lui-même la « bonne » manière d'agréger les caractéristiques des nœuds échantillonnés\n",
      "\n",
      "## EXEMPLE PINSAGE\n",
      "\n",
      "- PinSAGE effectue les conv sur l'échantillonnage du voisinage des nœuds et construit dynamiquement les réseaux\n",
      "- Exploite une architecture MapReduce pour distribuer le modèle entraîné afin de pouvoir générer des embeddings pour des milliards de nœuds\n",
      "- γ est une fonction de pooling d'importance\n",
      "\n",
      "[Image illustrant l'architecture PinSAGE]\n",
      "\n",
      "## POOLING OPERATOR\n",
      "\n",
      "- Les opérateurs de pooling dans les GNN (Graph Neural Networks) servent à résumer les informations d'un ensemble de nœuds voisins en une représentation plus concise\n",
      "- Ils sont intimement liés aux approches d'échantillonnage que nous venons de voir\n",
      "  - Souvent on ne fait la distinction que l'étape où c'est appliqué (avant ou après la conv)\n",
      "- Les opérateurs de pooling visent à réduire le nombre de voisins pris en compte en sélectionnant ou en résumant les informations d'un sous-ensemble de voisins échantillonnés\n",
      "- Après qu'un nœud a agrégé les messages de ses voisins, l'opérateur de pooling condense ces informations en une seule représentation\n",
      "  - C'est intuitivement la même chose que pour nos CNN!\n",
      "\n",
      "## POOLING OPERATOR\n",
      "\n",
      "- Dans les GNN, on parle souvent de passage de message\n",
      "- L'idée est qu'on part d'un ensemble d'embeddings de voisinage {h_v, ∀v ∈ N(u)}\n",
      "  - Le fait que ce soit un ensemble est important: il n'y a pas d'ordre!\n",
      "  - Donc, on maintient la contrainte d'être invariable aux permutations\n",
      "- Et nous voulons l'associer à un vecteur unique m_N(u)\n",
      "- Zaheer et al. (2017) a montré que m_N(u) = MLP_θ(∑_(v∈N(u)) MLP_φ(h_v)) est un approximateur universel d'ensemble pour les GNN\n",
      "- Cependant, en pratique, c'est lourd!\n",
      "  - De plus, on risque de tomber en surapprentissage si le MLP est profond\n",
      "  - Cette approche, de set pooling en pratique ne fait qu'ajouter une couche dense à l'agrégation\n",
      "\n",
      "## POOLING OPERATOR\n",
      "\n",
      "- Flat Pooling\n",
      "  - SumPool: des représentations de noeuds\n",
      "  - AvgPool: des représentations de nœuds\n",
      "  - Plus simple, plus rapide, mais perte d'information\n",
      "\n",
      "- Pooling hiérarchique\n",
      "  - Clustering (e.g. DiffPool, MemPool)\n",
      "  - Node Drop: supprime les nœuds avec un score de signification faible (e.g. AttPool, TopKPool)\n",
      "\n",
      "[Image illustrant différentes techniques de pooling dans les GNN]\n",
      "\n",
      "## SKIP-CONNECTION\n",
      "\n",
      "- Un des problèmes des GNN vient du fait que l'agrégation provoque un lissage excessif (over-smoothing)\n",
      "  - L'encodage dépend trop fortement de l'agrégation plutôt que de la représentation des nœuds aux couches précédentes\n",
      "  - Les nœuds deviennent trop similaires!\n",
      "- La skip-connection est conceptuellement similaire à nos modules résiduels\n",
      "- On peut simplement concaténer (GraphSAGE):\n",
      "  UPDATE_concat(h_v, m_N(v)) = [UPDATE_base(h_v, m_N(v))⊕h_v]\n",
      "- On peut aussi faire quelque chose de plus complexe tel que de l'interpolation:\n",
      "  UPDATE_interpolate(h_v, m_N(v)) = α₁ ∘ UPDATE_base(h_v, m_N(v)) + α₂⊙h_v],\n",
      "  α₁, α₂ ∈ [0,1]^d, α₂ = 1 - α₁\n",
      "- ∘ multiplication par élément\n",
      "\n",
      "## GNN ET SES TÂCHES\n",
      "\n",
      "[Image montrant différentes tâches possibles avec les GNN:\n",
      "- Node classification: Z_i = f(h_i)\n",
      "- Graph classification: Z_G = f(∑_i h_i)\n",
      "- Link classification: Z_ij = f(h_i, h_j, e_ij)]\n",
      "\n",
      "## DIVERSITÉ DES GNN\n",
      "\n",
      "[Image montrant un arbre de classification des différentes architectures GNN]\n",
      "\n",
      "- Comme vous pouvez voir, il existe maintenant une très grande diversité dans les GNN\n",
      "- On trouve des réseaux avec attention\n",
      "- Avec transformeurs\n",
      "- Diffusion, etc.\n",
      "- En fait, cette image résume un petit pourcentage des principaux GNN des 5-10 dernières années!\n",
      "\n",
      "## POUR ALLER PLUS LOIN...\n",
      "\n",
      "- Le cours de Standford CS224 est disponible en ligne gratuitement\n",
      "  - Il contient 19 séances de cours sur l'exploitation des graphes en apprentissage automatique avec emphase sur les GNN\n",
      "  - https://web.stanford.edu/class/cs224w/\n",
      "\n",
      "- Le livre\n",
      "  - Le cours CS224 se base principalement sur ce livre\n",
      "  - Il inclut des informations sur l'entraînement\n",
      "  - https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf\n",
      "\n",
      "- Autres bons liens:\n",
      "  - Architectures de GNN en résumé: https://theaisummer.com/gnn-architectures/\n",
      "  - Résumé des GNN: https://www.sciencedirect.com/science/article/pii/S2666651021000012\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Function to convert PDF to images and encode them\n",
    "def pdf_to_base64_images(pdf_path):\n",
    "    images = []\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    for page_number in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom for better resolution\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        \n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        img.save(buffered, format=\"PNG\")\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        \n",
    "        images.append(img_base64)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = \"data_pdf/Leçon #8 - Graph neural network.pdf\"\n",
    "base64_images = pdf_to_base64_images(pdf_path)\n",
    "\n",
    "# Create content list with all PDF pages as images\n",
    "content = [{\"type\": \"text\", \"text\": \"Tu es expert en deep learning.\\n\"\n",
    "    \"Voici un cours sur: Leçon #8 - Graph neural network.\\n\"\n",
    "    \"Il y a dans ce document des images explicatives et des formules mathématiques.\\n\"\n",
    "    \"Ton but est de faire un fichier texte qui redit exactement tout ce qui est expliqué dans ce \"\n",
    "    \"document en incluant les formules mathématiques et les explications que les images peuvent apporter.\\n\"}]\n",
    "\n",
    "# Add each page as an image\n",
    "for img_base64 in base64_images:\n",
    "    content.append({\n",
    "        \"type\": \"image\",\n",
    "        \"source\": {\n",
    "            \"type\": \"base64\",\n",
    "            \"media_type\": \"image/png\",\n",
    "            \"data\": img_base64\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Initialize Claude through LangChain\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens=9092\n",
    ")\n",
    "\n",
    "# Create a message with the PDF pages as images\n",
    "message = HumanMessage(content=content)\n",
    "\n",
    "# Get response\n",
    "response = llm.invoke([message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, UnstructuredMarkdownLoader\n",
    "# from langchain.schema import Document\n",
    "\n",
    "# def create_txt():\n",
    "#     loader = DirectoryLoader(\"./data_pdf\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "#     # loader = DirectoryLoader(\"./data_md\", glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader)\n",
    "#     # loader = DirectoryLoader(\"./data_txt\", glob=\"**/*.txt\")\n",
    "#     docs = loader.load()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bien sûr, voici le contenu textuel du cours sur les neurones artificiels, en incluant les formules et les explications des images.\n",
      "\n",
      "**NEURONES ARTIFICIELS**\n",
      "\n",
      "Par Kévin Bouchard Ph.D.\n",
      "Professeur titulaire en intelligence artificielle et apprentissage automatique\n",
      "Laboratoire d'Intelligence Ambiante pour la reconnaissance d'activités (LIARA)\n",
      "Directeur de l'Espace innovation en technologies numériques Hydro-Québec\n",
      "Président du Regroupement québécois des maladies orphelines (RQMO)\n",
      "Université du Québec à Chicoutimi\n",
      "www.kevin-bouchard.ca  Kevin_Bouchard@uqac.ca\n",
      "\n",
      "**CONTENU DE LA LEÇON #2**\n",
      "\n",
      "Vous apprendrez:\n",
      "* Comment fonctionne un seul neurone artificiel (ou réviserez)\n",
      "* Comment on entraîne un Adaline et le passage vers l'optimisation\n",
      "* Nous essaierons également de définir l'apprentissage profond comme un sous-domaine de l'intelligence artificielle\n",
      "\n",
      "Contenu spécifique:\n",
      "* Retour sur le Perceptron\n",
      "* Exercices\n",
      "* Adaline et le gradient\n",
      "* Retour sur Logistic Regression\n",
      "* Exemples de code\n",
      "\n",
      "**UN BREF HISTORIQUE DES PERCEPTRONS**\n",
      "\n",
      "* Retour en 1943: McCulloch & Pitts publient le *MCP Neuron*\n",
      "* *A logical Calculus of the Ideas Immanent in Nervous Activity*\n",
      "* Cellules nerveuses interconnectées\n",
      "* Transmettent des signaux électriques et chimiques\n",
      "* Simple porte logique!\n",
      "\n",
      "L'image montre une cellule nerveuse avec les éléments suivants:\n",
      "* Entrées (Dendrites)\n",
      "* Noyau\n",
      "* Axone\n",
      "* Gaine de Myéline\n",
      "* Termination Axonale\n",
      "* Sorties\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "* Rosenblatt 1957: Apprendre les poids optimaux à multiplier avec les entrées afin de déterminer si le neurone s'active ou non\n",
      "* Utile pour la classification binaire (ML supervisé)\n",
      "    * 1 positif\n",
      "    * -1 négatif\n",
      "* z est l'entrée nette composé d'une combinaison linéaire d'entrées x et de poids w (somme pondérée)\n",
      "\n",
      "Formule:\n",
      "\n",
      "w =  [w1, w2, ..., wm]^T  x = [x1, x2, ..., xm]^T  z = w1x1 + ... + wmxm\n",
      "\n",
      "Fonction d'activation:\n",
      "\n",
      "Φ(z) = 1 si z >= θ\n",
      "        -1 sinon\n",
      "\n",
      "* La classification se définie par une fonction d'activation φ(z) avec un threshold θ\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "* x représente l'entrée\n",
      "* Grosso modo, l'instance avec ses m features\n",
      "* Il peut s'agir d'une instance d'apprentissage ou d'une instance à classer\n",
      "* La classe est déterminée en fonction de ce qu'on appelle une fonction d'activation\n",
      "* La fonction d'activation du Perceptron s'appelle Heaviside ou encore fonction par palier (step-wise function)\n",
      "* Elle est représentée par φ( ) et prend z en entrée avec un seuil θ\n",
      "\n",
      "Formule:\n",
      "\n",
      "w =  [w1, w2, ..., wm]^T  x = [x1, x2, ..., xm]^T  z = w1x1 + ... + wmxm\n",
      "\n",
      "Fonction d'activation:\n",
      "\n",
      "Φ(z) = 1 si z >= θ\n",
      "        -1 sinon\n",
      "\n",
      "L'image montre la fonction de Heaviside:\n",
      "* Sur l'axe des x, on a z.\n",
      "* Sur l'axe des y, on a φ(z).\n",
      "* φ(z) = -1 pour z < 0\n",
      "* φ(z) = 1 pour z >= 0\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "* L'équation peut être écrite plus simplement apprendre le seuil θ comme un paramètre supplémentaire\n",
      "* Pour ce faire, nous définissons un paramètre w0 = θ avec une caractéristique fictive x0 = 1\n",
      "\n",
      "Formule:\n",
      "\n",
      "z = w0x0 + w1x1 + ... + wmxm = w^T x = ∑(de j=0 à m) wjXj = w^T x\n",
      "\n",
      "* T est ajouté dans la forme vectorielle pour signifier transposé\n",
      "* E.g.: z = [1 2 3] * [4 5 6] = 1 * 4 + 2 * 5 + 3 * 6 = 32\n",
      "* Note: w0 est ce qu'on appelle le biais\n",
      "\n",
      "**PERCEPTRON**\n",
      "\n",
      "L'image montre la fonction d'activation φ(w^T x) qui donne 1 si w^T x >= 0 et -1 sinon.\n",
      "\n",
      "L'image montre un plan avec deux classes:\n",
      "* Les points rouges sont séparés des croix bleues par une ligne droite.\n",
      "* Les points rouges sont du côté où φ(w^T x) < 0.\n",
      "* Les croix bleues sont du côté où φ(w^T x) >= 0.\n",
      "\n",
      "**FONCTIONNEMENT DE L'APPRENTISSAGE**\n",
      "\n",
      "1. Initialisation des poids à 0 (ou un petit nombre aléatoire)\n",
      "2. Tant qu'il y a des mauvaises classifications:\n",
      "    1. Pour chaque exemple d'entraînement x^(i):\n",
      "        1. Classer x^(i) avec les modèles courant pour obtenir la sortie estimée ŷ^(i)\n",
      "        2. Mettre à jour les poids\n",
      "\n",
      "* La mise à jour des poids wj ∈ w est wj = wj + Δwj\n",
      "* Δwj calculé selon la règle d'apprentissage du perceptron:\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δwj = η(y^(i) - ŷ^(i))x^(i)j\n",
      "\n",
      "* η est le fameux « Learning rate » dans l'intervalle [0.0, 1.0]\n",
      "\n",
      "**FONCTIONNEMENT DE L'APPRENTISSAGE**\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δwj = η(y^(i) - ŷ^(i))x^(i)j\n",
      "\n",
      "* Exemples:\n",
      "    * Δw1 = 1(1 - 1) * 1 = 0  Prédiction positive correcte!\n",
      "    * Δw1 = 1(-1 - (-1)) * 1 = 0  Prédiction négative correcte!\n",
      "    * Δw1 = 1(1 - (-1)) * 4 = 8\n",
      "    * Δw1 = 1(-1 - 1) * 0.5 = -1\n",
      "    * Δw1 = 0.1(1 - (-1)) * 4 = 0.8\n",
      "\n",
      "* Le poids ne changera pas si la prédiction est correcte!\n",
      "* Il varie autrement en fonction de la valeur de x^(i)j dans le vecteur d'entraînement i\n",
      "\n",
      "**BILAN**\n",
      "\n",
      "* Si pas séparable linéairement, Perceptron MàJ à l'infini\n",
      "* Nombre max de passes à travers l'ensemble (epochs)\n",
      "\n",
      "L'image montre trois cas:\n",
      "* Linearly separable: les deux classes peuvent être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "\n",
      "L'image montre le fonctionnement d'un perceptron:\n",
      "* Entrées: 1, x1, x2, ..., xm\n",
      "* Poids: w0, w1, w2, ..., wm\n",
      "* Net input function: ∑ (somme pondérée des entrées et des poids)\n",
      "* Activation function: Heaviside\n",
      "* Output\n",
      "\n",
      "**BILAN**\n",
      "\n",
      "* Dans l'ensemble, le perceptron original met en place les principaux éléments des réseaux de neurones\n",
      "* Le perceptron est un modèle linéaire\n",
      "* Si pas séparable linéairement, Perceptron MàJ à l'infini\n",
      "* Nombre max de passes à travers l'ensemble (epochs)\n",
      "\n",
      "L'image montre trois cas:\n",
      "* Linearly separable: les deux classes peuvent être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "* Not linearly separable: les deux classes ne peuvent pas être séparées par une ligne droite.\n",
      "\n",
      "L'image montre le fonctionnement d'un perceptron:\n",
      "* Entrées: 1, x1, x2, ..., xm\n",
      "* Poids: w0, w1, w2, ..., wm\n",
      "* Net input function: ∑ (somme pondérée des entrées et des poids)\n",
      "* Activation function: Heaviside\n",
      "* Output\n",
      "\n",
      "**EXERCICES**\n",
      "\n",
      "* Faisons des entraînements de Perceptron ensemble\n",
      "* Supposons un Perceptron entraîné sur l'ensemble des Iris\n",
      "* Poids: [-0.311, -3.091, 3.443, -3.292]\n",
      "* Biais: -1.0\n",
      "* Tentez le calcul avec les instances suivantes (et votre ordinateur!!)\n",
      "* Instance Versicolor: [0.311, -0.592, 0.535, 0.001]\n",
      "* Instance Virginica: [-0.174, 1.71, -1.17, -1.184]\n",
      "* z = -1 + 0.311 * 0.311 - 3.091 * -0.592 + 3.443 * 0.535 + 0.001 * -3.292 = 2.572\n",
      "* z = -1 - 0.311 * -0.174 - 3.091 * 1.71 + 3.443 * -1.17 - 3.292 * -1.184 = -6.362\n",
      "\n",
      "**EXEMPLE AVEC LES IRIS**\n",
      "\n",
      "* À partir du code, voici un moment spécifique dans l'exécution\n",
      "* Modèle actuel: [ 0. -0.24 0.14 -0.7 -0.3 ]\n",
      "* Fleur: [4.6 3.1 1.5 0.2] Type: Iris-setosa\n",
      "* z = 0.0 * 1 + [ -0.24 0.14 -0.7 -0.3 ] * [4.6 3.1 1.5 0.2] = -1.78\n",
      "* Update = 0.1 * ( 1 - (-1) ) = 0.2\n",
      "* Poids MàJ: [ -0.24 0.14 -0.7 -0.3 ] + [4.6 3.1 1.5 0.2] * 0.2 = [ 0.68 0.76 -0.4 -0.26 ]\n",
      "* On voit le calcul de l'entrée nette (en prenant le biais)\n",
      "* Le calcul de la mise à jour\n",
      "* La mise à jour elle-même\n",
      "\n",
      "**ONE-VS-ALL**\n",
      "\n",
      "* Les algorithmes de classification binaires tel que le perceptron peuvent être étendu aux problèmes multi classes par diverses stratégies\n",
      "* Le *One-vs-All* consiste à créer un classeur par classe où toute autre instance est considérée de classe négative\n",
      "* La classification consiste ensuite à passer un nouvel exemple dans tous les classeurs de façon à trouver celui qui se déclenche\n",
      "* Attention! En général, on préfère plutôt avoir une sortie en termes de niveau de confiance où l'on cherche le max\n",
      "* Difficile avec des données mal balancées\n",
      "* Difficile de s'assurer que la gamme de niveaux de confiance ne varie pas trop d'un classeur à l'autre\n",
      "\n",
      "**ONE-VS-ONE**\n",
      "\n",
      "* Il existe une autre stratégie populaire pour d'autres types de classeurs qui ne sont pas multiclasses par défaut\n",
      "* Le One-vs-One est une des stratégies populaires utilisées dans Scikit-Learn\n",
      "* Un classeur par pair de classe\n",
      "* Vote sur la totalité des classeurs\n",
      "* Le vote se fait sur l'entièreté des Tc =  c(c-1)/2 classeurs\n",
      "* E.g.: pour 10 classes => 10(10 - 1)/2 = 45 classeurs\n",
      "* Scikit-Learn explique de long en large les stratégies implémentées selon l'algorithme:\n",
      "* https://scikit-learn.org/stable/modules/multiclass.html\n",
      "\n",
      "**ADAPTIVE LINEAR NEURONS**\n",
      "\n",
      "Adaline: Un autre type de NN simple couche\n",
      "-MàJ des poids selon une fonction d'activation linéaire!\n",
      "\n",
      "**ADALINE**\n",
      "\n",
      "L'image montre le fonctionnement d'un Adaline:\n",
      "* Entrées: 1, x1, x2, ..., xm\n",
      "* Poids: w0, w1, w2, ..., wm\n",
      "* Net input function: ∑ (somme pondérée des entrées et des poids)\n",
      "* Activation function: Identité (linéaire)\n",
      "* Quantizer: Heaviside\n",
      "* Output\n",
      "\n",
      "* La fonction d'activation linéaire φ(z) est simplement la fonction d'identité de l'entrée nette φ(w^T x) = w^T x\n",
      "* Elle sert à mettre à jour les poids\n",
      "* Cependant, un élément similaire à la fonction Heaviside parfois nommé « Quantizer » permet la prédiction de la classe\n",
      "* Les sorties sont des valeurs *continues!* (plutôt que binaires)\n",
      "\n",
      "**FONCTION DE COÛTS**\n",
      "\n",
      "* Clé en ML: optimisation d'une fonction objective (souvent *cost* ou *loss function*)\n",
      "* Ceci n'est pas un cours d'optimisation, mais nous devrons comprendre quelques éléments\n",
      "* Pour Adaline, fonction de coûts à minimiser\n",
      "* Apprendre les poids en tant que *Sum of Squared Errors* (SSE) entre les sorties et les vraies classes\n",
      "\n",
      "Formule:\n",
      "\n",
      "J(w) = 1/2 ∑ (y^(i) - φ(z^(i)))^2\n",
      "\n",
      "*Le ½ est ajouté pour faciliter le calcul du gradient (1/n classes)\n",
      "\n",
      "**ALGORITHME DU GRADIENT**\n",
      "\n",
      "* Puisque J(w) est une fonction convexe, nous pouvons faire l'optimisation grâce à l'algorithme *gradient descent*.\n",
      "* Regarde la « pente » des états voisins\n",
      "* Bouge dans la direction la plus abrupte\n",
      "* Trouvée par la dérivée partielle (voir diapo 15)\n",
      "* Learning rule: w := w + Δw\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δwj = -η ∂J/∂wj = η ∑ (y^(i) - φ(z^(i))) xj^(i)\n",
      "\n",
      "L'image montre un algorithme de Hill-climbing:\n",
      "* Exploration locale\n",
      "* G(n) (cost) de chaque voisin\n",
      "* On choisit le voisin qui améliore le plus\n",
      "\n",
      "**ALGORITHME DU GRADIENT**\n",
      "\n",
      "* La dérivée d'une fonction mesure comment elle change à un point donné\n",
      "* Elle quantifie le *taux de variation* de la fonction par rapport à une ou plusieurs variables\n",
      "* La dérivée de f(x) à un point spécifique x = a est directement la pente de la tangente à ce point (taux de variation instantané)\n",
      "\n",
      "Formule:\n",
      "\n",
      "f'(a) = lim(h->0) (f(a + h) - f(a))/h\n",
      "\n",
      "* Par exemple, si f(x) = 3x^2 + 4x et x = 1, alors pour h vers 0 nous aurons ≈ 2\n",
      "* E.g. h = 0.1, f'(1) = 2.3 mais h = 0.00001, f'(1) = 2.00003\n",
      "\n",
      "**POURQUOI EST-CE PERTINENT?**\n",
      "\n",
      "L'image montre une courbe de coût J(w) en fonction du poids w. On voit un point de départ (initial weight) et le gradient qui pointe vers le minimum global (Global cost minimum).\n",
      "\n",
      "* La différentiation peut nous dire comment varier les paramètres d'une fonction\n",
      "* Évidemment, nos fonctions sont plus complexes, car elles contiennent |w| paramètres\n",
      "* Le gradient d'une fonction f(x1, x2, ..., xn) est un *vecteur* qui contient les *dérivées partielles* de f par rapport à chacune des variables xi\n",
      "\n",
      "Formule:\n",
      "\n",
      "∇f = (∂f/∂x1, ∂f/∂x2, ..., ∂f/∂xn)\n",
      "\n",
      "* Par exemple, pour f(x,y) = x^2 + y^2 le gradient serait le vecteur ∇f = [2x, 2y]\n",
      "* Bref, le gradient de notre fonction de coûts est le vecteur de taille |w|\n",
      "* Donc, w := w + Δw\n",
      "\n",
      "**DÉRIVÉE PARTIELLE DE SSE**\n",
      "\n",
      "Formule:\n",
      "\n",
      "J(w) = 1/2 ∑ (y^(i) - φ(z^(i)))^2\n",
      "\n",
      "* Pour trouver la dérivée partielle ∂J/∂wj (comment J change en fonction du poids)\n",
      "* On applique la règle de la chaîne pour le terme au carré:\n",
      "\n",
      "∂J/∂wj (y^(i) - φ(z^(i)))^2 = 2(y^(i) - φ(z^(i))) * ∂J/∂wj (y^(i) - φ(z^(i)))\n",
      "\n",
      "∂J/∂wj = 1/2 ∑ 2(y^(i) - φ(z^(i))) * ∂J/∂wj (y^(i) - φ(z^(i)))\n",
      "\n",
      "* De plus le 2 annule le ½\n",
      "\n",
      "∂J/∂wj = ∑ (y^(i) - φ(z^(i))) * ∂J/∂wj (y^(i) - φ(z^(i)))\n",
      "\n",
      "**DÉRIVÉE PARTIELLE DE SSE**\n",
      "\n",
      "Formule:\n",
      "\n",
      "J(w) = 1/2 ∑ (y^(i) - φ(z^(i)))^2\n",
      "\n",
      "* La fonction φ(z^(i)) peut être remplacée par la somme pour toutes les instances\n",
      "\n",
      "∂J/∂wj = ∑ (y^(i) - φ(z^(i))) ∂/∂wj (y^(i) - ∑ xj^(i))\n",
      "\n",
      "* Comme y^(i) est une constante, nous cherchons plutôt ∂/∂wj φ(z^(i))\n",
      "\n",
      "∂φ(z^(i))/∂wj = φ'(z^(i)) * ∂z^(i)/∂wj\n",
      "\n",
      "* Puisque z^(i) = ∑ wj xj^(i), alors ∂φ(z^(i))/∂wj = xj^(i)\n",
      "\n",
      "∂J/∂wj = ∑ (y^(i) - φ(z^(i))) (-xj^(i)) = -∑ (y^(i) - φ(z^(i)))xj^(i)\n",
      "\n",
      "**RETOUR AU GRADIENT**\n",
      "\n",
      "* Bref nous avons maintenant: ∂J/∂wj = -∑ (y^(i) - φ(z^(i)))xj^(i)\n",
      "* Nous avons dit précédemment que la mise à jour des poids Δw = -η ∂J/∂wj\n",
      "* Donc ultimement, si vous souhaitez implémenter Adaline avec le gradient:\n",
      "\n",
      "Formule:\n",
      "\n",
      "Δw = η ∑ (y^(i) - φ(z^(i)))xj^(i)\n",
      "\n",
      "* En code c'est encore plus simple:\n",
      "\n",
      "output = self.activation(X)\n",
      "errors = (y - output)\n",
      "self.w_[1:] += self.eta * X.T.dot(errors)\n",
      "self.w_[0] += self.eta * errors.sum()\n",
      "\n",
      "**EXPLICATION DU CODE**\n",
      "\n",
      "output = self.activation(X)\n",
      "\n",
      "* Calcul l'entrée nette pour chaque instance\n",
      "\n",
      "errors = (y - output)\n",
      "\n",
      "* Deux vecteurs de la taille du dataset\n",
      "* Donne en retour un vecteur d'erreurs de la même taille où chaque vraie classe se voit soustraire l'entrée\n",
      "* E.g. y=1, z=0.234 alors 1-0.234\n",
      "\n",
      "self.w_[1:] += self.eta * X.T.dot(errors)\n",
      "\n",
      "* On multiplie le learning rate avec X\n",
      "* X est un tableau de dimension instances par features\n",
      "* .T transpose X afin de pouvoir le multiplier par notre vecteur d'erreurs\n",
      "* Ça donne un vecteur de taille features, soit 1 élément par w!!\n",
      "\n",
      "self.w_[0] += self.eta * errors.sum()\n",
      "\n",
      "* Fait la somme des erreurs * le learning rate et l'addition au biais\n",
      "\n",
      "**PRODUIT CROISÉ (DOT) - RAPPEL**\n",
      "\n",
      "* Attention! Cette ligne ne donne pas la même chose:  X.*errors\n",
      "* On multiplie chaque élément du vecteur par les éléments de la matrice et on reste en instances x features!!\n",
      "* Tandis que le produit croisé change la dimension\n",
      "* Si X ∈ R^(nxf) et errors ∈ R^n alors X^T e:\n",
      "\n",
      "Formule:\n",
      "\n",
      "X^T e = [∑(i=1 à n) x1,i ei, ∑(i=1 à n) x2,i ei, ..., ∑(i=1 à n) xf,i ei]\n",
      "\n",
      "**GRADIENT**\n",
      "\n",
      "*Haut: Visualisation de l'algorithme du gradient à 1 paramètre\n",
      "*Bas: SSE en fonction des epochs\n",
      "\n",
      "L'image du haut montre la fonction de coût en fonction d'un paramètre, avec le gradient et la dérivée qui convergent vers le minimum.\n",
      "\n",
      "L'image du milieu montre des données labellisées et la sortie du modèle.\n",
      "\n",
      "L'image du bas montre la somme des erreurs au carré (Sum-squared-error) en fonction du nombre d'epochs. On voit que l'erreur diminue au fur et à mesure que le nombre d'epochs augmente.\n",
      "\n",
      "**RÉSUMÉ**\n",
      "\n",
      "* Même si la règle d'apprentissage φ(z^(i)) ressemble à celle du perceptron, z^(i) = w^T x est un nombre réel\n",
      "* Dans le perceptron, c'est en entier naturel de classe 1 ou -1\n",
      "* Enfin, la MàJ des poids se fait sur le dataset en entier!\n",
      "* Dans le perceptron, c'est plutôt incrémental (instance par instance)\n",
      "* L'algorithme du gradient bénéficie du *feature scaling*\n",
      "* Le calcul est plus rapide!!\n",
      "* sklearn.preprocessing.scale (standardisation)\n",
      "* Sinon avec un tenseur Torch:\n",
      "\n",
      "data = torch.tensor([[1.0, 2.0, 5.0], [4.0, 5.0, 6.0]])\n",
      "means = data.mean(dim=0, keepdim=True)\n",
      "stds = data.std(dim=0, keepdim=True)\n",
      "normalized_data = (data - means) / stds\n",
      "\n",
      "**ALLER UN PEU PLUS LOIN...**\n",
      "\n",
      "**HYPERPARAMÈTRES**\n",
      "\n",
      "* η, le « Learning rate » et le nombre d'« epochs » sont ce qu'on appelle des hyperparamètres\n",
      "* Il n'y a pas de valeurs parfaites\n",
      "* Un learning rate trop haut peut empêcher de converger\n",
      "* Un learning rate trop faible fera tourner l'algorithme longtemps (besoin de rouler un grand nombre d'\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import mimetypes\n",
    "import fitz  # PyMuPDF for PDF to image conversion\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Function to convert PDF to images and encode them\n",
    "def pdf_to_base64_images(pdf_path):  # Limit pages to avoid context limits\n",
    "    images = []\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Limit number of pages if PDF is too long\n",
    "    num_pages = len(pdf_document)\n",
    "    \n",
    "    for page_number in range(num_pages):\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # Higher resolution\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        \n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        img.save(buffered, format=\"JPEG\", quality=85)  # JPEG for better compatibility\n",
    "        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "        \n",
    "        images.append(img_base64)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = \"data_pdf/Leçon #8 - Graph neural network.pdf\"\n",
    "base64_images = pdf_to_base64_images(pdf_path)\n",
    "\n",
    "# Initialize Gemini through LangChain\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"models/gemini-2.0-flash\",\n",
    "    max_tokens=5120\n",
    "\n",
    ")\n",
    "\n",
    "# Build content with all PDF pages as images\n",
    "content = []\n",
    "content.append({\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"Tu es expert en deep learning.\\n\"\n",
    "            \"Voici un cours sur: Leçon #8 - Graph neural network.\\n\"\n",
    "            \"Il y a dans ce document des images explicatives et des formules mathématiques.\\n\"\n",
    "            \"Ton but est de faire un fichier texte qui redit exactement tout ce qui est expliqué dans ce \"\n",
    "            \"document en incluant les formules mathématiques et les explications que les images peuvent apporter.\\n\"\n",
    "})\n",
    "\n",
    "# Add each page as an image\n",
    "for img_base64 in base64_images:\n",
    "    content.append({\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{img_base64}\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "# Create a message with the PDF pages as images\n",
    "message = HumanMessage(content=content)\n",
    "\n",
    "# Get response\n",
    "response = llm.invoke([message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_cerebras import ChatCerebras\n",
    "from langchain_xai import ChatXAI\n",
    "\n",
    "llm1 = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm2 = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm3 = ChatGoogleGenerativeAI(model=\"models/gemini-2.0-flash\")\n",
    "llm4 = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "llm5 = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "llm6 = ChatCerebras(model=\"llama-3.3-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Any, List\n",
    "from langchain_text_splitters import TextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "class GPTSplitter(TextSplitter):\n",
    "    def __init__(self, model_name: str = \"gpt-4o-mini\", **kwargs: Any) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = ChatOpenAI(model=model_name)\n",
    "        # self.model = llm5\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_template(\n",
    "            \"You are an expert in identifying semantic meaning of text. \"\n",
    "            \"You wrap each chunk in <<<>>>.\\n\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Text: \\\"The curious cat perched on the windowsill, its eyes wide as it watched the fluttering birds outside. \"\n",
    "            \"With a swift leap, it was on the ground, stealthily making its way towards the door. \"\n",
    "            \"Suddenly, a noise startled it, causing the cat to freeze in place.\\\"\\n\"\n",
    "            \"Wrapped:\\n\"\n",
    "            \"<<<The curious cat perched on the windowsill, its eyes wide as it watched the fluttering birds outside.>>>\\n\"\n",
    "            \"<<<With a swift leap, it was on the ground, stealthily making its way towards the door.>>>\\n\"\n",
    "            \"<<<Suddenly, a noise startled it, causing the cat to freeze in place.>>>\\n\\n\"\n",
    "            \"Now, process the following text:\\n\\n\"\n",
    "            \"{text}\"\n",
    "        )\n",
    "        self.output_parser = StrOutputParser()\n",
    "        self.chain = (\n",
    "            {\"text\": RunnablePassthrough()}\n",
    "            | self.prompt\n",
    "            | self.model\n",
    "            | self.output_parser\n",
    "        )\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        response = self.chain.invoke({\"text\": text})\n",
    "        # Use regex to split properly by <<< and >>> markers\n",
    "        chunks = re.findall(r'<<<(.*?)>>>', response, re.DOTALL)\n",
    "        return [chunk.strip() for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"unstructured[md]\" nltk\n",
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, UnstructuredMarkdownLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Spécifier explicitement PyPDFLoader pour les fichiers PDF\n",
    "# loader = DirectoryLoader(\"./data_pdf\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "# loader = DirectoryLoader(\"./data_md\", glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader)\n",
    "loader = DirectoryLoader(\"./data_txt\", glob=\"**/*.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# raw_data = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "gpt_splitter = GPTSplitter()\n",
    "gpt_docs = gpt_splitter.split_text(docs)\n",
    "chunks = [Document(page_content=chunk, metadata={'source': 'data_txt/deeplearning.txt'}) for chunk in gpt_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='State of the art pour les problèmes exploitant des données complexes (images, voix, textes)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "# from langchain_community.document_loaders.directory import DirectoryLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# loader = DirectoryLoader(\"./data\", glob=\"**/*.pdf\")\n",
    "# docs = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=120,\n",
    "#     chunk_overlap=20,\n",
    "#     length_function=len,\n",
    "#     is_separator_regex=False,\n",
    "# )\n",
    "# chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1536)\n",
    "\n",
    "db = Chroma.from_documents(chunks, embedding_function)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_cerebras import ChatCerebras\n",
    "\n",
    "llm1 = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm2 = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm3 = ChatGoogleGenerativeAI(model=\"models/gemini-2.0-flash\")\n",
    "llm4 = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "llm5 = ChatCerebras(model=\"llama-3.3-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(llm1.invoke(\"describe me in details what is a graph neural network\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context and the Chathistory. Especially take the latest question\n",
    "\n",
    "Chathistory: {chat_history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    documents: List[Document]\n",
    "    on_topic: str\n",
    "    rephrased_question: str\n",
    "    proceed_to_generate: bool\n",
    "    rephrase_count: int\n",
    "    question: HumanMessage\n",
    "\n",
    "\n",
    "def question_rewriter(state: AgentState):\n",
    "    print(f\"Entering question_rewriter with following state: {state}\")\n",
    "\n",
    "    # Reset state variables except for 'question' and 'messages'\n",
    "    state[\"documents\"] = []\n",
    "    state[\"on_topic\"] = \"\"\n",
    "    state[\"rephrased_question\"] = \"\"\n",
    "    state[\"proceed_to_generate\"] = False\n",
    "    state[\"rephrase_count\"] = 0\n",
    "\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "\n",
    "    if state[\"question\"] not in state[\"messages\"]:\n",
    "        state[\"messages\"].append(state[\"question\"])\n",
    "\n",
    "    if len(state[\"messages\"]) > 1:\n",
    "        conversation = state[\"messages\"][:-1]\n",
    "        current_question = state[\"question\"].content\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=\"You are a helpful assistant that rephrases the user's question to be a standalone question optimized for retrieval. And give just this rephrased question as answer.\"\n",
    "            )\n",
    "        ]\n",
    "        messages.extend(conversation)\n",
    "        messages.append(HumanMessage(content=current_question))\n",
    "        rephrase_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        prompt = rephrase_prompt.format()\n",
    "        response = llm1.invoke(prompt)\n",
    "        better_question = response.content.strip()\n",
    "        print(f\"question_rewriter: Rephrased question: {better_question}\")\n",
    "        state[\"rephrased_question\"] = better_question\n",
    "    else:\n",
    "        state[\"rephrased_question\"] = state[\"question\"].content\n",
    "    return state\n",
    "\n",
    "\n",
    "class GradeQuestion(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Question is about the specified topics? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "def question_classifier(state: AgentState):\n",
    "    print(\"Entering question_classifier\")\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are a classifier that determines whether a user's question is about one of the following topics:\n",
    "\n",
    "        1. Information about Deep Learning.\n",
    "        2. Information about Artificial Neurons.\n",
    "        3. Information about Convolutional Neural Networks\n",
    "        4. Information about Recurrent Neural Networks\n",
    "        5. Information about Autoencoders\n",
    "        6. Information about General Adversarial Networks\n",
    "        7. Information about Graphs neural networks\n",
    "\n",
    "        If the question IS about any of these topics, respond with 'Yes'. Otherwise, respond with 'No'.\"\"\"\n",
    "    )\n",
    "\n",
    "    human_message = HumanMessage(\n",
    "        content=f\"User question: {state['rephrased_question']}\"\n",
    "    )\n",
    "    # print(f\"question_classifier: Human message: {ChatPromptTemplate.from_messages(human_message)}\")\n",
    "    grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm1.with_structured_output(GradeQuestion)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "    result = grader_llm.invoke({})\n",
    "    state[\"on_topic\"] = result.score.strip()\n",
    "    print(f\"question_classifier: on_topic = {state['on_topic']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def on_topic_router(state: AgentState):\n",
    "    print(\"Entering on_topic_router\")\n",
    "    on_topic = state.get(\"on_topic\", \"\").strip().lower()\n",
    "    if on_topic == \"yes\":\n",
    "        print(\"Routing to retrieve\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(\"Routing to off_topic_response\")\n",
    "        return \"off_topic_response\"\n",
    "\n",
    "\n",
    "def retrieve(state: AgentState):\n",
    "    print(\"Entering retrieve\")\n",
    "    documents = retriever.invoke(state[\"rephrased_question\"])\n",
    "    print(f\"retrieve: Retrieved {len(documents)} documents\")\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "\n",
    "class GradeDocument(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Document is relevant to the question? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "\n",
    "def retrieval_grader(state: AgentState):\n",
    "    print(\"Entering retrieval_grader\")\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are a grader assessing the relevance of a retrieved document to a user question.\n",
    "Only answer with 'Yes' or 'No'.\n",
    "\n",
    "If the document contains information relevant to the user's question, respond with 'Yes'.\n",
    "Otherwise, respond with 'No'.\"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm1.with_structured_output(GradeDocument)\n",
    "\n",
    "    relevant_docs = []\n",
    "    for doc in state[\"documents\"]:\n",
    "        human_message = HumanMessage(\n",
    "            content=f\"User question: {state['rephrased_question']}\\n\\nRetrieved document:\\n{doc.page_content}\"\n",
    "        )\n",
    "        grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "        grader_llm = grade_prompt | structured_llm\n",
    "        result = grader_llm.invoke({})\n",
    "        print(\n",
    "            f\"Grading document: {doc.page_content[:30]}... Result: {result.score.strip()}\"\n",
    "        )\n",
    "        if result.score.strip().lower() == \"yes\":\n",
    "            relevant_docs.append(doc)\n",
    "    state[\"documents\"] = relevant_docs\n",
    "    state[\"proceed_to_generate\"] = len(relevant_docs) > 0\n",
    "    print(f\"retrieval_grader: proceed_to_generate = {state['proceed_to_generate']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def proceed_router(state: AgentState):\n",
    "    print(\"Entering proceed_router\")\n",
    "    rephrase_count = state.get(\"rephrase_count\", 0)\n",
    "    if state.get(\"proceed_to_generate\", False):\n",
    "        print(\"Routing to generate_answer\")\n",
    "        return \"generate_answer\"\n",
    "    elif rephrase_count >= 2:\n",
    "        print(\"Maximum rephrase attempts reached. Cannot find relevant documents.\")\n",
    "        return \"cannot_answer\"\n",
    "    else:\n",
    "        print(\"Routing to refine_question\")\n",
    "        return \"refine_question\"\n",
    "\n",
    "\n",
    "def refine_question(state: AgentState):\n",
    "    print(\"Entering refine_question\")\n",
    "    rephrase_count = state.get(\"rephrase_count\", 0)\n",
    "    if rephrase_count >= 2:\n",
    "        print(\"Maximum rephrase attempts reached\")\n",
    "        return state\n",
    "    question_to_refine = state[\"rephrased_question\"]\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are a helpful assistant that slightly refines the user's question to improve retrieval results.\n",
    "Provide a slightly adjusted version of the question.\"\"\"\n",
    "    )\n",
    "    human_message = HumanMessage(\n",
    "        content=f\"Original question: {question_to_refine}\\n\\nProvide a slightly refined question.\"\n",
    "    )\n",
    "    refine_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    prompt = refine_prompt.format()\n",
    "    response = llm1.invoke(prompt)\n",
    "    refined_question = response.content.strip()\n",
    "    print(f\"refine_question: Refined question: {refined_question}\")\n",
    "    state[\"rephrased_question\"] = refined_question\n",
    "    state[\"rephrase_count\"] = rephrase_count + 1\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_answer(state: AgentState):\n",
    "    print(\"Entering generate_answer\")\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        raise ValueError(\"State must include 'messages' before generating an answer.\")\n",
    "\n",
    "    chat_history = state[\"messages\"]\n",
    "    documents = state[\"documents\"]\n",
    "    rephrased_question = state[\"rephrased_question\"]\n",
    "\n",
    "    response = rag_chain.invoke(\n",
    "        {\"chat_history\": chat_history, \"context\": documents, \"question\": rephrased_question}\n",
    "    )\n",
    "\n",
    "    generation = response.content.strip()\n",
    "\n",
    "    state[\"messages\"].append(AIMessage(content=generation))\n",
    "    print(f\"generate_answer: Generated response: {generation}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def cannot_answer(state: AgentState):\n",
    "    print(\"Entering cannot_answer\")\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "    state[\"messages\"].append(\n",
    "        AIMessage(\n",
    "            content=\"I'm sorry, but I cannot find the information you're looking for.\"\n",
    "        )\n",
    "    )\n",
    "    return state\n",
    "\n",
    "\n",
    "def off_topic_response(state: AgentState):\n",
    "    print(\"Entering off_topic_response\")\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "    state[\"messages\"].append(AIMessage(content=\"I can't respond to that!\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better query\n",
    "\n",
    "#### D tier -> not implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multiquery_retriever(state: AgentState):\n",
    "#     print(\"Entering multiquery_retriever\")\n",
    "#     return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer_rag = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow\n",
    "workflow_rag = StateGraph(AgentState)\n",
    "workflow_rag.add_node(\"question_rewriter\", question_rewriter)\n",
    "workflow_rag.add_node(\"question_classifier\", question_classifier)\n",
    "workflow_rag.add_node(\"off_topic_response\", off_topic_response)\n",
    "\n",
    "workflow_rag.add_node(\"retrieve\", retrieve)\n",
    "workflow_rag.add_node(\"retrieval_grader\", retrieval_grader)\n",
    "workflow_rag.add_node(\"generate_answer\", generate_answer)\n",
    "workflow_rag.add_node(\"refine_question\", refine_question)\n",
    "workflow_rag.add_node(\"cannot_answer\", cannot_answer)\n",
    "\n",
    "workflow_rag.add_edge(\"question_rewriter\", \"question_classifier\")\n",
    "workflow_rag.add_conditional_edges(\n",
    "    \"question_classifier\",\n",
    "    on_topic_router,\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"off_topic_response\": \"off_topic_response\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow_rag.add_edge(\"retrieve\", \"retrieval_grader\")\n",
    "workflow_rag.add_conditional_edges(\n",
    "    \"retrieval_grader\",\n",
    "    proceed_router,\n",
    "    {\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"cannot_answer\": \"cannot_answer\",\n",
    "        \"refine_question\": \"refine_question\",\n",
    "    },\n",
    ")\n",
    "workflow_rag.add_edge(\"refine_question\", \"retrieve\")\n",
    "workflow_rag.add_edge(\"generate_answer\", END)\n",
    "workflow_rag.add_edge(\"cannot_answer\", END)\n",
    "\n",
    "workflow_rag.add_edge(\"off_topic_response\", END)\n",
    "workflow_rag.set_entry_point(\"question_rewriter\")\n",
    "graph = workflow_rag.compile(checkpointer=checkpointer_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off topic request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [HumanMessage(content='How is the weather?', additional_kwargs={}, response_metadata={})], 'documents': [], 'on_topic': '', 'rephrased_question': 'How is the weather?', 'proceed_to_generate': False, 'rephrase_count': 0, 'question': HumanMessage(content='How is the weather?', additional_kwargs={}, response_metadata={})}\n",
      "Entering question_classifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected message type: content. Use one of 'human', 'user', 'ai', 'assistant', or 'system'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m off_topic_content_rag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow is the weather?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m input_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: HumanMessage(content\u001b[38;5;241m=\u001b[39moff_topic_content_rag)}\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2688\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2687\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2688\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2689\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2692\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2693\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2694\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2696\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2340\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2334\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2335\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2336\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   2347\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 83\u001b[0m, in \u001b[0;36mquestion_classifier\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     66\u001b[0m system_message \u001b[38;5;241m=\u001b[39m SystemMessage(\n\u001b[1;32m     67\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a classifier that determines whether a user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms question is about one of the following topics:\u001b[39m\n\u001b[1;32m     68\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124m    If the question IS about any of these topics, respond with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Otherwise, respond with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m human_message \u001b[38;5;241m=\u001b[39m HumanMessage(\n\u001b[1;32m     81\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrephrased_question\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m )\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_classifier: Human message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mChatPromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuman_message\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m grade_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([system_message, human_message])\n\u001b[1;32m     85\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1199\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_messages\u001b[0;34m(cls, messages, template_format)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   1162\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m   1163\u001b[0m     template_format: PromptTemplateFormat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1164\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \n\u001b[1;32m   1167\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;124;03m        a chat prompt template.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:983\u001b[0m, in \u001b[0;36mChatPromptTemplate.__init__\u001b[0;34m(self, messages, template_format, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    930\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    980\u001b[0m \n\u001b[1;32m    981\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 983\u001b[0m         \u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[1;32m    984\u001b[0m     ]\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     input_vars: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1472\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message, template_format)\u001b[0m\n\u001b[1;32m   1470\u001b[0m message_type_str, template \u001b[38;5;241m=\u001b[39m message\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message_type_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1472\u001b[0m     _message \u001b[38;5;241m=\u001b[39m \u001b[43m_create_template_from_message_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_type_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1476\u001b[0m     _message \u001b[38;5;241m=\u001b[39m message_type_str(\n\u001b[1;32m   1477\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m   1478\u001b[0m             cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m, template), template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[1;32m   1479\u001b[0m         )\n\u001b[1;32m   1480\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/prompts/chat.py:1419\u001b[0m, in \u001b[0;36m_create_template_from_message_type\u001b[0;34m(message_type, template, template_format)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected message type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Use one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1418\u001b[0m     )\n\u001b[0;32m-> 1419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected message type: content. Use one of 'human', 'user', 'ai', 'assistant', or 'system'.",
      "\u001b[0mDuring task with name 'question_classifier' and id '312efaba-2c00-c32e-7873-b9f44bef2c8a'"
     ]
    }
   ],
   "source": [
    "off_topic_content_rag = \"How is the weather?\"\n",
    "input_data = {\"question\": HumanMessage(content=off_topic_content_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 6}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No relevant docs found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'question': HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={})}\n",
      "Entering question_classifier\n",
      "question_classifier: on_topic = Yes\n",
      "Entering on_topic_router\n",
      "Routing to tool_router\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: ## DEEP CONVOLUTIONAL GAN (DCG... Result: No\n",
      "Grading document: Big GAN... Result: No\n",
      "Grading document: Ces GNN tombaient dans la caté... Result: No\n",
      "Grading document: ## DCGAN... Result: No\n",
      "Grading document: ## DCGAN... Result: No\n",
      "Grading document: # DEEP LEARNING... Result: No\n",
      "Grading document: Nous couvrirons les encodeurs ... Result: No\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: # GRAPH NEURAL NETWORKS... Result: No\n",
      "Grading document: ## CONDITIONAL GAN (CGAN)... Result: No\n",
      "retrieval_grader: proceed_to_generate = False\n",
      "Entering proceed_router\n",
      "Routing to refine_question\n",
      "Entering refine_question\n",
      "refine_question: Refined question: What is deepGCN in the context of Graph Neural Networks (GNNs)?\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: ## DEEP CONVOLUTIONAL GAN (DCG... Result: No\n",
      "Grading document: Deep Graph Library... Result: No\n",
      "Grading document: # GRAPH NEURAL NETWORKS... Result: No\n",
      "Grading document: ## GRAPH NEURAL NETWORK... Result: No\n",
      "Grading document: Ces GNN tombaient dans la caté... Result: No\n",
      "Grading document: ## DCGAN... Result: No\n",
      "Grading document: ## DCGAN... Result: No\n",
      "Grading document: # DEEP LEARNING... Result: No\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: Big GAN... Result: No\n",
      "retrieval_grader: proceed_to_generate = False\n",
      "Entering proceed_router\n",
      "Routing to refine_question\n",
      "Entering refine_question\n",
      "refine_question: Refined question: What is the deepGCN architecture in the context of Graph Neural Networks (GNNs)?\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: ## DEEP CONVOLUTIONAL GAN (DCG... Result: No\n",
      "Grading document: Deep Graph Library... Result: No\n",
      "Grading document: # GRAPH NEURAL NETWORKS... Result: No\n",
      "Grading document: ## GRAPH NEURAL NETWORK... Result: No\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: Cependant, la première référen... Result: No\n",
      "Grading document: 1. Motivation 2. Types de grap... Result: No\n",
      "Grading document: Big GAN... Result: No\n",
      "Grading document: CGAN est similaire à DCGAN, à ... Result: No\n",
      "Grading document: ## DCGAN... Result: No\n",
      "retrieval_grader: proceed_to_generate = False\n",
      "Entering proceed_router\n",
      "Maximum rephrase attempts reached. Cannot find relevant documents.\n",
      "Entering cannot_answer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I'm sorry, but I cannot find the information you're looking for.\", additional_kwargs={}, response_metadata={})],\n",
       " 'documents': [],\n",
       " 'on_topic': 'Yes',\n",
       " 'tool_used': '',\n",
       " 'rephrased_question': 'What is the deepGCN architecture in the context of Graph Neural Networks (GNNs)?',\n",
       " 'proceed_to_generate': False,\n",
       " 'rephrase_count': 2,\n",
       " 'question': HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={})}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_docs_cotent_rag = \"In the feald of GNN, What is deepGCN?\"\n",
    "input_data = {\"question\": HumanMessage(content=no_docs_cotent_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 7}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG with memory in acction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'question': HumanMessage(content=\"Qu'est-ce que le graph neural network? entre en détails\", additional_kwargs={}, response_metadata={})}\n",
      "Entering question_classifier\n",
      "question_classifier: on_topic = Yes\n",
      "Entering on_topic_router\n",
      "Routing to tool_router\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: # GRAPH NEURAL NETWORKS... Result: Yes\n",
      "Grading document: ## GRAPH NEURAL NETWORK... Result: Yes\n",
      "Grading document: La première application concrè... Result: No\n",
      "Grading document: 1. Motivation 2. Types de grap... Result: Yes\n",
      "Grading document: [L'image montre différents typ... Result: No\n",
      "Grading document: [L'image montre un réseau neur... Result: No\n",
      "Grading document: Prédiction de graphes... Result: No\n",
      "Grading document: [L'image montre un diagramme d... Result: No\n",
      "Grading document: Les graphes eux incorporent de... Result: No\n",
      "Grading document: Il s'agit d'un ensemble d'algo... Result: No\n",
      "retrieval_grader: proceed_to_generate = True\n",
      "Entering proceed_router\n",
      "Routing to generate_answer\n",
      "Entering generate_answer\n",
      "generate_answer: Generated response: Un **Graph Neural Network (GNN)** est un type de réseau de neurones conçu pour traiter des données structurées sous la forme de graphes. Les graphes sont des structures constituées de nœuds (ou sommets) et d'arêtes (qui relient les nœuds). Les GNN sont particulièrement utiles pour capturer les relations complexes entre les entités d'un graphique tout en tenant compte des attributs associés à ces entités.\n",
      "\n",
      "### Motivation\n",
      "Les GNN sont utilisés afin de résoudre des problèmes où les données peuvent être naturellement modélisées sous forme de graphes, tels que les réseaux sociaux, les molécules dans la chimie, ou encore les systèmes de recommandation. Ils permettent d'extraire des caractéristiques significatives des nœuds et de leur voisinage.\n",
      "\n",
      "### Types de graphes\n",
      "Il existe différents types de graphes, tels que les graphes orientés, non orientés, à poids, et non pondérés. Les GNN peuvent être adaptés pour travailler avec ces divers types de graphes afin de répondre à des besoins spécifiques.\n",
      "\n",
      "### Applications dans les graphes\n",
      "Les GNN sont appliqués dans divers domaines, notamment :\n",
      "- La classification de nœuds (par exemple, déterminer le type d'une entité dans un réseau social)\n",
      "- La classification de graphes (par exemple, prédire la fonction d'une molécule)\n",
      "- La recommandation de contenu\n",
      "- La prévision de liens (déterminer si une connexion va apparaître entre deux nœuds)\n",
      "\n",
      "### Node embeddings\n",
      "Les GNN utilisent des techniques de **node embeddings** pour représenter les nœuds en tant que vecteurs dans un espace à dimensions réduites. Cela permet de simplifier les calculs tout en préservant la structure topologique du graphe.\n",
      "\n",
      "### Architecture de GNN\n",
      "Les GNN se basent généralement sur des couches itératives où chaque nœud communique avec ses voisins pour mettre à jour ses propres caractéristiques. Cette propagation d'informations permet d'intégrer des informations contextuelles à travers le graphe.\n",
      "\n",
      "En conclusion, les Graph Neural Networks sont des outils puissants pour analyser et traiter les données structurées sous forme de graphes, offrant une nouvelle approche pour résoudre divers problèmes complexes dans de nombreux domaines.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Qu'est-ce que le graph neural network? entre en détails\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Un **Graph Neural Network (GNN)** est un type de réseau de neurones conçu pour traiter des données structurées sous la forme de graphes. Les graphes sont des structures constituées de nœuds (ou sommets) et d'arêtes (qui relient les nœuds). Les GNN sont particulièrement utiles pour capturer les relations complexes entre les entités d'un graphique tout en tenant compte des attributs associés à ces entités.\\n\\n### Motivation\\nLes GNN sont utilisés afin de résoudre des problèmes où les données peuvent être naturellement modélisées sous forme de graphes, tels que les réseaux sociaux, les molécules dans la chimie, ou encore les systèmes de recommandation. Ils permettent d'extraire des caractéristiques significatives des nœuds et de leur voisinage.\\n\\n### Types de graphes\\nIl existe différents types de graphes, tels que les graphes orientés, non orientés, à poids, et non pondérés. Les GNN peuvent être adaptés pour travailler avec ces divers types de graphes afin de répondre à des besoins spécifiques.\\n\\n### Applications dans les graphes\\nLes GNN sont appliqués dans divers domaines, notamment :\\n- La classification de nœuds (par exemple, déterminer le type d'une entité dans un réseau social)\\n- La classification de graphes (par exemple, prédire la fonction d'une molécule)\\n- La recommandation de contenu\\n- La prévision de liens (déterminer si une connexion va apparaître entre deux nœuds)\\n\\n### Node embeddings\\nLes GNN utilisent des techniques de **node embeddings** pour représenter les nœuds en tant que vecteurs dans un espace à dimensions réduites. Cela permet de simplifier les calculs tout en préservant la structure topologique du graphe.\\n\\n### Architecture de GNN\\nLes GNN se basent généralement sur des couches itératives où chaque nœud communique avec ses voisins pour mettre à jour ses propres caractéristiques. Cette propagation d'informations permet d'intégrer des informations contextuelles à travers le graphe.\\n\\nEn conclusion, les Graph Neural Networks sont des outils puissants pour analyser et traiter les données structurées sous forme de graphes, offrant une nouvelle approche pour résoudre divers problèmes complexes dans de nombreux domaines.\", additional_kwargs={}, response_metadata={})],\n",
       " 'documents': [Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='# GRAPH NEURAL NETWORKS'),\n",
       "  Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='## GRAPH NEURAL NETWORK'),\n",
       "  Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='1. Motivation 2. Types de graphes 3. Applications dans les graphes 4. Node embeddings 5. GNN')],\n",
       " 'on_topic': 'Yes',\n",
       " 'tool_used': '',\n",
       " 'rephrased_question': \"Qu'est-ce que le graph neural network? entre en détails\",\n",
       " 'proceed_to_generate': True,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content=\"Qu'est-ce que le graph neural network? entre en détails\", additional_kwargs={}, response_metadata={})}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_content_1_rag = \"Qu'est-ce que le graph neural network? entre en détails\"\n",
    "input_data = {\"question\": HumanMessage(content=memory_content_1_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 8}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [HumanMessage(content=\"Qu'est-ce que le graph neural network? entre en détails\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Un **Graph Neural Network (GNN)** est un type de réseau de neurones conçu pour traiter des données structurées sous la forme de graphes. Les graphes sont des structures constituées de nœuds (ou sommets) et d'arêtes (qui relient les nœuds). Les GNN sont particulièrement utiles pour capturer les relations complexes entre les entités d'un graphique tout en tenant compte des attributs associés à ces entités.\\n\\n### Motivation\\nLes GNN sont utilisés afin de résoudre des problèmes où les données peuvent être naturellement modélisées sous forme de graphes, tels que les réseaux sociaux, les molécules dans la chimie, ou encore les systèmes de recommandation. Ils permettent d'extraire des caractéristiques significatives des nœuds et de leur voisinage.\\n\\n### Types de graphes\\nIl existe différents types de graphes, tels que les graphes orientés, non orientés, à poids, et non pondérés. Les GNN peuvent être adaptés pour travailler avec ces divers types de graphes afin de répondre à des besoins spécifiques.\\n\\n### Applications dans les graphes\\nLes GNN sont appliqués dans divers domaines, notamment :\\n- La classification de nœuds (par exemple, déterminer le type d'une entité dans un réseau social)\\n- La classification de graphes (par exemple, prédire la fonction d'une molécule)\\n- La recommandation de contenu\\n- La prévision de liens (déterminer si une connexion va apparaître entre deux nœuds)\\n\\n### Node embeddings\\nLes GNN utilisent des techniques de **node embeddings** pour représenter les nœuds en tant que vecteurs dans un espace à dimensions réduites. Cela permet de simplifier les calculs tout en préservant la structure topologique du graphe.\\n\\n### Architecture de GNN\\nLes GNN se basent généralement sur des couches itératives où chaque nœud communique avec ses voisins pour mettre à jour ses propres caractéristiques. Cette propagation d'informations permet d'intégrer des informations contextuelles à travers le graphe.\\n\\nEn conclusion, les Graph Neural Networks sont des outils puissants pour analyser et traiter les données structurées sous forme de graphes, offrant une nouvelle approche pour résoudre divers problèmes complexes dans de nombreux domaines.\", additional_kwargs={}, response_metadata={})], 'documents': [Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='# GRAPH NEURAL NETWORKS'), Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='## GRAPH NEURAL NETWORK'), Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='1. Motivation 2. Types de graphes 3. Applications dans les graphes 4. Node embeddings 5. GNN')], 'on_topic': 'Yes', 'tool_used': '', 'rephrased_question': \"Qu'est-ce que le graph neural network? entre en détails\", 'proceed_to_generate': True, 'rephrase_count': 0, 'question': HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={})}\n",
      "question_rewriter: Rephrased question: What are some practical use cases for Graph Neural Networks?\n",
      "Entering question_classifier\n",
      "question_classifier: on_topic = Yes\n",
      "Entering on_topic_router\n",
      "Routing to tool_router\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: # GRAPH NEURAL NETWORKS... Result: No\n",
      "Grading document: 1. Motivation 2. Types de grap... Result: Yes\n",
      "Grading document: ## GRAPH NEURAL NETWORK... Result: No\n",
      "Grading document: La première application concrè... Result: No\n",
      "Grading document: Applications des GAN: https://... Result: No\n",
      "Grading document: https://machinelearningmastery... Result: No\n",
      "Grading document: Deep Graph Library... Result: No\n",
      "Grading document: Knowledge Graphs... Result: No\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: Scene Graphs... Result: No\n",
      "retrieval_grader: proceed_to_generate = True\n",
      "Entering proceed_router\n",
      "Routing to generate_answer\n",
      "Entering generate_answer\n",
      "generate_answer: Generated response: Graph Neural Networks (GNNs) have several practical use cases across various domains. Here are some notable examples:\n",
      "\n",
      "1. **Social Network Analysis**: GNNs can be used to classify nodes (e.g., users) based on their attributes and relationships, helping in detecting communities, predicting user behaviors, and recommending friends.\n",
      "\n",
      "2. **Molecular Chemistry**: In cheminformatics, GNNs can predict molecular properties by treating molecules as graphs where atoms are nodes and bonds are edges. This can help in drug discovery and material science.\n",
      "\n",
      "3. **Recommendation Systems**: GNNs can enhance recommendation engines by analyzing user-item interactions as a graph, allowing for better personalization and understanding of user preferences.\n",
      "\n",
      "4. **Link Prediction**: GNNs can predict potential connections in a graph, such as determining which users may become friends in social networks or predicting missing links in biological networks.\n",
      "\n",
      "5. **Traffic Prediction**: In transportation systems, GNNs can model the road networks to predict traffic patterns based on historical data and real-time conditions.\n",
      "\n",
      "6. **Fraud Detection**: GNNs can analyze transactions in financial networks to identify suspicious activities or patterns indicative of fraud.\n",
      "\n",
      "Each of these applications benefits from the GNN’s ability to process complex relationships and interactions within graph-structured data, allowing for improved decision-making and insights.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Qu'est-ce que le graph neural network? entre en détails\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Un **Graph Neural Network (GNN)** est un type de réseau de neurones conçu pour traiter des données structurées sous la forme de graphes. Les graphes sont des structures constituées de nœuds (ou sommets) et d'arêtes (qui relient les nœuds). Les GNN sont particulièrement utiles pour capturer les relations complexes entre les entités d'un graphique tout en tenant compte des attributs associés à ces entités.\\n\\n### Motivation\\nLes GNN sont utilisés afin de résoudre des problèmes où les données peuvent être naturellement modélisées sous forme de graphes, tels que les réseaux sociaux, les molécules dans la chimie, ou encore les systèmes de recommandation. Ils permettent d'extraire des caractéristiques significatives des nœuds et de leur voisinage.\\n\\n### Types de graphes\\nIl existe différents types de graphes, tels que les graphes orientés, non orientés, à poids, et non pondérés. Les GNN peuvent être adaptés pour travailler avec ces divers types de graphes afin de répondre à des besoins spécifiques.\\n\\n### Applications dans les graphes\\nLes GNN sont appliqués dans divers domaines, notamment :\\n- La classification de nœuds (par exemple, déterminer le type d'une entité dans un réseau social)\\n- La classification de graphes (par exemple, prédire la fonction d'une molécule)\\n- La recommandation de contenu\\n- La prévision de liens (déterminer si une connexion va apparaître entre deux nœuds)\\n\\n### Node embeddings\\nLes GNN utilisent des techniques de **node embeddings** pour représenter les nœuds en tant que vecteurs dans un espace à dimensions réduites. Cela permet de simplifier les calculs tout en préservant la structure topologique du graphe.\\n\\n### Architecture de GNN\\nLes GNN se basent généralement sur des couches itératives où chaque nœud communique avec ses voisins pour mettre à jour ses propres caractéristiques. Cette propagation d'informations permet d'intégrer des informations contextuelles à travers le graphe.\\n\\nEn conclusion, les Graph Neural Networks sont des outils puissants pour analyser et traiter les données structurées sous forme de graphes, offrant une nouvelle approche pour résoudre divers problèmes complexes dans de nombreux domaines.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Graph Neural Networks (GNNs) have several practical use cases across various domains. Here are some notable examples:\\n\\n1. **Social Network Analysis**: GNNs can be used to classify nodes (e.g., users) based on their attributes and relationships, helping in detecting communities, predicting user behaviors, and recommending friends.\\n\\n2. **Molecular Chemistry**: In cheminformatics, GNNs can predict molecular properties by treating molecules as graphs where atoms are nodes and bonds are edges. This can help in drug discovery and material science.\\n\\n3. **Recommendation Systems**: GNNs can enhance recommendation engines by analyzing user-item interactions as a graph, allowing for better personalization and understanding of user preferences.\\n\\n4. **Link Prediction**: GNNs can predict potential connections in a graph, such as determining which users may become friends in social networks or predicting missing links in biological networks.\\n\\n5. **Traffic Prediction**: In transportation systems, GNNs can model the road networks to predict traffic patterns based on historical data and real-time conditions.\\n\\n6. **Fraud Detection**: GNNs can analyze transactions in financial networks to identify suspicious activities or patterns indicative of fraud.\\n\\nEach of these applications benefits from the GNN’s ability to process complex relationships and interactions within graph-structured data, allowing for improved decision-making and insights.', additional_kwargs={}, response_metadata={})],\n",
       " 'documents': [Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='1. Motivation 2. Types de graphes 3. Applications dans les graphes 4. Node embeddings 5. GNN')],\n",
       " 'on_topic': 'Yes',\n",
       " 'tool_used': '',\n",
       " 'rephrased_question': 'What are some practical use cases for Graph Neural Networks?',\n",
       " 'proceed_to_generate': True,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={})}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_content_2_rag = \"Can you give me a use case of it?\"\n",
    "input_data = {\"question\": HumanMessage(content=memory_content_2_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 8}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adamenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
