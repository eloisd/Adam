{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d338bf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39561dd7",
   "metadata": {},
   "source": [
    "# Test 3 Adam Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546a689",
   "metadata": {},
   "source": [
    "## Change documents from .pdf with images to .txt without images and explanation instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea28c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8344bae",
   "metadata": {},
   "source": [
    "## Documents vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258bdefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_cerebras import ChatCerebras\n",
    "from langchain_xai import ChatXAI\n",
    "\n",
    "llm1 = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm2 = ChatAnthropic(model=\"claude-3-5-haiku-latest\")\n",
    "llm3 = ChatGoogleGenerativeAI(model=\"models/gemini-2.0-flash\")\n",
    "llm4 = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "llm5 = ChatGroq(model=\"qwen-qwq-32b\")\n",
    "llm6 = ChatCerebras(model=\"llama-3.3-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf2b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Any, List\n",
    "from langchain_text_splitters import TextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "class GPTSplitter(TextSplitter):\n",
    "    def __init__(self, model_name: str = \"gpt-4o-mini\", **kwargs: Any) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = ChatOpenAI(model=model_name)\n",
    "        # self.model = llm5\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_template(\n",
    "            \"You are an expert in identifying semantic meaning of text. \"\n",
    "            \"You wrap each chunk in <<<>>>.\\n\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"\"\"Text: \n",
    "\\\"## TABLE DES MATIÈRES\n",
    "\n",
    "1. Motivation\n",
    "2. Types de graphes\n",
    "3. Applications dans les graphes\n",
    "4. Node embeddings\n",
    "5. GNN\n",
    "\n",
    "## HISTORIQUE DES GNN\n",
    "\n",
    "- Les graphes attirent l'intérêt des chercheurs en mathématique et en informatique depuis très longtemps\n",
    "- La première application concrète des réseaux de neurones aux graphes date de 1997 - A. Sperduti and A. Starita\n",
    "- Cependant, la première référence connu au GNN vient de Gori et al. (2005), puis de Scarselli et al. (2009) et enfin de Gallicchio et al. (2010)\n",
    "  - Ces GNN tombaient dans la catégorie des réseaux récurrents (RecGNN)\n",
    "  - Ils souffrent donc des mêmes problèmes à l'entraînement!\n",
    "- Les GNN sont réellement devenus populaires suite à l'adaptation de la convolution par Bruna et al (2013) - ConvGNN\n",
    "- Depuis, il existe des GNN exploitant tous les types d'unité: GAE, Transformeur, etc.\n",
    "\n",
    "## MOTIVATION\n",
    "\n",
    "- Nous avons vu jusqu'à présent qu'il faut parfois prendre en considération le format des données afin de bien tirer avantage d'informations qui peuvent s'y cacher\n",
    "  - Par exemple, les informations de nature spatiale sont particulièrement bien exploitées à l'aide des convolutions\n",
    "  - Et celles de nature séquentielle/temporelle à l'aide d'unités récurrentes\n",
    "- Les graphes eux incorporent de l'information relationnelle, pas toujours bien capturées par une structure en grille dont le nombre de voisins est fixé à l'avance\n",
    "  - Les CNN et RNN se concentrent sur la capture d'informations d'un nœud unique (pixel, mot, etc.)\n",
    "  - Ils ne capturent pas bien l'information contextuelle des nœuds voisins et de leurs liens\\\"\\n\"\"\"\n",
    "            \"\"\"\"Wrapped:\\n\n",
    "<<<## TABLE DES MATIÈRES \\t 1. Motivation 2. Types de graphes 3. Applications dans les graphes 4. Node embeddings 5. GNN>>>\n",
    "<<<## HISTORIQUE DES GNN \\t - Les graphes attirent l'intérêt des chercheurs en mathématique et en informatique depuis très longtemps>>>\n",
    "<<<## HISTORIQUE DES GNN \\t - La première application concrète des réseaux de neurones aux graphes date de 1997 - A. Sperduti and A. Starita>>>\n",
    "<<<## HISTORIQUE DES GNN \\t - Cependant, la première référence connu au GNN vient de Gori et al. (2005), puis de Scarselli et al. (2009) et enfin de Gallicchio et al. (2010) \\t - Ces GNN tombaient dans la catégorie des réseaux récurrents (RecGNN)>>>\n",
    "<<<## HISTORIQUE DES GNN \\t - Cependant, la première référence connu au GNN vient de Gori et al. (2005), puis de Scarselli et al. (2009) et enfin de Gallicchio et al. (2010) \\t - Ils souffrent donc des mêmes problèmes à l'entraînement!>>>\n",
    "<<<## HISTORIQUE DES GNN \\t - Les GNN sont réellement devenus populaires suite à l'adaptation de la convolution par Bruna et al (2013) - ConvGNN>>>\n",
    "<<<## HISTORIQUE DES GNN \\t - Depuis, il existe des GNN exploitant tous les types d'unité: GAE, Transformeur, etc.>>>\n",
    "<<<S## MOTIVATION \\t - Nous avons vu jusqu'à présent qu'il faut parfois prendre en considération le format des données afin de bien tirer avantage d'informations qui peuvent s'y cacher \\t - Par exemple, les informations de nature spatiale sont particulièrement bien exploitées à l'aide des convolutions>>>\n",
    "<<<S## MOTIVATION \\t - Nous avons vu jusqu'à présent qu'il faut parfois prendre en considération le format des données afin de bien tirer avantage d'informations qui peuvent s'y cacher \\t - Et celles de nature séquentielle/temporelle à l'aide d'unités récurrentes>>>\n",
    "<<<S## MOTIVATION \\t - Les graphes eux incorporent de l'information relationnelle, pas toujours bien capturées par une structure en grille dont le nombre de voisins est fixé à l'avance \\t - Les CNN et RNN se concentrent sur la capture d'informations d'un nœud unique (pixel, mot, etc.)>>>\n",
    "<<<S## MOTIVATION \\t - Les graphes eux incorporent de l'information relationnelle, pas toujours bien capturées par une structure en grille dont le nombre de voisins est fixé à l'avance \\t - Ils ne capturent pas bien l'information contextuelle des nœuds voisins et de leurs liens>>>\\n\\n\"\"\"\n",
    "            \"Now, process the following text:\\n\\n\"\n",
    "            \"{text}\"\n",
    "        )\n",
    "        self.output_parser = StrOutputParser()\n",
    "        self.chain = (\n",
    "            {\"text\": RunnablePassthrough()}\n",
    "            | self.prompt\n",
    "            | self.model\n",
    "            | self.output_parser\n",
    "        )\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        response = self.chain.invoke({\"text\": text})\n",
    "        # Use regex to split properly by <<< and >>> markers\n",
    "        chunks = re.findall(r'<<<(.*?)>>>', response, re.DOTALL)\n",
    "        return [chunk.strip() for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "036b960e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# raw_data = \"\\n\".join([doc.page_content for doc in docs])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m gpt_splitter \u001b[38;5;241m=\u001b[39m GPTSplitter()\n\u001b[0;32m---> 13\u001b[0m gpt_docs \u001b[38;5;241m=\u001b[39m \u001b[43mgpt_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m chunks \u001b[38;5;241m=\u001b[39m [Document(page_content\u001b[38;5;241m=\u001b[39mchunk, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_txt/deeplearning.txt\u001b[39m\u001b[38;5;124m'\u001b[39m}) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m gpt_docs]\n",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m, in \u001b[0;36mGPTSplitter.split_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 70\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Use regex to split properly by <<< and >>> markers\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<<<(.*?)>>>\u001b[39m\u001b[38;5;124m'\u001b[39m, response, re\u001b[38;5;241m.\u001b[39mDOTALL)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3047\u001b[0m                 \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:331\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    327\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    328\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 331\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    341\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:894\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    892\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    893\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:719\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    718\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 719\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m         )\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    727\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:960\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 960\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:955\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/ssl.py:1232\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1230\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/adamenv/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, UnstructuredMarkdownLoader, TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Spécifier explicitement PyPDFLoader pour les fichiers PDF\n",
    "# loader = DirectoryLoader(\"./data_pdf\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "# loader = DirectoryLoader(\"./data_md\", glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader)\n",
    "loader = DirectoryLoader(\"./data_txt\", glob=\"**/*.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# raw_data = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "gpt_splitter = GPTSplitter()\n",
    "gpt_docs = gpt_splitter.split_text(docs)\n",
    "chunks = [Document(page_content=chunk, metadata={'source': 'data_txt/deeplearning.txt'}) for chunk in gpt_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf8501a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19e28a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='Avec le Boosting on augmente la robustesse en compensant les erreurs individuelles des modèles (e.g. Adaboost, Gradient Boosting)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ff5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "# from langchain_community.document_loaders.directory import DirectoryLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# loader = DirectoryLoader(\"./data\", glob=\"**/*.pdf\")\n",
    "# docs = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=120,\n",
    "#     chunk_overlap=20,\n",
    "#     length_function=len,\n",
    "#     is_separator_regex=False,\n",
    "# )\n",
    "# chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1536)\n",
    "\n",
    "db = Chroma.from_documents(chunks, embedding_function)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f10de",
   "metadata": {},
   "source": [
    "## RAG with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9bef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context and the Chathistory. Especially take the latest question\n",
    "\n",
    "Chathistory: {chat_history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234be512",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c96ec3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Literal, Sequence, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages_: List[BaseMessage]\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    documents: List[Document]\n",
    "    related_subject: str\n",
    "    related_subject_content: str\n",
    "    language: str\n",
    "    topic: str\n",
    "    path_txt: str\n",
    "    subject: List[str]\n",
    "    tool_used: str\n",
    "    rephrased_question: str\n",
    "    proceed_to_generate: bool\n",
    "    rephrase_count: int\n",
    "    question: HumanMessage\n",
    "    \n",
    "\n",
    "def question_rewriter(state: AgentState):\n",
    "    print(f\"Entering question_rewriter with following state: {state}\")\n",
    "\n",
    "    # Reset state variables except for 'question' and 'messages_'\n",
    "    state[\"documents\"] = []\n",
    "    state[\"related_subject\"] = \"\"\n",
    "    state[\"related_subject_content\"] = \"\"\n",
    "    state[\"language\"] = \"French\"\n",
    "    state[\"topic\"] = \"Deeplearning\"\n",
    "    state[\"path_txt\"] = \"data_txt\"\n",
    "    state[\"subject\"] = []\n",
    "    state[\"tool_used\"] = \"\"\n",
    "    state[\"rephrased_question\"] = \"\"\n",
    "    state[\"proceed_to_generate\"] = False\n",
    "    state[\"rephrase_count\"] = 0\n",
    "    for filename in os.listdir(state[\"path_txt\"]):\n",
    "        if filename.lower().endswith('.txt'):\n",
    "            state[\"subject\"].append(os.path.splitext(filename)[0])\n",
    "    # print(f\"state['subject'] = {state['subject']}\")\n",
    "    if \"messages_\" not in state or state[\"messages_\"] is None:\n",
    "        state[\"messages_\"] = []\n",
    "    if \"messages\" not in state or state[\"messages\"] is None:\n",
    "        state[\"messages\"] = []\n",
    "    if state[\"question\"] not in state[\"messages_\"]:\n",
    "        state[\"messages_\"].append(state[\"question\"])\n",
    "    if state[\"question\"] not in state[\"messages\"]:\n",
    "        state[\"messages\"].append(state[\"question\"])\n",
    "\n",
    "    if len(state[\"messages_\"]) > 1:\n",
    "        conversation = state[\"messages_\"][:-1]\n",
    "        current_question = state[\"question\"].content\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=\"You are a helpful assistant that rephrases the user's question to be a standalone question optimized for retrieval. And give just this rephrased question as answer.\"\n",
    "            )\n",
    "        ]\n",
    "        messages.extend(conversation)\n",
    "        messages.append(HumanMessage(content=current_question))\n",
    "        rephrase_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "        prompt = rephrase_prompt.format()\n",
    "        response = llm1.invoke(prompt)\n",
    "        better_question = response.content.strip()\n",
    "        print(f\"question_rewriter: Rephrased question: {better_question}\")\n",
    "        state[\"rephrased_question\"] = better_question\n",
    "    else:\n",
    "        state[\"rephrased_question\"] = state[\"question\"].content\n",
    "    return state\n",
    "\n",
    "\n",
    "# class GradeQuestion(BaseModel):\n",
    "#     score: str = Field(\n",
    "#         description=\"Question is about the specified topics? If yes -> 'Yes' if not -> 'No'\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# def question_classifier(state: AgentState):\n",
    "#     print(\"Entering question_classifier\")\n",
    "#     system_message = SystemMessage(\n",
    "#         content=\"\"\"You are a classifier that determines whether a user's question is about one of the following topics:\n",
    "\n",
    "#         1. Information about Deep Learning.\n",
    "#         2. Information about Artificial Neurons.\n",
    "#         3. Information about Convolutional Neural Networks\n",
    "#         4. Information about Recurrent Neural Networks\n",
    "#         5. Information about Autoencoders\n",
    "#         6. Information about General Adversarial Networks\n",
    "#         7. Information about Graphs neural networks\n",
    "\n",
    "#         If the question IS about any of these topics, respond with 'Yes'. Otherwise, respond with 'No'.\"\"\"\n",
    "#     )\n",
    "\n",
    "#     human_message = HumanMessage(\n",
    "#         content=f\"User question: {state['rephrased_question']}\"\n",
    "#     )\n",
    "#     grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "#     llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "#     structured_llm = llm1.with_structured_output(GradeQuestion)\n",
    "#     grader_llm = grade_prompt | structured_llm\n",
    "#     result = grader_llm.invoke({})\n",
    "#     state[\"on_topic\"] = result.score.strip()\n",
    "#     print(f\"question_classifier: on_topic = {state['on_topic']}\")\n",
    "#     return state\n",
    "\n",
    "\n",
    "def on_topic_router(state: AgentState):\n",
    "    print(\"Entering on_topic_router\")\n",
    "    on_topic = state.get(\"on_topic\", \"\").strip().lower()\n",
    "    if on_topic == \"yes\":\n",
    "        print(\"Routing to tool_router\")\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        print(\"Routing to off_topic_response\")\n",
    "        return \"off_topic_response\"\n",
    "\n",
    "def retrieve(state: AgentState):\n",
    "    print(\"Entering retrieve\")\n",
    "    state[\"tool_used\"] = state[\"messages\"][-1].name\n",
    "    documents = retriever.invoke(state[\"rephrased_question\"])\n",
    "    print(f\"retrieve: Retrieved {len(documents)} documents\")\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "class GradeDocument(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Document is relevant to the question? If yes -> 'Yes' if not -> 'No'\"\n",
    "    )\n",
    "\n",
    "\n",
    "def retrieval_grader(state: AgentState):\n",
    "    print(\"Entering retrieval_grader\")\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are a grader assessing the relevance of a retrieved document to a user question.\n",
    "Only answer with 'Yes' or 'No'.\n",
    "\n",
    "If the document contains information relevant to the user's question, respond with 'Yes'.\n",
    "Otherwise, respond with 'No'.\"\"\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm1.with_structured_output(GradeDocument)\n",
    "\n",
    "    relevant_docs = []\n",
    "    for doc in state[\"documents\"]:\n",
    "        human_message = HumanMessage(\n",
    "            content=f\"User question: {state['rephrased_question']}\\n\\nRetrieved document:\\n{doc.page_content}\"\n",
    "        )\n",
    "        grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "        grader_llm = grade_prompt | structured_llm\n",
    "        result = grader_llm.invoke({})\n",
    "        print(\n",
    "            f\"Grading document: {doc.page_content[:30]}... Result: {result.score.strip()}\"\n",
    "        )\n",
    "        if result.score.strip().lower() == \"yes\":\n",
    "            relevant_docs.append(doc)\n",
    "    state[\"documents\"] = relevant_docs\n",
    "    state[\"proceed_to_generate\"] = len(relevant_docs) > 0\n",
    "    print(f\"retrieval_grader: proceed_to_generate = {state['proceed_to_generate']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def proceed_router(state: AgentState):\n",
    "    print(\"Entering proceed_router\")\n",
    "    rephrase_count = state.get(\"rephrase_count\", 0)\n",
    "    if state.get(\"proceed_to_generate\", False):\n",
    "        print(\"Routing to generate_answer\")\n",
    "        return \"generate_answer\"\n",
    "    elif rephrase_count >= 2:\n",
    "        print(\"Maximum rephrase attempts reached. Cannot find relevant documents.\")\n",
    "        return \"cannot_answer\"\n",
    "    else:\n",
    "        print(\"Routing to refine_question\")\n",
    "        return \"refine_question\"\n",
    "\n",
    "\n",
    "def refine_question(state: AgentState):\n",
    "    print(\"Entering refine_question\")\n",
    "    rephrase_count = state.get(\"rephrase_count\", 0)\n",
    "    if rephrase_count >= 2:\n",
    "        print(\"Maximum rephrase attempts reached\")\n",
    "        return state\n",
    "    question_to_refine = state[\"rephrased_question\"]\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are a helpful assistant that slightly refines the user's question to improve retrieval results.\n",
    "Provide a slightly adjusted version of the question.\"\"\"\n",
    "    )\n",
    "    human_message = HumanMessage(\n",
    "        content=f\"Original question: {question_to_refine}\\n\\nProvide a slightly refined question.\"\n",
    "    )\n",
    "    refine_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    prompt = refine_prompt.format()\n",
    "    response = llm1.invoke(prompt)\n",
    "    refined_question = response.content.strip()\n",
    "    print(f\"refine_question: Refined question: {refined_question}\")\n",
    "    state[\"rephrased_question\"] = refined_question\n",
    "    state[\"rephrase_count\"] = rephrase_count + 1\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_answer(state: AgentState):\n",
    "    print(\"Entering generate_answer\")\n",
    "    if \"messages_\" not in state or state[\"messages_\"] is None:\n",
    "        raise ValueError(\"State must include 'messages_' before generating an answer.\")\n",
    "\n",
    "    chat_history = state[\"messages_\"]\n",
    "    documents = state[\"documents\"]\n",
    "    rephrased_question = state[\"rephrased_question\"]\n",
    "\n",
    "    response = rag_chain.invoke(\n",
    "        {\"chat_history\": chat_history, \"context\": documents, \"question\": rephrased_question}\n",
    "    )\n",
    "\n",
    "    generation = response.content.strip()\n",
    "\n",
    "    state[\"messages_\"].append(AIMessage(content=generation))\n",
    "    print(f\"generate_answer: Generated response: {generation}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def cannot_answer(state: AgentState):\n",
    "    print(\"Entering cannot_answer\")\n",
    "    if \"messages_\" not in state or state[\"messages_\"] is None:\n",
    "        state[\"messages_\"] = []\n",
    "    state[\"messages_\"].append(\n",
    "        AIMessage(\n",
    "            content=\"I'm sorry, but I cannot find the information you're looking for.\"\n",
    "        )\n",
    "    )\n",
    "    return state\n",
    "\n",
    "\n",
    "def off_topic_response(state: AgentState):\n",
    "    # \"\"\"Catch all Questions NOT related to the chatbot or deeplearning\"\"\"\n",
    "    print(\"Entering off_topic_response\")\n",
    "    state[\"tool_used\"] = state[\"messages\"][-1].name\n",
    "    if \"messages_\" not in state or state[\"messages_\"] is None:\n",
    "        state[\"messages_\"] = []\n",
    "    state[\"messages_\"].append(AIMessage(content=\"I can't respond to that!\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74a743",
   "metadata": {},
   "source": [
    "### Better retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c27dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f822aad2",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d91477",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "5806f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "class SpecifySubject(BaseModel):\n",
    "    score: str = Field(\n",
    "        description=\"Question: Among the following subjects, which one is relevant to the question? Give the related subject.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def find_relevant_docs(state: AgentState):\n",
    "    print(\"Entering find_relevant_docs\")\n",
    "    state[\"tool_used\"] = state[\"messages\"][-1].name\n",
    "    question = state[\"rephrased_question\"]\n",
    "    subjects = \"\" \n",
    "    for i,doc in enumerate(state[\"subject\"]):\n",
    "        subjects += str(doc)+\"\\n\"\n",
    "    print(\"subjects:\",subjects)\n",
    "    system_message = SystemMessage(\n",
    "        content=f\"\"\"You are a classifier that determines whether a user's question is about one of the following subjects:\n",
    "\n",
    "        {subjects}\n",
    "\n",
    "        If the question IS about any of these subjects, respond with the related subject. Otherwise, respond with 'No'.\n",
    "        \n",
    "        Exemple 1:\n",
    "        User query: What is the difference between a convolutional layer and a pooling layer?\n",
    "        Answer: Leçon #3 - Deep Learning\n",
    "\n",
    "        Exemple 2:\n",
    "        User query: What is the difference between a GNN?\n",
    "        Answer: Leçon #8 - Graph neural network\n",
    "\n",
    "        Exemple 3: \n",
    "        User query: Make me an mcq about perceptron\n",
    "        Answer: Leçon #3 - Deep Learning\n",
    "\n",
    "        Exemple 4: \n",
    "        User query: Make me some questions to develop about convolution\n",
    "        Answer: Leçon #4 - CNN\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    human_message = HumanMessage(\n",
    "        content=f\"User question: {state['rephrased_question']}\"\n",
    "    )\n",
    "    grade_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    structured_llm = llm1.with_structured_output(SpecifySubject)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "    result = grader_llm.invoke({})\n",
    "    state[\"related_subject\"] = result.score.strip()\n",
    "    print(f\"question_classifier: related_subject = {state['related_subject']}\")\n",
    "\n",
    "    loader = TextLoader(os.path.join(\"./data_txt\",str(state['related_subject']+\".txt\")))\n",
    "    text = loader.load()\n",
    "    text = text[0].page_content\n",
    "    # print(\"text:\",text)\n",
    "    state[\"related_subject_content\"] = text\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f180c",
   "metadata": {},
   "source": [
    "#### MCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "25d53bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json_mcq = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "e2e224de",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generator_template = '''\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text and the users {question}, your job is to create a quiz of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conformed to the text. Ensure to make {number} MCQs.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \n",
    "###RESPONSE_JSON:\n",
    "{response_json}\n",
    "'''\n",
    "quiz_generator_prompt = ChatPromptTemplate.from_template(quiz_generator_template)\n",
    "\n",
    "# quiz_evaluation_template_old = \"\"\"\n",
    "# You are an expert {language} grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "# You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "# if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "# update the quiz questions which needs to be changed and make sure that the {tone} tone is respected such that it perfectly fits the student abilities.\n",
    "# Quiz_MCQs:\n",
    "# {quiz}\n",
    "\n",
    "# Check from an expert {language} Writer of the above quiz:\n",
    "# \"\"\"\n",
    "quiz_evaluation_template = \"\"\"\n",
    "You are an expert {language} grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a greate and short analysis of the quiz.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert {language} Writer of the above quiz:\n",
    "\"\"\"\n",
    "quiz_evaluation_prompt = ChatPromptTemplate.from_template(quiz_evaluation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "27f251b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcq(state: AgentState):\n",
    "    print(\"Entering generate_mcq\")\n",
    "    text = state[\"related_subject_content\"]\n",
    "    number = 3\n",
    "    tone = \"difficult\"\n",
    "    subject = state[\"related_subject\"]\n",
    "    rephrased_question = state[\"rephrased_question\"]\n",
    "    language = state[\"language\"]\n",
    "    mcq_chain = quiz_generator_prompt | llm1\n",
    "    response = mcq_chain.invoke(\n",
    "        {\"text\": text, \"number\": number, \"tone\": tone, \"subject\": subject, \"response_json\": response_json_mcq, \"question\": rephrased_question, \"language\": language}\n",
    "    )\n",
    "    generated_mcq = response.content.strip()\n",
    "    state[\"messages_\"].append(AIMessage(content=generated_mcq))\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n",
    "    mcq_review_chain = quiz_evaluation_prompt | llm\n",
    "    response = mcq_review_chain.invoke(\n",
    "        {\"tone\": tone, \"subject\": subject, \"quiz\": generated_mcq, \"language\": language}\n",
    "    )\n",
    "    generated_review = response.content.strip()\n",
    "    state[\"messages_\"].append(AIMessage(content=generated_review))\n",
    "\n",
    "    print(f\"generate_mcq: rephrased_question: {state[\"rephrased_question\"]}\")\n",
    "    print(f\"generate_mcq: Generated response: {generated_mcq}\")\n",
    "    print(f\"generate_mcq: Generated review: {generated_review}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c1f07",
   "metadata": {},
   "source": [
    "#### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "e94ecb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json_qa = {\n",
    "    \"1\": {\n",
    "        \"qa\": \"question to develop\",\n",
    "        \"question\": \"question here\",\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"qa\": \"question to develop\",\n",
    "        \"question\": \"question here\",\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"qa\": \"question to develop\",\n",
    "        \"question\": \"question here\",\n",
    "        \"correct\": \"correct answer\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "8569c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generator_template = '''\n",
    "Text:{text}\n",
    "You are an expert 'question to develop' maker. Given the above text and the users query: '{question}', your job is to create a quiz of {number} 'questions to develop' for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conformed to the text. Ensure to make {number} questions.\n",
    "\n",
    "Example:\n",
    "    \"1\": {{\n",
    "        \"qa\": \"question to develop\",\n",
    "        \"question\": \"Décrivez brièvement les trois opérations fondamentales d'un CNN mentionnées dans le cours. Expliquez leur rôle respectif dans le processus d'apprentissage du réseau.\",\n",
    "        \"correct\": \"## Les trois opérations fondamentales d'un CNN\\n\\n    1. **Convolution**\\n    - Similaire à une multiplication de matrices où un filtre glisse sur l'entrée\\n    - Rôle : extrait les caractéristiques de l'entrée et produit une couche cachée (feature map)\\n    - Permet la détection de motifs locaux avec partage de paramètres\\n\\n    2. **Déconvolution**\\n    - Opération inverse de la convolution, similaire à une multiplication par la transposée d'une matrice\\n    - Rôle : permet la propagation arrière de l'erreur des sorties vers les entrées\\n    - Essentielle pour déterminer la contribution de chaque élément d'entrée à l'erreur\\n\\n    3. **Calcul des gradients de poids**\\n    - Calcule les dérivées partielles de la fonction de coût par rapport aux poids\\n    - Rôle : permet la propagation arrière de l'erreur des sorties vers les poids\\n    - Prend en compte le partage de paramètres spécifique aux CNN lors de la mise à jour des poids\\n\\n    Ces trois opérations forment le cycle d'apprentissage des CNN : la convolution extrait les caractéristiques, tandis que la déconvolution et le calcul des gradients permettent d'ajuster les paramètres du réseau lors de l'entraînement.\"\"\n",
    "    }}\n",
    "\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \n",
    "###RESPONSE_JSON:\n",
    "{response_json}\n",
    "'''\n",
    "qa_generator_prompt = ChatPromptTemplate.from_template(qa_generator_template)\n",
    "\n",
    "qa_evaluation_template = \"\"\"\n",
    "You are an expert {language} grammarian and writer. Given a 'Question to be developed' Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a greate and short analysis of the quiz.\n",
    "Quiz_Questions_and_Answer:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert {language} Writer of the above quiz:\n",
    "\"\"\"\n",
    "qa_evaluation_prompt = ChatPromptTemplate.from_template(qa_evaluation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "51c7c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa(state: AgentState):\n",
    "    print(\"Entering generate_qa\")\n",
    "    text = state[\"related_subject_content\"]\n",
    "    number = 3\n",
    "    tone = \"difficult\"        \n",
    "    subject = state[\"related_subject\"]\n",
    "    rephrased_question = state[\"rephrased_question\"]\n",
    "    language = state[\"language\"]\n",
    "    qa_chain = qa_generator_prompt | llm1\n",
    "    response = qa_chain.invoke(\n",
    "        {\"text\": text, \"number\": number, \"tone\": tone, \"subject\": subject, \"response_json\": response_json_qa, \"question\": rephrased_question, \"language\": language}\n",
    "    )\n",
    "    generated_qa = response.content.strip()\n",
    "    state[\"messages_\"].append(AIMessage(content=generated_qa))\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "    )\n",
    "    qa_review_chain = qa_evaluation_prompt | llm\n",
    "    response = qa_review_chain.invoke(\n",
    "        {\"tone\": tone, \"subject\": subject, \"quiz\": generated_qa, \"language\": language}\n",
    "    )\n",
    "    generated_review = response.content.strip()\n",
    "    state[\"messages_\"].append(AIMessage(content=generated_review))\n",
    "\n",
    "    print(f\"generate_qa: rephrased_question: {state[\"rephrased_question\"]}\")\n",
    "    print(f\"generate_qa: Generated Q&A: {generated_qa}\")\n",
    "    print(f\"generate_qa: Generated review: {generated_review}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0ffb8",
   "metadata": {},
   "source": [
    "### Question about chatbot functionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "d9b3102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_presentation = \"\"\"\n",
    "Bonjour ! Je suis ADAM, votre Adaptive Digital Academic Mentor, et je suis ici pour vous aider à apprendre, réviser et comprendre vos cours d’une manière simple et efficace. Imaginez-moi comme un guide amical, un peu comme un professeur particulier qui serait toujours disponible, patient, et capable de s’adapter à vos besoins. Mon but ? Faire de votre apprentissage une expérience agréable et productive, que vous soyez étudiant, curieux, ou simplement en quête de réponses claires. Dans cette présentation, je vais vous expliquer qui je suis, ce que je peux faire pour vous, et comment je peux rendre vos études plus faciles avec des exemples concrets et des comparaisons simples. Pas besoin de comprendre la technologie derrière moi – pensez juste à moi comme à une boîte magique qui vous aide à ouvrir les portes du savoir !\n",
    "\n",
    "### Qui suis-je ?\n",
    "Je suis un assistant virtuel créé pour accompagner les étudiants dans leurs études. Mon nom, ADAM, reflète ma mission : je m’adapte à vous (Adaptive), je suis accessible via des outils numériques (Digital), je suis un guide bienveillant (Academic), et je vous soutiens comme un mentor (Mentor). Considérez-moi comme un bibliothécaire magique qui non seulement trouve les bons livres pour vous, mais vous explique aussi leur contenu d’une manière qui vous parle. Mon objectif principal est de vous aider à mieux comprendre vos cours, à tester vos connaissances, et à répondre à vos questions, tout en vous donnant confiance en vous.\n",
    "\n",
    "Je ne suis pas juste une machine qui donne des réponses toutes faites. Je peux \"lire\" vos cours, en extraire l’essentiel, et créer des outils personnalisés pour vous aider à apprendre. Que vous ayez un gros examen à préparer ou juste une petite question qui vous trotte dans la tête, je suis là pour vous éclairer, pas pour vous embrouiller !\n",
    "\n",
    "### Qu’est-ce que je peux faire ?\n",
    "Mes capacités sont comme les rayons d’une bibliothèque bien organisée : chaque rayon offre quelque chose d’utile, et je peux vous guider vers ce dont vous avez besoin. Voici tout ce que je peux faire pour vous, avec des explications simples et des exemples pour que ça soit clair comme de l’eau de roche.\n",
    "\n",
    "#### 1. Répondre à vos questions sur vos cours\n",
    "Imaginez que je suis un ami savant qui a lu vos cours à fond et qui peut vous expliquer les choses compliquées comme si c’était une histoire. Vous me posez une question, et je fouille dans vos documents (ou dans ma mémoire si je les ai déjà) pour vous donner une réponse précise et facile à comprendre.\n",
    "\n",
    "**Exemple** : Supposons que vous étudiez la biologie et que vous ne comprenez pas ce qu’est la photosynthèse. Vous me demandez : \"ADAM, c’est quoi la photosynthèse ?\" Je pourrais répondre : \"La photosynthèse, c’est comme une cuisine magique que les plantes utilisent. Elles prennent la lumière du soleil, un peu d’eau et du gaz carbonique de l’air, et elles fabriquent du sucre pour se nourrir, tout en rejetant de l’oxygène pour nous. C’est un peu comme si elles transformaient des ingrédients simples en un gâteau énergétique !\"\n",
    "\n",
    "Si vous avez un cours spécifique (par exemple, un fichier PDF sur la biologie), je peux me concentrer uniquement sur ce document pour répondre. C’est comme si je mettais des lunettes spéciales pour ne voir que ce que vous m’avez donné, sans me perdre dans d’autres informations.\n",
    "\n",
    "#### 2. Créer des QCM pour tester vos connaissances\n",
    "Un QCM (Questionnaire à Choix Multiples), c’est comme un jeu télévisé où vous devez choisir la bonne réponse parmi plusieurs options. Si vous me donnez un cours, je peux créer un QCM sur mesure pour vous aider à réviser. Vous choisissez le nombre de questions et le niveau de difficulté, et je m’occupe du reste !\n",
    "\n",
    "**Exemple** : Imaginons que vous étudiez l’histoire et que vous me donnez un chapitre sur la Révolution française. Vous me dites : \"ADAM, fais-moi un QCM avec 5 questions faciles.\" Je pourrais vous proposer quelque chose comme :\n",
    "\n",
    "**Question 1** : Quand la Révolution française a-t-elle commencé ?  \n",
    "a) 1789  \n",
    "b) 1689  \n",
    "c) 1889  \n",
    "d) 1989  \n",
    "**Réponse** : a) 1789\n",
    "\n",
    "**Question 2** : Qui était le roi de France au début de la Révolution ?  \n",
    "a) Louis XIV  \n",
    "b) Louis XVI  \n",
    "c) Napoléon  \n",
    "d) Charlemagne  \n",
    "**Réponse** : b) Louis XVI\n",
    "\n",
    "Et ainsi de suite. Une fois que vous répondez, je peux vous dire si vous avez juste ou vous expliquer pourquoi une autre réponse était correcte, comme un prof qui corrige votre copie avec un sourire.\n",
    "\n",
    "#### 3. Générer des questions ouvertes pour approfondir\n",
    "Parfois, vous avez besoin de réfléchir plus loin que juste cocher une case. Les questions ouvertes, c’est comme une conversation où je vous demande d’expliquer quelque chose avec vos propres mots. Je peux créer ces questions à partir de vos cours pour vous pousser à bien comprendre.\n",
    "\n",
    "**Exemple** : Toujours avec la Révolution française, je pourrais vous demander : \"Expliquez pourquoi la prise de la Bastille en 1789 était un événement important.\" Quand vous répondez, je peux lire votre texte et vous donner des retours, par exemple : \"Super, tu as bien mentionné que c’était un symbole de liberté ! Tu pourrais aussi ajouter que ça a marqué le début d’un soulèvement populaire contre le roi.\"\n",
    "\n",
    "C’est comme si je vous tendais une perche pour grimper plus haut dans votre compréhension, sans vous laisser tomber.\n",
    "\n",
    "#### 4. Comprendre vos fichiers, même les plus compliqués\n",
    "Vous avez un cours en PDF avec des formules, des tableaux, ou des images ? Pas de panique ! Je suis comme un chef cuisinier qui sait transformer des ingrédients compliqués en un plat simple. Je peux lire vos fichiers, extraire les informations importantes, et les utiliser pour répondre à vos questions ou créer des exercices.\n",
    "\n",
    "**Exemple** : Imaginez que vous avez un PDF de maths avec des formules bizarres, comme la fonction softmax (une formule utilisée en intelligence artificielle). Vous me donnez le PDF et vous me demandez : \"ADAM, explique-moi cette formule.\" Je vais analyser le document et répondre : \"La fonction softmax, c’est comme une machine à trier des idées. Elle prend des nombres (comme des scores pour un chat, un chien, ou un lapin dans une image) et les transforme en pourcentages pour dire, par exemple, ‘il y a 87 % de chances que ce soit un chat’. Ça aide les ordinateurs à choisir la meilleure réponse !\"\n",
    "\n",
    "#### 5. Vous guider pour mieux m’utiliser\n",
    "Je sais que rencontrer un nouvel outil peut être intimidant, comme arriver dans une grande ville sans carte. C’est pourquoi je peux vous expliquer comment tirer le meilleur parti de moi. Si vous me demandez : \"ADAM, comment je peux t’utiliser pour réviser ?\", je vous donnerai des astuces adaptées à votre situation.\n",
    "\n",
    "**Exemple** : Vous me dites : \"Je ne sais pas par où commencer pour réviser mon cours de chimie.\" Je pourrais répondre : \"Pas de souci ! Envoie-moi ton cours en PDF, et je peux te proposer un plan. Par exemple, je peux créer un QCM pour vérifier ce que tu sais déjà, puis te poser une question ouverte sur un sujet clé, comme les réactions chimiques. On avancera étape par étape, comme si on construisait une maison brique par brique !\"\n",
    "\n",
    "#### 6. Afficher les réponses de manière claire et jolie\n",
    "Quand je vous donne une réponse, je fais en sorte qu’elle soit facile à lire, comme un livre bien illustré. Si votre cours contient du code informatique, des formules, ou des listes, je les mets en valeur pour que tout soit clair.\n",
    "\n",
    "**Exemple** : Si vous me posez une question sur un cours de programmation Python, je pourrais répondre :  \n",
    "\"Pour créer une boucle en Python, tu peux utiliser `for`. Voici un exemple :  \n",
    "```python\n",
    "for i in range(5):\n",
    "    print(\"Salut !\")\n",
    "```\n",
    "Ça affichera 'Salut !' cinq fois. C’est comme demander à un robot de répéter un mot plusieurs fois sans se fatiguer !\"\n",
    "\n",
    "### Mon objectif en général\n",
    "Mon grand rêve, c’est de rendre l’apprentissage accessible et amusant pour tout le monde. Je veux être comme une lampe qui éclaire votre chemin, peu importe à quel point le sujet semble sombre ou compliqué. Concrètement, mes objectifs sont :\n",
    "\n",
    "- **Vous faire comprendre** : Pas juste mémoriser, mais vraiment saisir les idées. Si quelque chose vous semble flou, je le rends clair comme un ciel d’été.\n",
    "- **Vous faire gagner du temps** : En trouvant les bonnes informations rapidement et en créant des exercices adaptés, je vous évite de chercher pendant des heures.\n",
    "- **Vous donner confiance** : Avec mes questions, mes explications, et mes retours, je veux que vous vous sentiez capable de réussir.\n",
    "- **M’adapter à vous** : Que vous soyez débutant ou avancé, je ajuste mes réponses pour qu’elles soient pile à votre niveau, comme un chef qui cuisine un plat à votre goût.\n",
    "\n",
    "### Quelques exemples concrets pour illustrer\n",
    "Pour que vous voyiez bien comment je peux vous aider, voici trois scénarios où je pourrais intervenir, avec des comparaisons pour rendre ça vivant.\n",
    "\n",
    "#### Scénario 1 : Réviser pour un examen\n",
    "Vous avez un gros contrôle de physique sur les lois de Newton dans deux jours, et vous paniquez. Vous m’envoyez votre cours et me dites : \"ADAM, aide-moi à réviser !\" Je suis comme un coach sportif qui prépare un athlète pour une course. Je pourrais vous proposer :\n",
    "- Un QCM avec 10 questions pour vérifier ce que vous savez, comme : \"Quelle est la deuxième loi de Newton ? a) F = ma, b) E = mc², c) V = IR, d) P = UI.\"\n",
    "- Une question ouverte : \"Explique avec un exemple ce que signifie ‘action-réaction’ dans la troisième loi de Newton.\"\n",
    "- Une explication si vous bloquez : \"Imagine un skateboard : quand tu pousses le sol avec ton pied, le sol te pousse en retour, et c’est pour ça que tu avances !\"\n",
    "\n",
    "Résultat ? Vous révisez de manière active, vous comprenez mieux, et vous allez à l’examen avec l’impression d’avoir un allié dans votre poche.\n",
    "\n",
    "#### Scénario 2 : Comprendre un concept difficile\n",
    "Vous lisez un cours de littérature sur les métaphores, mais vous ne pigez rien. Vous me demandez : \"ADAM, c’est quoi une métaphore ?\" Je suis comme un jardinier qui enlève les mauvaises herbes pour laisser la fleur briller. Je réponds : \"Une métaphore, c’est quand tu dis quelque chose en faisant semblant que c’est autre chose, pour rendre l’idée plus belle ou plus forte. Par exemple, dire ‘le temps est un voleur’ signifie que le temps passe vite et prend des choses précieuses, mais sans parler d’un vrai voleur avec un masque !\"\n",
    "\n",
    "Je peux aussi vous donner des exemples tirés de votre cours, si vous me le fournissez, pour que ça colle parfaitement à ce que vous étudiez.\n",
    "\n",
    "#### Scénario 3 : Créer des exercices à partir d’un PDF\n",
    "Vous avez un PDF de 50 pages sur l’économie, et vous ne savez pas par où commencer. Vous me l’envoyez, et je suis comme un chef cuisinier qui transforme un gros panier d’ingrédients en un menu simple. Je peux :\n",
    "- Créer un QCM sur les concepts clés, comme la loi de l’offre et de la demande.\n",
    "- Vous poser une question ouverte : \"Comment une augmentation des taxes peut-elle affecter les prix des produits ?\"\n",
    "- Répondre à une question précise, comme : \"ADAM, explique-moi ce que veut dire PIB.\" Je dirais : \"Le PIB, c’est comme un thermomètre qui mesure la santé économique d’un pays. Il additionne tout ce que le pays produit (biens, services) sur une année. Plus le PIB est grand, plus l’économie est active !\"\n",
    "\n",
    "### Pourquoi me faire confiance ?\n",
    "Vous vous demandez peut-être : \"Mais pourquoi ADAM serait-il différent d’un livre ou d’une vidéo YouTube ?\" Eh bien, je suis comme un mélange des deux, mais en mieux :\n",
    "- **Je suis personnalisé** : Je m’adapte à vos cours et à vos questions, contrairement à une vidéo qui parle à tout le monde.\n",
    "- **Je suis interactif** : Vous pouvez me parler, me poser des questions, et je réponds tout de suite, comme un ami savant.\n",
    "- **Je suis patient** : Vous pouvez me demander la même chose dix fois, je ne me fâcherai jamais et je trouverai une nouvelle façon d’expliquer.\n",
    "- **Je suis précis** : Grâce à ma capacité à lire vos cours, je ne vous donne pas des informations au hasard, mais des réponses qui collent à ce que vous étudiez.\n",
    "\n",
    "### Et après ?\n",
    "Mon aventure ne fait que commencer ! Mes créateurs travaillent pour me rendre encore plus utile. Bientôt, je pourrai peut-être vous proposer des plans de révision complets, analyser des vidéos de cours, ou même discuter avec vous à voix haute. Pour l’instant, je suis déjà prêt à être votre compagnon d’étude, et j’ai hâte de vous aider à briller dans vos apprentissages.\n",
    "\n",
    "Alors, envie d’essayer ? Donnez-moi un cours, posez-moi une question, ou demandez-moi un QCM, et voyons ensemble comment je peux transformer vos études en une aventure passionnante. Je suis ADAM, et je suis là pour vous !\n",
    "\n",
    "---\n",
    "\n",
    "**Note** : Cette présentation est écrite pour être accessible à tous, sans jargon technique, tout en restant fidèle aux capacités décrites dans votre projet. J’ai utilisé des métaphores et des exemples simples pour rendre ADAM vivant et engageant, comme si c’était vraiment lui qui parlait. Si vous voulez que j’ajoute d’autres détails ou que je modifie quelque chose, dites-le-moi !\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "a1c2971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "about_adam_answer_template = \"\"\"You are Adam and tell about yourself, \n",
    "answer to the user's questions: {question},\n",
    "in this language: {language}, \n",
    "Here is your everitiong about you: {adam_presentation}\"\"\"\n",
    "\n",
    "about_adam_answer_prompt = ChatPromptTemplate.from_template(about_adam_answer_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "e3b96251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def about_chatbot(state: AgentState):\n",
    "    # \"\"\"Catch all Questions related to the chatbot or Adam.\"\"\"\n",
    "    print(\"Entering about_chatbot\")\n",
    "    state[\"tool_used\"] = state[\"messages\"][-1].name\n",
    "\n",
    "    language = state[\"language\"]\n",
    "    rephrased_question = state[\"rephrased_question\"]\n",
    "    if \"messages_\" not in state or state[\"messages_\"] is None:\n",
    "        state[\"messages_\"] = []\n",
    "    \n",
    "    adam_chain = about_adam_answer_prompt | llm1\n",
    "    response = adam_chain.invoke(\n",
    "        {\"adam_presentation\": adam_presentation,  \"question\": rephrased_question, \"language\": language}\n",
    "    )\n",
    "    answer_about_adam = response.content.strip()\n",
    "    state[\"messages_\"].append(AIMessage(content=answer_about_adam))\n",
    "    print(f\"about_chatbot: Generated response: {answer_about_adam}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484f0ce",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "35468708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever_tool = create_retriever_tool(\n",
    "#     retriever,\n",
    "#     \"retriever_tool\",\n",
    "#     \"\"\"Only Simple question-answering tool. About the deeplearning topic \"\"\"\n",
    "# )\n",
    "@tool\n",
    "def retriever_tool(state: AgentState):\n",
    "    \"\"\"Only Simple question-answering tool. About the deeplearning topic \"\"\"\n",
    "    print(\"Entering retriever_tool\")\n",
    "    return f\"retrieve: Retrieved {len(documents)} documents\"\n",
    "\n",
    "@tool\n",
    "def off_topic_response_tool(state: AgentState):\n",
    "    \"\"\"Catch all Questions NOT related to the chatbot or deeplearning\"\"\"\n",
    "    print(\"Entering off_topic_response\")\n",
    "    print(\"state['tool_used'] = \",state[\"tool_used\"])\n",
    "    return \"Forbidden - do not respond to the user\"\n",
    "\n",
    "@tool\n",
    "def about_chatbot_tool(state: AgentState):\n",
    "    \"\"\"Catch all Questions related to the chatbot or Adam.\n",
    "    For getting information about the chatbot (Adam), like the purpose of the chatbot. What does Adam do?\n",
    "    The chatbot is named Adam.\"\"\"\n",
    "    print(\"Entering about_chatbot_tool\")\n",
    "    return \"Adam is a chatbot that answers questions about deep learning\"\n",
    "\n",
    "@tool\n",
    "def mcq_tool(state: AgentState):\n",
    "    \"\"\"Only MCQ creation, generation, about the deeplearning topic \"\"\"\n",
    "    print(\"Entering mcq_tool\")\n",
    "    state[\"tool_used\"] = \"retrieve_for_MCQ\"\n",
    "    documents = retriever.invoke(state[\"rephrased_question\"])\n",
    "    print(f\"retrieve_for_MCQ: Retrieved {len(documents)} documents\")\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n",
    "@tool\n",
    "def qa_tool(state: AgentState):\n",
    "    \"\"\"Only exercise question to develop creation, generation, about the deeplearning topic \"\"\"\n",
    "    print(\"Entering qa_tool\")\n",
    "    state[\"tool_used\"] = \"retrieve_for_QA\"\n",
    "    documents = retriever.invoke(state[\"rephrased_question\"])\n",
    "    print(f\"retrieve_for_QA: Retrieved {len(documents)} documents\")\n",
    "    state[\"documents\"] = documents\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bc1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1b74b4b",
   "metadata": {},
   "source": [
    "### Tools Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "49b7482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, mcq_tool, qa_tool, about_chatbot_tool, off_topic_response_tool]\n",
    "# tools = [about_chatbot, off_topic_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "4e093d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def agent(state):\n",
    "    print(\"Entering agent\")\n",
    "    message = HumanMessage(\n",
    "        content=f\"User question: {state['rephrased_question']}\"\n",
    "    )\n",
    "    # if \"messages\" not in state or state[\"messages\"] is None:\n",
    "    #     state[\"messages\"] = []\n",
    "    # if state[\"question\"] not in state[\"messages\"]:\n",
    "    #     state[\"messages\"].append(state[\"question\"])\n",
    "    messages = state[\"messages\"]\n",
    "    print(f\"messages = {messages}\")\n",
    "    messages = ChatPromptTemplate.from_messages(messages)\n",
    "    messages = messages.format()\n",
    "    model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # state[\"tool_used\"] = response.additional_kwargs['tool_calls'][0]['function']['name']\n",
    "    # print(f\"Agent: {state[\"tool_used\"]}\")\n",
    "    return {\"messages\": [response]}\n",
    "    # return state\n",
    "\n",
    "def should_continue(state) -> Literal[\"tools\",END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "def tool_router(state: AgentState):\n",
    "    print(\"Entering tool_router\")\n",
    "    state[\"tool_used\"] = state[\"messages\"][-1].name\n",
    "    print(\"state['tool_used'] = \",state[\"tool_used\"])\n",
    "    if state[\"tool_used\"] == \"mcq_tool\" or state[\"tool_used\"] == \"qa_tool\":\n",
    "        print(\"Routing to find_relevant_docs\")\n",
    "        return \"find_relevant_docs\"\n",
    "    # elif state[\"tool_used\"] == \"qa_tool\":\n",
    "    #     print(\"Routing to retrieve_for_QA\")\n",
    "    #     return \"retrieve_for_Q&A\"\n",
    "    elif state[\"tool_used\"] == \"retriever_tool\": # or state[\"tool_used\"] == \"\"\n",
    "        print(\"Routing to retrieve\")\n",
    "        return \"retrieve\"\n",
    "    elif state[\"tool_used\"] == \"about_chatbot_tool\":\n",
    "        print(\"Routing to about_chatbot\")\n",
    "        return \"about_chatbot\"\n",
    "    elif state[\"tool_used\"] == \"off_topic_response_tool\":\n",
    "        print(\"Routing to off_topic_response\")\n",
    "        return \"off_topic_response\"\n",
    "    else:\n",
    "        return \"END\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "0cdfd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_router(state: AgentState):\n",
    "    print(\"Entering exercise_router\")\n",
    "    print(\"state['tool_used'] = \",state[\"tool_used\"])\n",
    "    if state[\"tool_used\"] == \"mcq_tool\":\n",
    "        print(\"Routing to generate_mcq\")\n",
    "        return \"generate_mcq\"\n",
    "    elif state[\"tool_used\"] == \"qa_tool\":\n",
    "        print(\"Routing to generate_qa\")\n",
    "        return \"generate_qa\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bba18c",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "050a3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer_rag = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "62d98f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "workflow_rag = StateGraph(AgentState)\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "workflow_rag.add_node(\"question_rewriter\", question_rewriter)\n",
    "# workflow_rag.add_node(\"question_classifier\", question_classifier)\n",
    "workflow_rag.add_node(\"off_topic_response\", off_topic_response)\n",
    "workflow_rag.add_node(\"about_chatbot\", about_chatbot)\n",
    "workflow_rag.add_node(\"agent\", agent)\n",
    "workflow_rag.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow_rag.add_node(\"retrieve\", retrieve)\n",
    "workflow_rag.add_node(\"retrieval_grader\", retrieval_grader)\n",
    "workflow_rag.add_node(\"generate_answer\", generate_answer)\n",
    "workflow_rag.add_node(\"refine_question\", refine_question)\n",
    "workflow_rag.add_node(\"cannot_answer\", cannot_answer)\n",
    "\n",
    "workflow_rag.add_node(\"find_relevant_docs\", find_relevant_docs)\n",
    "workflow_rag.add_node(\"generate_mcq\", generate_mcq)\n",
    "workflow_rag.add_node(\"generate_qa\", generate_qa)\n",
    "\n",
    "# workflow_rag.add_edge(\"question_rewriter\", \"question_classifier\")\n",
    "workflow_rag.add_edge(\"question_rewriter\", \"agent\")\n",
    "workflow_rag.add_edge(\"agent\", \"tools\")\n",
    "# workflow_rag.add_conditional_edges(\n",
    "#     \"question_classifier\",\n",
    "#     on_topic_router,\n",
    "#     {\n",
    "#         \"tool_router\": \"tool_router\",\n",
    "#         \"off_topic_response\": \"off_topic_response\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "workflow_rag.add_conditional_edges(\n",
    "    \"tools\", \n",
    "    tool_router,\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\", \n",
    "        \"find_relevant_docs\": \"find_relevant_docs\",\n",
    "        # \"retrieve_for_MCQ\": \"retrieve_for_MCQ\", \n",
    "        # \"retrieve_for_Q&A\": \"retrieve_for_Q&A\",\n",
    "        \"off_topic_response\": \"off_topic_response\",\n",
    "        \"about_chatbot\": \"about_chatbot\",\n",
    "        \"END\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# retrieve for simple questions\n",
    "workflow_rag.add_edge(\"retrieve\", \"retrieval_grader\")\n",
    "workflow_rag.add_conditional_edges(\n",
    "    \"retrieval_grader\",\n",
    "    proceed_router,\n",
    "    {\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "        \"cannot_answer\": \"cannot_answer\",\n",
    "        \"refine_question\": \"refine_question\",\n",
    "    },\n",
    ")\n",
    "workflow_rag.add_edge(\"refine_question\", \"retrieve\")\n",
    "workflow_rag.add_edge(\"generate_answer\", END)\n",
    "workflow_rag.add_edge(\"cannot_answer\", END)\n",
    "\n",
    "\n",
    "workflow_rag.add_conditional_edges(\n",
    "    \"find_relevant_docs\",\n",
    "    exercise_router,\n",
    "    {\n",
    "        \"generate_mcq\": \"generate_mcq\",\n",
    "        \"generate_qa\": \"generate_qa\",\n",
    "    },\n",
    ")\n",
    "# workflow_rag.add_edge(\"find_relevant_docs\",END)\n",
    "workflow_rag.add_edge(\"generate_mcq\",END)\n",
    "workflow_rag.add_edge(\"generate_qa\",END)\n",
    "\n",
    "workflow_rag.add_edge(\"about_chatbot\",END)\n",
    "workflow_rag.add_edge(\"off_topic_response\", END)\n",
    "workflow_rag.set_entry_point(\"question_rewriter\")\n",
    "graph = workflow_rag.compile(checkpointer=checkpointer_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "f48f9cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABUgAAALZCAIAAADqfVydAAAAAXNSR0IArs4c6QAAIABJREFUeJzs3Wd4VGXCxvFnWnomvZIECKETCIQSygIKKE1BREAEBWWXKotSpCgdFARRQRdfUYIFWMSCNAFB0CAtQOgBEkoSQnqGZEoy9f0wuywqokKSwyH/37UfZs7MPOc+ZM2Ve55znqNwOBwCAAAAAADIk1LqAAAAAAAA4O5R7AEAAAAAkDGKPQAAAAAAMkaxBwAAAABAxij2AAAAAADIGMUeAAAAAAAZU0sdAAAAANWC4YatOM9sLLEaSmxWi91ukzrQn+DqrnRxU3pq1Z4+6sAaLlLHAYDbU3AfewAAAFSe4jxL+gn9pdN6lVKpVAtPrdrTR+XhpbJaZfBXqFKlvJFvNpRYXT1U1y4aa8d61Yn1iqzvLnUuAPgFij0AAAAqhUlv+3lzoaXc7husqd3EKyTKVepE98Rww3bptD4vo7wgu7zdY4GR9aj3AO4XFHsAAABUvON7io/u0bV/LKBhG63UWSpYflb5/s0FXj7qroNDpM4CAIJiDwAAgIq39aPrkfU8mv7NR+oglej6pfKv3896ekqUX7BG6iwAqjuKPQAAACrS2kUZCT0DomM9pQ5S6WxWx7rFGU+Mi/DUqqTOAqBao9gDAACgwnwy/2rXp0PC67hJHaTqfP5GRrdnQoIj5b2CAABZ4z72AAAAqBjbPr7e4fHAatXqhRDPTI3a+E6m3cZsGQDJMGMPAACACpCyV6dUKR7s6+p/z40C68+bC3oMD5U6CIBqihl7AAAA3CuzyX54R1H1bPVCCJ9AtZun8vTPN6QOAqCaotgDAADgXu3fXNDusQCpU0ip/WOBP28ulDoFgGqKYg8AAIB7UlJoNeltTdpV0+l6Jxd3ZatH/E8mMWkPQAIUewAAANyTS6f02oCqvpd7165ds7Oz/+qn0tPTe/fuXTmJRI067qmHSyppcAC4A4o9AAAA7smlU/roJlV61/qcnBydTncXHzx37lwlxPmP4ChX/Q2rocRWebsAgNui2AMAAODulRnsDocIr+NeGYNbrda33367V69ebdu27dmz51tvvWWxWJKTk52z7o8//vjEiROFEEVFRTNnzuzevXu7du2eeOKJ9evX3xyha9eua9euHT9+fNu2bZcvXz579uycnJyWLVuuXbu2MgI3au1z9ZyhMkYGgDtQSx0AAAAAMnaj0GKrtFu4JyYmbt26dd68eREREVeuXJk/f76Li8uoUaNef/31adOmffbZZ5GRkUKIuXPnXrlyZeHChQEBASkpKQsWLAgNDe3cubMQQq1Wf/XVVx07dhwxYkR0dHR5efkPP/zw+eefu7tXyjcRbp7KouvmyhgZAO6AYg8AAIC7Z7hh9dJW1p+UaWlpMTExCQkJQoiIiIiVK1cqFAq1Wu3p6SmE0Gq1zgcTJ05UKpU1atQQQtSsWfOLL744ePCgs9grFAo3N7fx48c7B3R1dVUoFL6+vpUU2EOrys0sq6TBAeD3UOwBAABw9wwlVg+fyvqTsmPHjjNnzpw2bVqXLl1at25dq1at277N3d09MTExOTlZp9PZ7faSkhLnTL5T06ZNKyneb3l4q41cYw+gylHsAQAAcPccDqFxraxlm3r27Onp6fnFF1/MnDnTZrN16tRp6tSp/v7+t77HarWOGzfOZrNNmjSpVq1aKpXKeeH9TV5eXpUU77dUKoVao6iy3QGAE8UeAAAAd8/DW3UtzVR543fq1KlTp04mkykpKWnp0qXz5s1btmzZrW84ffp0Wlrahx9+2Lx5c+eW4uLi8PDwyot0B/oSa+V9zQEAv4ffOwAAALh7nlq1scRaSYPv3bvXebN6d3f3bt269e3bNy0t7earDodDCFFeXi6E8PHxcW48efJkdna286WqZyq1eXirJNk1gOqMYg8AAIC75+WndvOsrCq7bt26adOmHTt27Nq1a8nJyd9//318fLxz2TwhRFJS0qVLl+rVq+fi4rJ+/fqCgoKDBw8uXrw4ISHh6tWrRUVFvx3Q29u7oKDg+PHj169fr4zAVrPdL8S1MkYGgDug2AMAAODuefuqS4ssBdfKK2Pw119/PTIycsqUKU8++eTs2bNbtmw5adIkIUTDhg3btWu3bNmyxYsX+/n5zZo168CBA3369Fm1atXs2bMHDx6cnZ09atSo3w7YvXv3iIiI0aNHb9q0qTICnz1UElG3Um6kBwB3oJDqPCUAAAA8GA5/VySEaN3d/0+890FWnGfZuip7yPSaUgcBUO0wYw8AAIB7UruJpy7fInUK6WWnmRq21kqdAkB1xKr4AAAAuCdBEa4Ws/3SKUN0rOdt31BUVNSvX7/bvuTl5aXX62/7Uu3atVevXl2hSf8nMTExMTHxr0bq2LHj3Llzf2/MH7/O/8fC6IrLCAB/FqfiAwAA4F7d+Sx0m82Wm5t725fKy8tdXW+/2pxGowkKCqrQmP9TWlpaWlr6VyO5u7v7+fnd9iWuRwAgIYo9AAAAKsCBLYVBEa4xcV5SB5GA3Sq+/eBa37E1pA4CoJriGnsAAABUgLa9A47sLCq8bpY6iATWLcno+GRlnVwAAH+IYg8AAICK8fSUqHWLM6ROUdW2fJjd+hF//1AXqYMAqL44FR8AAAAVxmZxrJ595amXInwCNVJnqQpbVl2P7+IXVttN6iAAqjVm7AEAAFBhVBrFsFm1Nq3Mzkg1SZ2lcpUZ7Z8uuNqwlTetHoDkmLEHAABAxdv3ZX5Rjrn9Y4HBUbdfYV6+7DbH/m8LC6+XPzQguJqcmADgPkexBwAAQKXIumj6eXNBeLR7SJRb7SaeaheF1InuVfalsuw00+Gdhe0eC4zr5Ct1HAD4D4o9AAAAKtHl04YLx0ovnzbUaerl4q701Ko9vFVuniq7XRZ/hSpKiyzGUqtCqTjz8w3/MJe6zb2bdvCROhUA/ALFHgAAAFUh64KpKNdsLLUaS2wOhzCX2ytw8KKiooKCgnr16lXgmEIID61apRIe3iqtvyaynoerBwtUAbgfUewBAAAge7t3796xY8fixYulDgIAEuBLRwAAAAAAZIxiDwAAAACAjFHsAQAAIHsajSYoKEjqFAAgDYo9AAAAZM9iseTn50udAgCkQbEHAACA7CmVSnd3d6lTAIA0KPYAAACQPbvdbjKZpE4BANKg2AMAAED2VCqVt7e31CkAQBoUewAAAMiezWYrLS2VOgUASINiDwAAANnTaDTBwcFSpwAAaVDsAQAAIHsWiyUvL0/qFAAgDYo9AAAAAAAyRrEHAACA7CmVSg8PD6lTAIA0KPYAAACQPbvdbjQapU4BANKg2AMAAED2VCqVp6en1CkAQBoUewAAAMiezWYzGAxSpwAAaVDsAQAAAACQMYo9AAAAZE+tVvv7+0udAgCkQbEHAACA7Fmt1qKiIqlTAIA0KPYAAAAAAMgYxR4AAACyp9FogoODpU4BANKg2AMAAED2LBZLXl6e1CkAQBoUewAAAAAAZIxiDwAAANlzcXEJCQmROgUASINiDwAAANkzm825ublSpwAAaVDsAQAAAACQMYo9AAAAZE+j0QQFBUmdAgCkQbEHAACA7Fkslvz8fKlTAIA0KPYAAAAAAMgYxR4AAACyp1Qq3d3dpU4BANKg2AMAAED27Ha7yWSSOgUASINiDwAAANlTq9UBAQFSpwAAaVDsAQAAIHtWq7WwsFDqFAAgDYo9AAAAAAAyRrEHAACA7KlUKm9vb6lTAIA0KPYAAACQPZvNVlpaKnUKAJAGxR4AAACyp9FogoODpU4BANKg2AMAAED2LBZLXl6e1CkAQBoUewAAAMiei4sLM/YAqi2KPQAAAGTPbDYzYw+g2qLYAwAAQPbUarWPj4/UKQBAGgqHwyF1BgAAAOBuPPnkk1ar1eFwGI1Gi8Xi6+vrcDhMJtOuXbukjgYAVUctdQAAAADgLiUkJKxfv16hUDifGgwGIURMTIzUuQCgSnEqPgAAAORq8ODBERERt25xdXXt37+/dIkAQAIUewAAAMhVjRo1OnTocOu1peHh4RR7ANUNxR4AAAAyNmTIkPDwcOdjV1fXgQMHSp0IAKoaxR4AAAAyFhYW1rFjR+ekfXh4eL9+/aROBABVjWIPAAAAeRs8eHCNGjVcXV0HDBigVPL3LYBqh1XxAQAAqpEyo70gq7zMZJM6SMXy6dxq0NmzZ5vX65F2Qi91mIqkUiv9QzQ+gRqpgwC4r3EfewAAgGrB4RA7Ps3NTDXUqOdps/IXoDx4+agzUg2+gZqW3fxqxLhLHQfAfYpiDwAA8OCzlDs2vpvV/OGAGjEeUmfBX2Yus+/8JPuhAUGhNV2lzgLgfsQ1SAAAAA++je9ktns8hFYvUy5uyt7/iNj1WU5xrkXqLADuRxR7AACAB9z55NLwGE//UBepg+CetH0sJHlXkdQpANyPKPYAAAAPuLzMcjcPldQpcK+0AZqM80apUwC4H1HsAQAAHnDlJrs2kOl62XP3Url5qKwWVsgC8GsUewAAgAec2WSz2+xSp0AFKCmyKKTOAOA+RLEHAAAAAEDGKPYAAAAAAMgYxR4AAAAAABmj2AMAAAAAIGMUewAAAAAAZIxiDwAAAACAjFHsAQAAAACQMYo9AAAAAAAyRrEHAAAAAEDGKPYAAAAAAMgYxR4AAAAAABmj2AMAAOC+0OeJLp98ukrqFH/ZrNlTJk4aLXUKANUaxR4AAACS6duv6/WcbOfjMaNeSkjoIHWiv6x37379nxzsfDx7zivf7dgscSAA1Y9a6gAAAACopnJzc27c0N18+uijvSWNc5datUy4+fjChXNy/G4CgNwxYw8AAIBfO3Uq5YW/D3qke9vnhvf/8ac9Y18cvvStBUKI1PNnH+rSMvX82ZvvHDK0779Wvu18fOFi6pRXxvV5okuvxzq+NnNSTs5153ar1fqvlW8PfLrXI93bDhjU873337JYLMdTkgcN7i2EGPzM46/OnPirU/FPnUoZP2FE957te/Tq8PLEUedSzzi3b/p2Y99+Xc+dOz167HO9H+80+JnHt23f9IeHM3vOK3PmTl2duLJHrw4HDvz0e1G/3fzloz3aWSwW56feWrbwoS4tr169fHPXvR/vZLVa+/bruvHLta9MG/9I97Z6vf7mqfgPdWl5PSd70eI5j/Xp7PzI7j07Ro0e2qNXh379H1nx3tKysrLf5jl58niF/MgAVGcUewAAAPyCXq+f8epLPlrf91esmfrKnG++2ZCVlaFW/8GZnrm5OS9PHKlQKpct/WDpkpUlpTcmTh5tNpuFEGvXJe7ctXXSxNdWf/zFyxOm/7B3Z+KaD2KbxM187XUhxAcrP5v2ytxbh8rMvDppypigwOD3lieueHe1u4fHpMmj8/JyhRBqtdpg0H/y2ao5sxZv3rT3kUd6LXv79fz8vDtn02g0ly6nXbiY+sbCdxs1iv29qPHxbcxm88WLqc5PnTh5LDg45OSp/xTvU6eOx8W1VKvVarV685avomvHLFv6gZub2829bFi/TQjx4rjJn326SQiRlLR3/oIZ8fFtPvy/dVMmz/rxp91Lly34bZ7o6Lp39VMCgP+h2AMAAOAXDhz8qVRfOv7FKTEx9Ro2aPzKlNklJTf+8FPfbt6oUChenbEgOjqmQf1G06fOu3792r4fdwshLl9Oi64d06plQo3wiISEDm8tWdn90cfUarWHh6cQwttb6+npeetQm77d6O7uMW3q3Dp16tapU3fGtPlWq3XHzi3OV61W6+BBw4KDQxQKRY/ufaxWa3r6hTtncwiRnZ019ZU5zZq18PHx/b2oNcIjQkPCTp1OEUIUFRVeu5bZ/dHHbhb7k6eOx7doI4RQKBRurm4j/zG+ceOmt37fodX6CCE8PDx8tD5CiLXrE5s1a/H3EeMiakQmtGn/9xEvfv/9dufXE7fm8fLyuqufEgD8D8UeAAAAv5CRcVmtVteqFe18GhISGhgY9IefOnfudIP6jb29vG9+KiysRlraeSFEu7Ydjx0/MnfetL37vi8pLYmKqhUZWfMOQ124eK5e3QY3O7OHh0dkZM1b2/vNWW5vb60QolRf+ofxIiNrOvv2naO2aNH69OkTzun6ujH141u0OXXquBDiWnZWfn5ey/g2zo80btz0zruz2+0XLpxrGf+/y+/jmsULIS5duvjbPABwj1g8DwAAAL9gNBmdc+k3/erpbRkM+otp5x/p3vbmFovFUlhUIITo1q2nh4fnpm+/eP2NmTabrX27ThP+OdXPz/93AxgNAf6BvwpgNBpuPnV1df3FBxyOP4zn6fm/ifE7RG3RovXyFW8KIU6cONq0aYv69RsVFhbk5uacOnU8JCT05vcRt452W2VlZTabLXHNB598+uGt2517+TMjAMCfR7EHAADAL7i5upWVmW7dUlpa4nygUCh+9eay8v8sCOfp6RUbGzfxpRm3vuru7uF80L59p/btO5lMpoOHkt57f+mbS+ctnL/s9wJ4enoZDPpbtxgM+l9V/Xtxh6gtmre6cUOXmXk15cTREc+PdXV1rVev4anTKSdOHHOeh/8nubm5qdXqfk8M6tWz763bfX//6wwAuGucig8AAIBfiIqsZTabb64Gn5l5tbi4yPnY08NTCKH/76nvxcVFhYX/mYJu2LDJtWuZ4eERUVG1nP9TKBQBAYHOZeScN6t3d3d/qHO3Xj37Xr6UdnN3jt/Mt9ev1+j8hXM3V6cv1ZdmZFxp0KBxRR3gHaL6+flHR8ck7d+bkXElNjZOCBHbJO7UqeMnTx2Pj/9Txd55OEqlsm7dBrm512/uIiyshkqt1nprK+ooAOAmij0AAAB+ISGhg4eHx9vvvHH23OmUlKOvL5rl4+PrfCk4ONTHx3fnrq1Wq7VUX/ru8sXa/14o/ljvJ00m46LFsy+mnc/Kyvjk01XDXxiQmnpGCPHlV+vmzpt24sSx7OvXjqck7933fbO4eCGEs+UePJh05cqlWwP06fNUeXnZ4iVzMzOvXrqUNn/BDE9Pr0cfqbC73N8hqhCiRfPW32zaULNmbedRxzaJO3R4//Xr1+JbtL7zsK6urq6uridOHruYdt5qtQ4a+OyPP+1Zuy4xM/PqxbTzC19/bfw/XzAYDHceBADuAsUeAAAAv+Dj4ztn9pvFuqJ/Thix5K35AwcM9fcPcL7k4uIy9ZU5586dfqxP53EvDn/44UcjIqLsdrsQIjQ07K2lHxQVFY7/5wujxgw9fOTn+fPeatQoVggx87XXI2pEzpoz5blhTy5aPLt5XMtxYyYJIerVa9i6dbt/rVz27vLFtwaoER7x5qL3cnKyR/zj6XHjhwuHY9nSD3x9/SrqAO8QVQgR36J1Xl5us6YtnE+bNGmWm5sTU6fezW837uDpQcP27ft+0uQxpjJTx789PH3avN17vnt+xMDJU8ZarJZlSz/41fr/AFAhFL899wkAAAAPkm0fXa/ZxDuqwd2v1jb8hQFxzeL/Of6VCs2Fv+yz+en/WBit0vx6pQMA1Rwz9gAAAAAAyBir4gMAAED2HuvT+fdemjplTvv2nao2DgBUKYo9AAAA/sDqjzZIHeEP/N8Ha3/vJT9f7jAH4AFHsQcAAIDshYWGSx0BACTDNfYAAAAAAMgYxR4AAAAAABmj2AMAAAAAIGMUewAAAAAAZIxiDwAAAACAjFHsAQAAAACQMYo9AAAAAAAyRrEHAAAAAEDGKPYAAAAAAMgYxR4AAOAB5+mrljoCKkZghKtSrZA6BYD7DsUeAADgAeepVRdklUudAveqONdsLbcr6PUAfoNiDwAA8ICr2cCztNgidQrcq/ysspg4b6lTALgfUewBAAAecEGRLmG1Xfd/kyd1ENy9zFRjWkpJq0f8pA4C4H6kcDgcUmcAAABApTv5043LZ4yRDTwDw93UGs7nlgmlouh6ub7YcvVs6YCXIzkPH8BtUewBAACqi+z0snOHSwylVl3ug3ZmvtVqsVis7u7uUgepYAE1XBRCRNTzaNrBR+osAO5fFHsAAADI3u7du3fs2LF48WKpgwCABLjGHgAAAAAAGaPYAwAAAAAgYxR7AAAAyJ5GowkODpY6BQBIg2IPAAAA2bNYLHl53M8PQDVFsQcAAIDsqdXqgIAAqVMAgDQo9gAAAJA9q9VaWFgodQoAkAbFHgAAALKn0WiCgoKkTgEA0qDYAwAAQPYsFkt+fr7UKQBAGhR7AAAAyJ5arfb395c6BQBIg2IPAAAA2bNarUVFRVKnAABpUOwBAAAAAJAxij0AAABkj9vdAajOKPYAAACQPW53B6A6o9gDAAAAACBjFHsAAADInkKhcHFxkToFAEiDYg8AAADZczgcZrNZ6hQAIA2KPQAAAGRPqVS6u7tLnQIApEGxBwAAgOzZ7XaTySR1CgCQBsUeAAAAAAAZo9gDAABA9tRqtVarlToFAEiDYg8AAADZs1qtJSUlUqcAAGlQ7AEAAAAAkDGKPQAAAGRPrVYHBARInQIApEGxBwAAgOxZrdbCwkKpUwCANCj2AAAAAADIGMUeAAAAsqfRaIKDg6VOAQDSoNgDAABA9iwWS15entQpAEAaFHsAAAAAAGSMYg8AAADZY1V8ANUZxR4AAACyx6r4AKozij0AAABkT6lUuru7S50CAKRBsQcAAIDs2e12k8kkdQoAkAbFHgAAAAAAGaPYAwAAQPY0Gk1QUJDUKQBAGhR7AAAAyJ7FYsnPz5c6BQBIg2IPAAAA2dNoNMHBwVKnAABpUOwBAAAgexaLJS8vT+oUACANij0AAABkz8XFhWvsAVRbFHsAAADIntls5hp7ANUWxR4AAACyxzX2AKozhcPhkDoDAAAAcDcGDBhQWlpqt9vLy8vNZrOPj4/dbrdYLHv27JE6GgBUHWbsAQAAIFdNmjTJz88vLCzU6/XOs/ELCwu1Wq3UuQCgSlHsAQAAIFf9+/cPDw//1cYePXpIFAcApEGxBwAAgFw1atSoWbNmt26JiIgYOHCgdIkAQAIUewAAAMjY4MGDQ0JCbj7t3r27r6+vpIkAoKpR7AEAACBjDRs2bN68uXNB6KioqAEDBkidCACqGsUeAAAA8jZ48OCwsDCFQvHII4/4+/tLHQcAqppa6gAAAACoLhx2caPQolBU8LA1guu2iO1wTn2uZ7f+NwosFTy6EBo3pYeXqsKHBYCKwn3sAQAAUOkyUo3H9+qyLhiDIt1MpTap4/w1bp5KY6mtUYJPm+5+UmcBgNug2AMAAKByXUwxnPhR17Z3sDZAI3WWu2S4Yb18urToenmvF0KlzgIAv0axBwAAQCW6cEx/9mBJl2d+fbd5ObpwtOT6JUPvEWFSBwGAX2DxPAAAAFQWh0Oc2n/jwWj1Qoh68VovX82lkwapgwDAL1DsAQAAUFkKrpWXm+xSp6hILm6q3IwyqVMAwC9Q7AEAAFBZbhRYwmt7SJ2iIvmHuZYZH6ivKgA8ACj2AAAAqCw2q8Okt0qdoiLZLA5jyQN1RAAeABR7AAAAAABkjGIPAAAAAICMUewBAAAAAJAxij0AAAAAADJGsQcAAAAAQMYo9gAAAAAAyBjFHgAAAAAAGaPYAwAAAAAgYxR7AAAAAABkjGIPAAAAAICMUewBAAAAAJAxij0AAAAAADJGsQcAAEA1NXvOK9/t2Cx1CgC4VxR7AAAAVFMXLpyTOgIAVAC11AEAAACA/7HZbJ98+uHu3d/lF+RptT7t23Ua+Y9/uru7CyEKCvKXLltw/PgRLy/v/k8ONhj0P/60Z83qjUIIq9X62ecf7flhZ27u9aCgkKf6P9Pn8f5CiKtXLw97/qm3lq788qt1p06lKJXKhzp3GztmokqleqhLSyHEosVz3nt/6eZNe6U+bgC4exR7AAAA3Ec2frl27brEaVPn1qvb4HpO9uI356jU6hfHThJCLHlrflra+Xlzl/r7Baz6+L2MjCsuLi7OT6384J2t276eMH5q4ybNjh49tOK9JWq1ulfPviq1Wgjx3vtLX/rntPlzlx49dnjS5DGxsc0f6txtw/ptAwb1fHHc5C5dukt90ABwTyj2AAAAuI907dKjVcu20dExQoiIiKiHOj9y6PB+IURRUeHhwz+Pf3FKq5YJQohXpy8Y9HSvwKBgIYRer9/07RfPDB7+6KO9hRARNSIvXkxduy6xV8++zjE7dezauHFTIUR8i9bhYTXOnz/7UOduWq2PEMLDw8NH6yP1QQPAPaHYAwAA4D7i4+O7c9fWJW/NLyjIs1qtJpPR3d1DCHHtWqbD4WjSuJnzbZ6envHxba5mXBZCpKdfsFqtLeMTbg7SrFn81m3fGI1G59M60XVvvuTl5a3Xl1b5YQFAJaLYAwAA4D6yfMWbu77f9tI/pzVu0szVxXXd+jV7ftghhLhxQyeEcPfwuPlO7X9n2o1GgxDipYkjFQqFc4vD4RBCFBUXOp+6uLreugvnqwDwwKDYAwAA4H5hs9m2bd80dMiIbt16OrcYDHrnA2c5Ly8ru/nm0tIS5wNPTy8hxIzp86Nrx9w6WnBQSF5+bhXGBwBpUOwBAABwv3A4HDab7eZUvMFg+PnAj0qlUghRo0akECL1/Bnn5fcGg+Ho0UMBgUFCiOjouhqNpri4KKpTLecHdbpihUJxc2m9O++xko8JACodxR4AAAD3C7VaXTem/o6dW1q1altmMr27YnGbNu337NmRkXElPDyiXt0Gn3/+cc2o2t7e2v9btdzPP8D5KS8vr969+yWu+cDHx7dBg8a5udffe39pUFDI6wvevsO+XF1dXV1dT5w8FhNTP6ZOvZun8QOA7FDsAQAAcB+ZPGnmm0vmPv/CgNDQ8OeHj27YoMmZ0ydGj3121YfrX52x4M2l816aODIwIOiZZ54P8A9MTT3j/NSYUS95e3n/34fvFhYW+PsHtGvb8YXnx/7hvp4eNGz9v9ccOPDT11/uotgDkC8FZx8BAACgkpxPLr10ytihX0iFjFZWVmaxWry9vJ1PX55R65F0AAAgAElEQVQ4Sqv1mT1rUYUM/idlnDNcOV3Sa0RYVe4UAO6MGXsAAADIw/QZE4qKCye+NMPPz//AwZ+OpyTf+WR7AKgmKPYAAACQh1dnLHj/X2+9NmtSeXlZeHjE1CmzExI6SB0KAKRHsQcAAIA8+PsHvDpjgdQpAOC+o5Q6AAAAAAAAuHsUewAAAAAAZIxiDwAAAACAjFHsAQAAAACQMYo9AAAAAAAyRrEHAAAAAEDGKPYAAAAAAMgYxR4AAAAAABmj2AMAAAAAIGMUewAAAAAAZIxiDwAAgMqiUis8tCqpU1QklUbh5auWOgUA/ALFHgAAAJXFL8Ql64JR6hQVqeBamavHA/VVBYAHAMUeAAAAlSUgzMVDq7bbpM5Rccwme1htN6lTAMAvUOwBAABQiVo87LsjMUvqFBXjxN5im9VWs6GH1EEA4BcUDodD6gwAAAB4kF2/VPbDhryE3iHaQI2ruwwnlhyiMKf86hm9cNg79Q+SOg0A/BrFHgAAAJWu4Jr56O7ijFSDh5daf8NS4eM7HA6Hw6FUVsq3Bl4+GpWLonGCT2wHbWWMDwD3iGIPAACAqmMucygUFT/s3r17d+/ePW/evIofWgi1i6IyMgNAReFeHQAAAKg6Lm6VUpGVartdmDWu9G8A1ZEMr3ECAAAAAAD/RbEHAACA7KnVan9/f6lTAIA0KPYAAACQPavVWlRUJHUKAJAGxR4AAACyp9FogoODpU4BANKg2AMAAED2LBZLXl6e1CkAQBoUewAAAMieRqMJCQmROgUASINiDwAAANmzWCy5ublSpwAAaVDsAQAAIHsKhcLNzU3qFAAgDYo9AAAAZM/hcJSVlUmdAgCkQbEHAAAAAEDGKPYAAACQPRcXFxbPA1BtUewBAAAge2azmcXzAFRbFHsAAAAAAGSMYg8AAADZU6vVfn5+UqcAAGlQ7AEAACB7Vqu1uLhY6hQAIA2KPQAAAAAAMkaxBwAAgOwplUo3NzepUwCANCj2AAAAkD273V5WViZ1CgCQBsUeAAAAsqdQKJRK/rIFUE3x6w8AAACy53A47Ha71CkAQBoUewAAAAAAZIxiDwAAANlTqVQeHh5SpwAAaVDsAQAAIHs2m81oNEqdAgCkQbEHAAAAAEDGKPYAAACQPbVa7e/vL3UKAJAGxR4AAACyZ7Vai4qKpE4BANKg2AMAAAAAIGMUewAAAMieRqMJDg6WOgUASINiDwAAANmzWCx5eXlSpwAAaVDsAQAAAACQMYo9AAAAZE+pVLq5uUmdAgCkQbEHAACA7Nnt9rKyMqlTAIA0KPYAAACQPRbPA1CdUewBAAAgeyyeB6A6o9gDAABA9lQqla+vr9QpAEAaFHsAAADIns1m0+l0UqcAAGlQ7AEAACB7arXax8dH6hQAIA2KPQAAAGTParXeuHFD6hQAIA2KPQAAAGTPxcWFVfEBVFsUewAAAMie2WxmVXwA1ZbC4XBInQEAAAC4G6NHjz506JBCoVAo/vdnbY0aNb799lupowFA1WHGHgAAAHI1bNgwX19fhUIhhLhZ79u2bSt1LgCoUhR7AAAAyFWbNm3q169/65aoqKhnnnlGukQAIAGKPQAAAGRs2LBhgYGBzscOh6NNmzZRUVFShwKAKkWxBwAAgIy1adOmXr16zsdRUVFPP/201IkAoKpR7AEAACBvzzzzTGBgoMPhaN26da1ataSOAwBVTS11AAAAAOCetGnTpm7duiqVavDgwVJnAQAJcLs7AAAAVKn93xZmnjeq1IqinPKKGtNudzgcdpVKVVEDCiG8/DT+wS5xD/mG1XarwGEBoMJR7AEAAFBFTHrbR69d7tQ/1DtA4xvk4rBLHeiOyk22wuzyMweK4zr51mvhJXUcAPhdFHsAAABUBWOpbd2ijAGTa0sd5C/buyEnqp5bs06+UgcBgNtj8TwAAABUhZ++Lug6pIbUKe5G5wGhGedNNwqtUgcBgNuj2AMAAKDS2ayO9JN6/zAXqYPcJbWL8vplk9QpAOD2KPYAAACodAXXyqObyvgy9ZCabqVFzNgDuE9xuzsAAABUOrtdlBZZpE5x9yzlDrPJJnUKALg9ZuwBAAAAAJAxij0AAAAAADJGsQcAAAAAQMYo9gAAAAAAyBjFHgAAAAAAGaPYAwAAAAAgYxR7AAAAAABkjGIPAAAAAICMUewBAAAAAJAxij0AAAAAADJGsQcAAAAAQMYo9gAAAAAAyBjFHgAAAA+mr77+d5duraVOAQCVjmIPAACA+9Hly+mDBveWOgUAyADFHgAAAPejCxfOSR0BAORBLXUAAAAA4Nd27dr2xuLZQoiHurQcO+bl/k8OzsvL/dfKZUePHjKVmSIjaz498Llu3Xo633zqVMqHH624cOGcQqFo2KDJ3//+YsMGjX814MmTx1d9/N7ly2k2m61OnXojnh/brFkLKY4MACoeM/YAAAC473Tq1LVfv0HBwSHffPX9Y72ftFgsk18Zm5l1dd7cpas/2tDxbw8vfGPm/v37hBCZmVcnTRkTFBj83vLEFe+udvfwmDR5dF5e7q2jmUym6a9OqFUzesW7q99fsaZOdN2p08eXlJZId3wAUJEo9gAAALjvuLi4uLq4KhQKHx9fV1fXQ4f2Z2RceWXK7GbNWkRERA17bmSTJs2+/ubfQohN3250d/eYNnVunTp169SpO2PafKvVumPnlltHy8vLMRgM3br2rFmzdq1a0ePGTnp9wTsuGhfpjg8AKhLFHgAAAPe7i2mprq6uMXXq3dxSr17DtPQLQogLF8/Vq9tArf7PFaYeHh6RkTXT0y/c+vGIiKjIyJoLXn917brECxdTVSpVXFy8m5tblR8HAFQKij0AAAAqks1mE0Lk5OScPHlSp9MJIZKSkrZv32632+96TL1B7+bmrlAobm7x9PA0Gg1CCKPR4OnpdeubPf770k0qlerdt1d16th169avR44a8vQzj+3cufWuwwDA/YZiDwAAgN+l1+vLysqEEFeuXElKSsrNzRVC7Nmz5/33309PTxdCrFq16h//+Mfx48eFENOnT2/dunVycrIQ4uOPP162bNn169eFEFlZWaWlpUIo/sQOb8/L08tkMjocjptbDP/t856eXgaD/tY3Gwz6X1V9IYSvr9/oURM+/2zT6o82tGje+vVFs86z6j6ABwXFHgAAoLowmUzZ2dl6vV4Ice7cuW3btmVlZQkhtm3btnDhwtOnTwshVq5cOWjQoKSkJCHEpEmTevXqlZKSIoTYsmXLF198UVRUJIQwGAyurq7u7u5CiISEhJEjR9atW1cI8dprrx04cKBNmzbOkr969eqGDRsKIQYNGvTUU0/dOt/+V9Wv18hsNl+4mHpzy9kzJxs0aOx86fyFcxaLxbm9VF+akXGlwS9Xxc++fi0paa/zca1a0S+/NF2pVF65nP6XMmRnXz979uytXy4AwH2CYg8AACA/znqp0+lSU1MLCgqEECkpKevXr09LSxNCbNq0afr06c6Z87fffrtHjx67d+8WQixdunTkyJGnTp0SQiQnJx84cMBgMAghPD0969evHxgYKITo3r37/PnzW7ZsKYRYsmTJvn37EhIShBDjxo175513nEX9sccee+GFF8LDw4UQTZo0iY+P9/LyEkK4u7urVCqr1SqEOHnyZGJi4vnz54UQ8+bNGzFihN1u+0vH6OXlXVhYcPLk8Zyc661bt6tZs/bSpfPPpZ65lp314aoVqefPPtX/GSFEnz5PlZeXLV4yNzPz6qVLafMXzPD09Hr0kd63DpWXmzNrzpQNX3yWkXElM/Pqp5+tUiqVjRrF/qU8WVlZr7/+enl5uRBiyJAhEyZMcF5csHv37tTU1D8xAABUFtXs2bOlzgAAAFCtmc1mq9WqVquvX79+7tw5pVLp7e196NChbdu2ubq6BgcHf/XVV++9955Wq42Kilq6dOmUKVNCQ0Pr1av3wQcfrFu3LiYmJjIycv/+/RkZGfXr1w8ICNDr9cHBwQ0bNvT09KxTp07fvn0bNmyoVCo7duw4ePDgyMhIIUSzZs0efvhhZ5mvVatWo0aNnOXc19fX39//5lp0d+BwOBQKRXp6+g8//KBQKIKCglauXDlp0qTatWvXrl17165dJSUlzZs39/b2jo2N7fVo/6wLZTHNtX/+nyU4OPTgoaQvv1rn7u4e36J1u7adUs+f+eTT/9v45VqTyTjhn1PbtGkvhNB6a5s1jd/34+7ViSu/2/FtSHDoq9MXhIWFCyHOpZ45cuTAc8/+PTQ0PCw0/NstX65dl7ht+yaj0Thh/NTGjZv++TD5WWXXsq43ahnUokULhULRvHnzyMjIqKgohUKxcuXKHTt29O3b12w2Dxw48MiRI4888ojZbP7hhx/MZrPzXxgAKpWCs4kAAAAqkNVq1el0Li4uWq32ypUraWlp0dHR0dHRSUlJhw4d6tixY6tWrdauXbt9+/YhQ4Y8+uijixcv/vrrr2fMmNG7d+/ExMRDhw4NHz68devWu3btunTpUpcuXWJiYs6ePVtSUtKgQQNfX9/S0lKNRlP1K7rn5uaeOHEiPDy8SZMmX3zxxZo1a55//vl+/fqtXbv2ypUrAwYMiImJyc7O9vb29vb2/u3Hr18uS9pU0H14RBXHrihnD+guXbxSIH4aPXq0Wq1++OGHGzZs+N5771mt1jNnztSvX9/5E7l8+XJubm5CQkJ5efmsWbN0Ot3KlSt1Ot3f//73+vXrz58/32AwJCUl1axZs0GDBlIfE4AHB8UeAADgTvR6fV5enlarDQwMPH/+/JkzZxo0aNCoUaN9+/b98MMPDz/8cMeOHT/77LONGzcOHTr0ySeffOedd7Zt2/biiy/27t17w4YNx44d69+/f8uWLX/++ecrV660bdu2du3aV65cMRqNUVFRXl5eNptNpVJJfZT/o9frT58+7e3t3bhx4++//3716tXdu3cfOnTohg0bjh8/PnDgwLi4uMzMTLVaHRYW9ueHfQCKvdlk/dsT/5l+v3HjxqVLl5o3b242m0eNGpWXl7dlyxadTrd27dqmTZt26NDhVx+/dOlSQUFB69at9Xr9woULzWbzkiVLsrKyJkyYEBcX9+qrr+p0uiNHjkRHR9epU0eK4wMgbxR7AABQXZjNZhcXl6KiooyMjICAgMjIyDNnziQnJzuvEt+5c+f27dsfffTR7t27JyYmrlmzZtiwYc8991xiYuLWrVtfeOGF7t27b9++/dixYz169GjRokVKSkpWVlZcXFxERERubq7FYgkKCnJ1dZX6KP8ss9l84cIFpVLZqFGj5OTkjz/+uFWrVsOHD//yyy/37NkzYMCATp06Xbp0yWw2R0dHu7i43OPuHrBif1vl5eWfffaZTqebOHFienr6q6++2rlz55EjR5aWlppMpuDg4F+93+FwXL16VafTxcXFFRYWvvnmmxqNZt68eampqdOnT2/Xrt2kSZNyc3NTUlLq1q0bHR1dyYcIQMYo9gAAQJZu3LjhcDh8fX0LCgrOnTsXEBDQqFGj06dPHzlypG7duh06dPjuu+82btzYvXv3/v37JyYmrlixYsKECUOGDPn3v/+9a9eugQMHduvW7ccff0xJSenYsWNcXNz58+dzc3Pr1asXGhpaWlrqcDi8vb3vZSH3+0dmZmZ5eXlMTExqaupHH31Up06dUaNGbd++ff369U888UTfvn3T09MLCgoaNGjg4+NTSRmqQ7H/lQsXLuTl5XXo0CE9PX3cuHGNGzdesmRJenr6qVOn4uPjnSsd3JbD4cjIyCgtLW3SpMn169eXL1+u1WqnTp2anJz8xhtvdOnSZfTo0ZmZmc6TR2rVqlVBhwhAxij2AABAemazOS8vT6VShYWF5ebmJicnBwYGtmnT5syZM19//XVsbGyfPn22bt2amJjYpUuXUaNGbdq06Z133unXr9+4ceOSkpI2btzYtWvX3r17p6SkXLx4sXHjxo0aNbp69WpxcXFUVJS/v395ebmM5tLvWklJiU6ni4qKunbt2urVqwMDA0eNGrV79+7ly5f36dNn+PDhly9fvnz5cqNGjUJDQ6s4WzUs9r9iNBo9PDyys7M//vhjX1/fcePG7d2799tvv3388cc7d+5cWlp627UJbmW32zMyMkwmU8OGDa9cubJq1arQ0NBx48b98MMPy5cv79279/PPP5+enp6Wlta4ceOICLn+UwO4CxR7AABQkZyru9tstosXL5rN5qZNmxoMhs2bN6vV6v79+1+7dm358uVRUVFjxoz56aefFixY0Lt373Hjxm3evHnVqlU9e/YcOXLkkSNHNm/e3LZt2x49eqSlpZ06daphw4YNGjTIz88vLS0NCgr6w/7zwLPb7dnZ2RERETdu3Pj666/LyspGjRqVkpLy0ksvPfroo1OnTs3IyDh69GhsbGxMTIzUYf+DYv9bJpPp8OHDKpWqQ4cO27dvnzNnzvjx4wcPHnzq1CmDwdCsWTN3d/c/M45zht9sNtetW/f8+fNr1qyJjo4eMWLEpk2bEhMTn3vuub59+yYnJzsv8vf396/AQwBwn6DYAwCA32W1WsvKyry8vHQ6XVpampubW5MmTXJzc7/99ltvb+9Bgwbl5+fPnj3bzc1t6dKlBQUFffv29fHx2bp1q06nGzt2bGRk5BtvvFFUVPTxxx/XrFnzqaeeKi4uPnr0aI0aNRo2bKjX68vKynx9ff/MndWqLedErtVq/eSTT3JycqZPn26xWNq1a9e4cePExMSCgoK9e/fWqlWrZcuWzq9UpM77uyj2f8hqtRYXFwcFBR0+fPiTTz5p167d4MGDv/zyy8uXL/fr1y86Ovqv/ogdDkdmZqbdbq9Vq9bBgwc3b97crVu3zp07z5s379ixY1OmTGnbtu2hQ4eKi4ubN28eEhJSeYcGoLJR7AEAqEZKSkqMRmNoaKjFYtm/f7/Vau3atavBYPjwww9dXFzGjBmTnZ09bdq0GjVqLFy4MDk5eezYsb169Zo5c+bevXvXr1+fkJAwbNiwrKysLVu2REVF9ezZ02AwnDp1KiAgoG7duna73Ww2V/1t2B4YdrtdqVRu3rz50qVLL774oslk6tGjR3Bw8MaNG81m84cffhgREdGnTx/n3eOlDvuXUezvTmZm5v79+2NiYlq2bDl16tTz588vWbKkTp06zstV7u4Ce7vdnpWV5ebmFhwcnJSU9N133yUkJPTu3Xvx4sUHDhyYMWNGy5Ytd+/ebbFY2rdvzwkygCxQ7AEAkCur1VpQUOBwOMLCwgoKCg4fPuzh4dG5c+ecnJzVq1d7enqOHz8+Ly9vzJgxnp6ea9asKSws7N+/f1RU1Jo1a0pKSubOnRsaGjpp0iS9Xv/NN9+EhIR069bNZDKlp6cHBASEhYU5e6bUR/kAcjbz3bt3Z2RkPPfcc0ql8umnn7548eKePXu0Wu1bb70VGBg4dOhQh8NhMpk8PT2lzlsxKPYVIiMjQ6vV+vr6rly5cteuXZMnT05ISFi1apW7u/uTTz55j1+r2Wy2a9eueXp6BgQEbNu2bf/+/QMGDGjWrNkrr7ySlpY2bdq0li1b/vTTT2VlZW3btvXy8qq4wwJwryj2AADcL5wrY5WVlTVo0MBisWzZssVqtT711FN6vf7NN990dXWdPn16Zmbm6NGjIyIiVq5cmZKS8uqrr3bs2HHKlCknTpzYuHFjbGzsgAED8vPz9+3bFxYW1r59+/Ly8uzsbF9fXz8/P6mPr5o6ffr0xYsXO3fu7OfnN2nSpOTk5K+++srf33/69Onh4eFjx45VKBQ5OTlVv5pdFaPYVwbnl0RJSUmHDx8eOnRoUFDQkCFDfH19Fy5cqNVqL1++XLt27Xvfi9VqzcrK8vLyCgwM3Llz5549ewYNGhQXFzdu3Li8vLw333yzZs2a3333nYuLS9u2bf/kugAAKhbFHgCAylJeXp6RkaFQKGJiYnQ63c6dOzUazRNPPFFcXLxo0SIXF5e5c+fqdLqnnnrK1dV1y5YtJSUlzz//fGho6IoVKwwGw7Jly0JDQ0eMGGE0Gvfs2RMSEtKqVSuz2VxUVKTVaj08PKQ+PvxCZmZmWlpafHy8VqudNWvWiRMn3n777Vq1as2fP18I8eKLL/r4+KSnpwcHB1fPc5sp9lWjqKjo/PnzsbGxXl5e48ePP3z48MGDB3U63TfffBMfHx8bG1uB+7JYLBkZGc7/S69du/b48eMjR46MiYkZP358fn7+3Llz69atu3PnTjc3t7Zt22o0mgrcNYBfodgDAPDHbDabSqWy2+3nz58vLy+Pi4szm81ffPGF3W4fOnSoTqebM2eOh4fHggULrl69OmzYsIiIiE8//fT06dPz58+Pj4+fPHlyVlbW559/XrNmzUGDBun1+oMHDwYGBsbFxdlsths3bmi12vt52TPcqqSk5NKlSzVq1AgKCkpMTNy3b9+ECROaNWs2Y8aM8vLyGTNm+Pn5HT9+PCgoiPuN3YpiLyGTybRq1SqLxfLyyy8fOXJk1apVPXr06Nu3b0lJiYeHR4X/8jEajVlZWcHBwb6+vp999tnRo0cnT54cHh7+7LPPKpXKd955x8fHZ8eOHX5+fvHx8SqVqmL3DlRPFHsAQHXkXFzaarWmpqZarda4uDiTyeQs6sOGDTMajdOmTbPZbCtWrNDr9d27d3dzc/v+++8NBsPIkSNDQ0OXLFliNBpXrlwZHBw8ZMgQk8l05MiRwMDARo0aWa1Wo9Go1WqlPkTcK+eK4h4eHoGBgV999dVPP/00YsSIxo0bT506taCgYOrUqTExMUeOHHF1dW3UqBHfy/whiv19wmq1pqSkmEymv/3tb0eOHBk3btzAgQNffvnlrKysrKysRo0aVd6vr+Li4qysrLp167q5ub3zzjupqanz5s0LDAwcMWKERqNZvHixt7f3999/HxYW1rhx40rKADyoKPYAgAfBzRn1c+fOlZWVxcfHl5WVbdiwweFwPPfcczqdbubMmV5eXgsXLkxPT3/22Wfr1KnzySefXLt2bfr06dHR0bNmzSotLf34449DQkIGDRpkNpsPHz7s6+vbpEkTh8NRVlbGVaMPNr1ebzAYQkJCTp8+vWnTphYtWvTo0ePNN9/8+eefnSuE7927V6lUtm7dmjX/79r1y2Un9t1o/4Rc76l24ViJxWRN6PkA3gQ+Nzc3JCTkypUrS5YscXNzW7JkSVZW1saNG9u3b9+qVauqCXD16tXY2Fh3d/dZs2ZlZ2d/+OGHhYWFY8aMadGixSuvvKLT6c6cOVO7du3w8PAqyAPIEcUeAHD/stvtFy5cMBgM8fHxVqt13bp15eXlI0aMMJvNU6ZMsVgs7733XllZWdeuXdVq9d69ew0Gw+jRo8PCwhYtWqTX6z/66KPQ0NCBAweaTKZjx44FBgbWr1/farVarVbqWbWl1+u9vLycd+wLCQl54okntm3btmjRouHDhw8bNiw5OTkjIyMhIYH+UOFMetvnb2QMnFwBa7lJ4tC2/JBIl9gOPlIHqQpGo/HLL7+02WzDhg377rvv1q5dO3To0G7duuXl5Wm12ir7/ZmWllZcXNyqVau8vLz58+c7v5w9efLku+++27Fjx2effbagoCA7O7t27drVc90K4FYUewBAlUpLSzMajU2bNrVarRs3brTZbM8884xOp5s/f75KpVq0aFFxcXHfvn01Gs3NU98DAwPffvtts9n8/vvv+/v7P/vss1ar9eDBgz4+PrGxscyo4w7y8/N//PFHrVbbrVu3pKSk6dOn9+zZc+rUqSdPnjx06FCbNm2aNm1qNptdXFykTlotbPpXdru+oW4esryH4s+b8mI7aMOjq913gg6H4+zZs3a7PTY2dvPmzW+88cbEiRP79et38OBBIUSLFi2q+D8fi8Vy+vTp8vLyhISEixcvLly4MDw8fMGCBadPn16zZk3btm379eun1+t1Oh2LXKBaodgDAO5JTk6OTqeLjo52cXHZtm1bfn7+wIED3dzc5s2b57wNkpubW8+ePQsLCw8dOmSz2QYPHhwUFLRixYqysrLly5eHhIQ8++yzRqPx8OHDgYGBTZo0sdvtRqOROyTjL9Hr9SdOnPDy8mrWrNnevXvffffd1q1bT506df/+/fv27evcuXO7du1KSkpUKtUDc1t4Obpy1nj0++JHnqshdZC/7NyhG7q8skeGyPU6gopVUlKi1Wr37du3YcOGHj169O7d+9///rdOp+vTp4+Ed200Go0HDx602+1du3ZNT0+fOHGin5/f6tWrs7KyPv3004YNG/bt27e8vNzhcHDGFh5IFHsAwC+UlJTodLqQkBBXV9ekpKScnJxu3br5+PisWLHi6tWrU6ZMCQoKGjVqVGpq6rp168LCwl544YXy8vIVK/6fvXsPiCn//wd+qqmZaqrpfpWkK0Uld7kVlQrZakkkcglr3e+X2LXu67IXobWhlV0tpZa1yqWLtSQkKl1kpItuU0013WZ+f8zn5+PrgyVN7+b0fPyVmel9nsPumXmd8369399zOJyDBw/KyMjMmzePxWJdvXqVxWINGTJEVlaWx+Ox2WysLgafTigUFhQUCAQCGxubrKys7777rk+fPosXL7506dKlS5d8fHxGjhxZXFzc0tJibGwsIyNDOi+86Wlm/d1E3ujP9ZmK0nHfvq1V9CiVx+c1u85EVf9Oubm5165d69ev35AhQ7799tuCgoIFCxbY2NhUVlZqamqSzdbQ0HDx4kU+nz9r1qzCwsKAgABHR8cDBw4UFBRcu3bNwcHB3t5evJwq2ZwAnwiFPQAAzbW2ttbV1amoqDAYjLt375aVlY0cOZLNZh8/fpzL5S5cuFBHR2f58uVZWVlhYWE9e/acPXt2dXX1jz/+qK+vf+DAAYFAsGDBAg6Hk5CQICsrO2zYMBaLVVZWpqysjJvqIFECgaCiosLIyBBQBfQAACAASURBVKi0tDQ8PJzNZi9dujQ1NfXQoUPu7u6zZs16/vx5cXGxpaUlh8MhHRY+wrOshnvXeZXFTQa9leqqWzpqWJFIJBKJZGU78npBW4uoprK5/0jOUA/C1akUaWhoePDggYaGhqWl5XfffRcdHX3w4EE7O7u0tDQtLS0TExPSASkej8fhcCoqKn777TdlZeXAwMCkpKTQ0FBfX9+QkJCcnJz8/Pz+/fsbGkrf1BLozlDYAwBIH/GpW0ZGJjs7m8fj2dvbM5nMqKio0tLSOXPmqKqqrl69msvlHjx4ULw2WF1dXWRkpJ6e3tdff93U1LRixQoOh3PhwgVZWdmxY8cqKSlxuVwWi6WtrY07nECEQCBgsVh8Pj86Orq1tTU4ODg7Ozs4ONjFxSU0NLSoqCgtLa1Pnz4WFhakk0KHaahrq6lo6cAvonfv3r19+3ZISEhHDUhRlBKbwdGR78ABuyE+n9/a2srhcI4fP/7HH39s27atb9++kZGR2trazs7OXec+eU1NTV1dnZGR0ZMnT06dOmVqahoUFHThwoWzZ89+/vnnnp6eT58+5fP54r36SIcFeAsU9gAAXUhJSUldXZ24eomLi6uqqpo+fTqDwdi0aVN5efmBAwdYLJanp2dpaen169fZbPbixYspitq5cyebzY6IiGAwGD4+PiwWKzMzk8lkmpqaysnJkX5PAG9qampKTk6uq6vz9vZ+8eJFUFCQkZHR8ePHi4uLz507Z2trO2rUKMyMhY917969O3fuzJs3j3QQeB+RSCQjIxMXF/f3338vWbJET09v9erVRkZGCxcu7IL/y7e0tOTm5srIyFhbW9+6dSssLGzIkCELFiy4dOlSamqql5fX4MGDKyoqWCwWprABcSjsAQAkSCQS1dbWqqmpiUSimzdv8vl8V1fXtra2/fv38/n80NDQtrY2X1/f2trahIQEiqI8PT1VVFQiIyPl5OR27typpKS0aNEiOTk5cRnv4OAgKysr3qyL9DsD+HcikSg3N7eysnLo0KEVFRVr166lKCo8PLyoqOj777+3s7ObOnWqQCCor68n3oULAKQ8ePDg/v374lVXJ0yYYGZmdujQIZFIVFVV1WXPDBUVFWlpaZqamgMHDoyPj9+zZ494v8ykpKS8vLzRo0ebmpq2tbXh2jp0JhT2AADtIRKJnj59Wl9fb2tr29LS8uuvvzY1Nc2ZM0cgEKxYsaK5ufnYsWONjY1OTk56enrx8fEtLS0rVqzQ1NTcsmWLeJs3Dofj5uZGUdSzZ8/U1NTQJAxSraWl5cWLFyYmJg0NDd9++219ff2OHTuKiopWrVplb2+/evVqPp+fl5dnYmKC/9RBQqqqqqqqqszMzEgHgfbj8XiPHj0aPny4UCh0c3NTU1M7e/asQCDIzMy0tbVlMpmkA75TY2OjoqJibm7uX3/9ZWlp6eLiEh4eHhMTs3jxYjc3twcPHtTX1/fr1w/X5UFyUNgDAPxHa2trbW2thoaGUChMTk7m8/keHh5NTU179uxpaWnZunVrfX29n5+fUCi8dOkSn88PCgrS19c/dOiQQCA4fPiwtrZ2QEBAa2trWloah8OxsrIi/YYAJKitre3MmTPl5eVLly6trq52d3d3cHD48ccf+Xx+QkKCmZmZjY0N6YzQvSQmJl6+fHn37t2kg0CHKS0t1dPTEwgEX375ZVlZWUxMTHV19Y0bNwYMGNCjRw/S6f5daWmpUCg0MDBISko6e/bs6NGjP/vss5MnT2ZkZAQEBNjZ2RUXFysrK6upqZFOCnSAwh4AuoXnz59XVVXZ2NjIycn9+uuv1dXV8+bNk5WVXbBgQX19/alTp5qbm0eOHKmlpRUfHy8QCNavX6+jo7N27drm5uY//vhDU1Nz5MiRQqHw5cuXHA4HC+dAt3L//v38/PxJkyYxGAxvb++XL1+mpqY2NTX98MMPFhYWnp6eQqGwY5ciB2iH3NzcnJwcT09P0kFAgvh8/oEDB/h8/s6dO58+fRofHz9y5Mj+/fuTzvURqqqqMjIydHV1ra2tIyMjjx8/vnz5ck9Pz7i4OB6PN378eF1dbKwI7YHCHgCkVWNjI4PBkJeXf/To0YsXLwYNGsThcCIiIvLz85ctW6ahoREcHFxQUHDu3DkOhzNz5kwGg3H48GEmk3nw4EFlZeU5c+bIyMjcuXNHTU0NS20DiL8xFxYWmpiYsNnsvXv33r179/vvv9fU1Fy6dKmOjs6aNWvk5OS4XK6xsTHppAAAlHgfjaampvnz59+6devChQteXl5Dhw4lneujNTc3KygopKenJyUlOTk5DRgwYO3atQUFBdu2bbOysrp165aKioqVlRU69uH9UNgDQJfD5/Orq6t1dHSYTGZSUhKXy3V3d9fU1Dx48GBWVtbatWtNTEyCgoJyc3PDw8OtrKz27t1bWVm5dOlSXV3d+Ph48RZuLBYLM9wA3kUkEgmFQjk5ud9++y0nJyckJERLSysgIEBOTm737t26urqpqana2tq45gVSpLKysqKiwtLSknQQIEAgENy4caOtrW3ChAnnzp27ePHi7Nmzhw0bJm59J53uo4lEooKCAjU1NS0trRMnTiQmJq5atcrW1nbHjh0MBiMkJITNZldXV6urq5NOCl0ICnsA6FSlpaVlZWW9e/dms9nx8fH5+fnTpk3T0dHZtGlTVlbW/v37e/ToMWvWLB6Pd/jwYX19/R9++KG5uTkoKIjD4dy6dYvBYIiXz8FWWAAfJSMjIz8/f/z48crKyoGBgY8ePUpISOBwOD/99JOmpuaECRMUFBRIZwT4JOixh1fu378vFAodHBx++umn+Pj4DRs2ODo6VlRUaGlpkY72STIzMzMzM11dXdXV1WfOnMnlcs+cOSNeo1dDQ2PQoEH4atSdobAHgA4gLrO5XC6XyzU1NTUwMLh48eLdu3d9fX2trKw2b9588+bNvXv32tnZrVq1qrKy8quvvjI0NIyKimppafH29lZRUcnKymKxWMbGxphpBvApRCJRYWGhtrY2m80+ePDgvXv3du7cqaent3LlSg6Hs3LlShaL9eLFC0NDQ9JJATpYbm5uVlbWxIkTSQeBroXL5QqFQhMTk7CwsLNnz+7cuXPgwIH06Cqqq6uTl5dnsVinTp26ffv2smXLTE1NQ0ND5eTkFi9erK6uToNrGfDhUNgDwPs0NTXJysqK+9ifP3/u6OiopaUVGRmZmZk5e/ZsCwuLtWvXXr169eDBg0OHDj106FBBQUFwcLCNjc3Vq1dra2tHjhypoaFRWlrKZDIxYQygwzU1NTGZzLS0tJSUFDc3Nysrq7lz51ZXVx86dMjAwOD69etaWlp9+vTBynYAAOLt9AQCgZ6eXnh4eFhY2JEjRwYMGJCdnd27d295eXnS6TpGbm6ueMtAbW3tJUuWpKennzlzxsjIKC4uTltbe9CgQfhEoCsU9gDdF5/PZzAYLBYrMzPz6dOnAwcO1NPTi4iIuHfv3qJFiywsLBYsWJCRkXH8+HFxH3t1dXVISIiRkdG1a9daW1uHDBmioqJSV1enpKSE2+wAnYDP5z98+FBZWblfv34XL17cv3//okWLJk+e/Pvvvzc0NHh5eWGLeOjOioqKuFzusGHDSAcB6SASiWpqajgcTlhYWERExKlTp8zNze/du2dtbU2nvW8aGxtlZGRYLNbx48fT09NDQ0O1tLSWL1+uo6OzatUqWVnZ+vp6NptNOiZ0ABT2APRUV1cnIyPDZrNzc3MzMzPNzc1tbGwuXLhw+fLlzz//fOTIkRs3bkxOTt63b5+jo+ORI0dKSkrmzJnTo0ePW7dutba2Ojg4KCkpCQQCOn22AUgXHo/H4XAyMjLOnj3bv39/Hx+fX3/9NTk5eerUqSNGjCgpKWEymRoaGqRjAnQV6LGHT1FfX6+srLxz5874+PgLFy5oaGikpKQ4OjrS8otQRkbGkydPJk+eLBKJxo0bZ2RkFBkZWVlZeefOHRsbGyMjI9IBoT1Q2ANIH4FAQFEUi8V69OhRXl7egAEDjIyMTp8+ffPmzZkzZw4aNCg0NPT69esbN250cXGJiYnJzMz08PCwt7d/9OhRXV2dtbW1mpoaFp8D6FIaGhpu3rzZ1tbm6up648aN1atXBwcHz507Nz09vbS0dODAgdra2qQzAnRpGRkZ9+7dCwwMJB0EpJ74O9KKFStycnLi4+MrKiry8vIGDhxI1/mJ5eXl2traPB5v7969TCZz06ZNN2/evHjx4rhx40aNGiXejY90Rvh3KOwBuhxx0+zTp09zcnKsra179uwZHR198+bNgIAABweHNWvWpKam7t+/f+DAgeHh4cXFxTNnzjQxMUlPT29ubraxsWGz2UKhEA1UAF1ZaWmpnp5eYWHh4cOHNTU1V69enZ6e/ttvv40dO3b8+PF1dXWKioq49AYA0BVUVVVt3ry5paXlyJEjL1++LC4utrOzIx1Ksvh8fkpKCkVRbm5u169f/+abb/z9/WfNmvX8+fOmpiYzMzPSAeEtUNgDdKq2tjY5ObmKiors7Gx1dfW+ffump6efO3du6NChHh4eR48ePXr06KZNmyZNmnTixIknT57MmDHDysrq9u3bjY2N9vb2qqqquG4KIHVaW1uTkpJ4PN6UKVMePXoUGBjo4+Ozdu3awsLCvLy8fv366ejokM4IIPWeP39eWFjo5OREOgjQWVlZ2fr16+Xk5I4ePfry5cuGhgYTExPSoSSusrKyurrazMzs7t27u3fvHjhw4MqVK1NTU0tKSkaPHo2F97sIFPYAHaympub58+daWlp6enopKSl///23k5PTkCFDjh8/fuLEiblz5wYEBJw7dy4pKcnT09PFxSU7O7uwsFDc0dTQ0KCkpET6HQDAJ6msrNTU1Kyrq9u7d29NTc2BAwcqKyt37tw5ePBgHx8fLF0BICHosYdO09LSIi8v//z582XLlllbW3/11VelpaVqamqKioqko3UG8czQ7OzsmJgYOzs7Nze3sLCwoqKiwMBAc3Nz8cxT0hm7IxT2AB+nsrKSoihNTc1Hjx7dvn3bzs7O3t7+9OnT586dmz179oQJEw4cOHDv3r3FixcPHDjw2rVrZWVlI0aMMDIyqq6ulpeXx7qjAPSTnZ2dl5fn6enJ4/E+++yzXr16hYeH83i8lJSUPn36mJqakg4I0C1gH3sgQrzQaXp6+pIlSxYvXjx16lRxyzrpXJ2qoqLizp07RkZGtra2e/bsSU1N3bRp04ABA54+faqrq4u7Vp0DhT3A/yFeLqW6ujo9PZ3JZI4YMSI7OzssLMzGxiY4ODgyMvLkyZPz5s3z8fG5cuVKTk6Oq6urubn5s2fPhEKhkZERbTZBBYD3O3nyZFZW1vr161VUVObOnWtmZrZmzZrm5uaGhgbsOQcA0D29ePHC0NDwl19+OXny5MGDB62srLrnWsVFRUWysrIGBgbHjh07efLkd999Z2dn99dff+nq6vbv3590OtpCYQ/dTktLS2lpqYKCgq6ubkZGxrVr1/r16zdmzJiYmJgDBw5MmjRp2bJlt27dOnfu3KBBg3x8fIqLiwsKCszMzPT09EhnBwAC8vPz9fT0lJWVly9ffu/evcuXLysoKISFhZmamjo7O9N1kWQAqfPy5cuysjJbW1vSQQCoioqK1tZWPT29qVOn6ujoHDp0SCQSycjIkM5FhrgHLSoq6sqVK9u3b9fX1z906FDPnj09PDy64VUPyUFhDzQk7vyprKy8d++elpaWnZ3djRs3oqKiXFxcfHx8wsLC/vzzz/nz57u7u6empubn5w8dOtTc3LympkZOTg5T5QGgqKgoPT3dzs7O2Nj4yy+/LCkpCQsL09DQuHfvXu/evVVVVUkHBIC3QI89dE3//PPP4MGDBQLB7NmzPTw8pk+fTjoReX/++eft27dDQkK0tbXXrVvXo0ePefPmocj/RCjsQVrV1NTweLyePXvy+fzIyEgGgxEcHHz//v2VK1cOGTLk66+/vn79+qVLl9zd3UePHp2Xl1ddXW1hYaGmpkY6OAB0RWlpaYmJiZMmTbKystq0aRODwVi4cKG2tnb3nEUJII2ysrIePnzo5+dHOgjA2+Xk5Ny5cycgIODJkyeXL1/29vY2MjIiHYq8Bw8epKWl+fv7Kyoqent7Dx8+fOXKlVhoth1Q2EOXJhKJsrOza2trBw8ezOPxvv32WwaDsXnz5oKCguDgYHt7+3379lVXV0dHR5uZmY0ZM6ahoaG5uRkNrgDwfo2NjYqKiikpKZGRkc7Ozr6+vmfPnhWJRB4eHsrKyqTTAQAAnTU3N58+fbq+vn7RokVpaWlKSkp9+vQhHapL4HK52dnZ48ePz8vLCw4OFnfIij+ySUeTAijsoUtobW39+++/a2pqPD09Gxoali1bVltbGxUVVVNTs2jRIisrq40bN9bU1KSkpJiYmPTt27c79ykBQPuUlJTo6+tfuXLlwIEDc+fOnTx58t27d0UikZ2dHe7JA9AAl8stLCwcOXIk6SAAHyEzM3PXrl1eXl5+fn4VFRXYE/6Vurq6vLw8e3v7wsJCX19fX1/f1atX83g8NTU1VAFvhcIeOtvly5d5PJ6vr69QKPT3929oaIiPj+fxeKGhob179/7iiy+am5szMjL09PQwPQkAPkVTU9Pz58/NzMwePnwYHBz8xRdfBAQE5OXlsdlsrIUJQD/osQfpxefz2Wx2WFhYUlLSt99+iw+pNwiFwtzcXEtLy4cPHwYFBX3xxReBgYHFxcUGBgako3UhKOyhg4lEIqFQKCcn98cff3C53JCQkLa2tkmTJpWWlqalpVEUtXnzZjMzsxkzZohEoqdPnxoYGGB2DQB0FIFAkJ2dbWdnd//+/YULF86dOzcoKIjH47HZbNyWB6A37GMPNJCTk6OsrGxkZLRt27ZRo0aNGjWKdKKuiMvlGhsbnzt37rvvvtu8efOYMWPKy8u1tbVJ5yIMhT20X1tbm5ycXEJCQkFBgb+/P5vNDgoKevjwYUJCAofD2blzp5aWVnBw8KsZsKTzAgBt3b9/387Ojs/nu7m5TZkyZfny5eK7H6RzAQAAtId46+Xdu3fX1tbW1tZiHutbiUSi0tJSfX39kydPnjx5cufOnY6Ojt32CwAKe/hQd+/ezcnJGTt2rJ6e3uLFi9PS0uLj47W0tPbs2aOqqjpr1iwmk4nWIADoNIWFhZqamoqKikOHDh0/fvz27duxgj1Ad1ZaWlpSUmJvb086CEBH4vP506dPd3d3X7BgAeksXVp1dXV9fb2RkdHGjRu5XO7BgwfV1dVJh+pUKOzhTU+ePHn+/LmzszNFUYsWLcrPzz99+rSGhsa+ffsoigoKCtLQ0Hjx4oWuri6+QANA5xNfiV+wYEFFRUV4eLh4V3lZWVnSuQCAsOvXrycnJ2/atIl0EICOl52dbWVlFRERwWQyp02bRjpOV/fo0SN9fX0NDY0JEyYMGzZsw4YN3WG9PRT23ZdQKHz27JmhoaGCgsI333zD5XLDwsLa2toCAgJ69er1zTffiGe3GhkZ4SY8AHQFcXFxu3btioyMNDExKSsr09XVJZ0IALqQhw8f3r9/f8aMGaSDAEhKXV3dkSNHrKysPD09u+2E849SWVmZnJw8ceLE1tbWjRs3enl5OTk5kQ4lKSjsu4vm5mYFBYWMjIwrV664urra2NgEBAQIBIKff/5ZRUUlPj7eyMjIzs6OdEwAgP+juLj48OHD9vb2U6ZMyczMNDMzY7FYpEMBAAAQFhISYmJismbNGtJBpEZiYuKDBw+WL1/++PFjLpc7fvx4mk33Q2FPT5WVlTk5Ob1799bV1T106FBsbOyaNWvGjx9/5cqV8vJyd3f37tZzAgDSpbCwMDMz09PT8/r16w0NDe7u7t1hEh0AfIoXL148f/58yJAhpIMAdJLY2NhJkyYVFhaqqKhoamqSjiM1Kisr9+/fr6Ojs2TJksLCQhMTE9KJOgYKezoQCAQsFuv69evXr1/39fXt27fvmjVrGhoa1qxZY2Rk9PTpU3V1dQ6HQzomAMAHefHixZdffrl06dIRI0aQzgIAUgP72EP3VFFR4e/vv27dujFjxpDOIn0SEhK2bt168OBBBwcH0lk+FQp76dPW1paVlSUQCBwdHS9evLhv375Vq1a5ubnFx8eLRKIxY8ag3wYApNH169e/++6733//XXyxknQcAJAy2MceurP09HQHB4erV6+OHTuWdBYp09DQUFxcbGZm9vXXX5uYmAQEBJBO1E4o7KVDUVHRlStXNDU1J06cePny5aioqEmTJnl7e5eUlCgqKuJuPABItaqqKg0NjYiICFdXV319fdJxAAAApNKFCxeOHj0aHx9POohUKikpOXPmzIIFC+Tl5R89etS/f3/SiT4OCvuuqLa2VlVVNTMz86effurbt29wcHBCQkJ2draLi4uVlRXpdAAAHaa5uXnZsmVr1qwxNjYmnQUApBt67AEoiiotLdXT08vLyzMyMsL0t/YRCoXBwcFaWlrS1dqDwr5L4PP5OTk5AwYMKCoqCg4OdnJy2rBhw6NHjyorKx0cHDC1HgDoKiEhgc1m44s4AHw69NgDvMLj8Tw8PKKionDdvN0KCgpMTU0TEhJevHgRGBhIOs6/Q2FPTH5+fm5urpubW319/YQJE+zt7Q8cOFBXVycQCLS1tUmnAwCQLC6XW1xcjJIeADoK9rEHeMO9e/fs7e1Jp5BuLS0thw8fNjU19fT0bG1tZTAYpBO9Ewr7TpWenp6dne3v719aWrpkyZIRI0YsWbJEKBTSbBNFAID3e/z48Z49e37++WfSQQAAAGjOw8Nj//79FhYWpINIvS+//NLS0nLhwoWkg7wd6kmJe/LkyY8//vjy5UuKog4fPiwQCCiK0tXV/e2335YsWUJRFKp6AOhu+vTpg6oeADpWRUVFVlYW6RQAXU5sbOxvv/1GOgUdHDx4kMlkNjY2lpaWks7yFigpJSI/P//YsWMZGRkURSUlJTGZTDU1NYqijh07Nnv2bIqiZGRkSGcEACCjrq5OfK0TAKADPXjwAFcMAf4Xg8HYuHEjRVHnz58nnUXqzZkzR1FRsa2tzc3NraCggHSc/wOFfYepq6s7f/58ZmYmRVExMTFtbW09e/akKCo4OHjOnDlMJpN0QACALiE+Pv7kyZOkUwAA3ejp6aGdGOA9LCws1q1bRzoFHRgaGp46derJkycURdXU1JCO8x/osf9UGRkZVVVVo0ePDgsLq6ioWLBggZaWFulQAABdjoeHR1lZmVAofNWCJBQKDQ0N4+LiSEcDAADoFnJzc83NzUmnoJXVq1c7OTl5eXmRDoI79u31+PFjiqIyMzP3798v3iJywYIFGzduRFUPAPBWEydOlJGRkZWVfbWwiJycnKurK+lcAEATxcXFt2/fJp0CoEszNzfn8/nr168nHYQ+du/eXV5eTlFUc3Mz2SQo7D9aUVHRiBEjrl69SlGUlZXVzz//jO2aAAD+lZ+fn5GR0euPGBsbf/755+QSAQCtZGVlRUdHk04B0NWx2ezly5evXLmSdBD6EK+hFhMTk5SURDAGCvsPFR4e7ufnJ/6f4cqVK4sXLxavRUE6FwCAdFBXV3dzc3t96dAxY8Zoa2sTDQUA9GFgYODo6Eg6BYAU0NLS2rt3L+kUdOPn53f+/Pna2lpSAdBj/z5CoTA6OtrCwsLOzi42NnbUqFEcDod0KAAAacXj8WbNmlVUVCS+XR8WFqajo0M6FAAAQHeUnp6em5uLqXMdi8/n5+TkDBgwoPMPjTv2b8fj8SiKWrNmzdOnTy0sLCiKmjRpEqp6AIBPweFwxo0bJ75p7+LigqoeADpQWVnZ/fv3SacAkBoODg5VVVWXLl0iHYRW2Gy2kZFRUFBQ5x8ad+zfVFNTs2HDBhcXl8mTJ5POAgBAN9XV1cHBwSKRCLfrAaBjJSYmXr58effu3aSDAEB3l5GRoaOjo6en15kHRWH/X7du3RoyZEh2dnZ1dfXQoUNJxwEA6AyPb9WWPBW0tYpqq1o654gVFRUikajTuutV1OXl5GX0TVh9h6p2zhEBgIj79+/fvXt3zpw5pIMASJOKioqLFy/OnDmTdBC6qampyc/Pd3Bw6LQjorD/j2XLljGZzJ07d5IOAgDQSYRC6veDRQZmyopsOXVdhbY2en4cyDJkeWVNAn4bN5vvt8xIVk7mA34JAACgu9i1a1evXr3Ey4RDB0pKSjp//vz+/fs753DdvbCvr69//PjxwIEDHz9+3KdPH9JxAAA6z9n9RbZOmobmiqSDdJKyZ4K0v8qnruxBOggASMTLly/LyspsbW1JBwGQPtnZ2ZaWlq/vXAMdoqioSCAQmJmZdcKxuvXieWVlZe7u7gYGBhRFoaoHgG4lJbbCfIBa96nqKYrS7cnqM1T9xu8VpIMAgEQ8fPjw1KlTpFMASCUrKytU9ZJgZGRkZGTU2traCcfqpoW9UChsa2traWlJSkoyNDQkHQcAoLM9/qe2h4Uy6RSdrYeFctY/NaRTAIBEGBgYDBo0iHQKAKnU2to6ePBg0inoicFgDB8+vBMO1B0L++Li4sGDB8vJyRkZGZHOAgBAQG1Vq7YRS0Gx230EMBRk9Hsp8l52xoVzAOhk1tbWPj4+pFMASCUGg7Fw4cKEhATSQWiIwWD89NNPnbCtIEPSB+iCbt++fefOHdIpAACIaW0WNtR20+K2oa6tpaWte378AdBbUVERl8sdNmwY6SAAUikwMJB0BNqysbGxsbGR9FG61+2avLy8Bw8eYIN6AAAAAJrJycmJiYkhnQJAiqWmptbX15NOQU8PHz4MCwuT6CG6UWEfHR199uzZ/v37kw4CAAAAAB3M2Nh45MiRpFMASLHbt2+fP3+edAp6srW1/fPPP4uKiiR3iO4yF7GtrW3y5MkMRnd5vwAAAADdirm5N2GELAAAIABJREFUubm5OekUAFLM29v75s2bpFPQVmRkpESXx+8Wd+z5fP4ff/yBqh4AAACArp49e3bt2jXSKQCkmImJib+/P+kUtMVmszkcjuTG7xaF/aJFi0xNTUmnAAAAAABJycvL64R1pwHoLS4urrKyknQK2goKCnr8+LGEBqd/YV9eXv7NN990wjqEAAAAAEAKeuwBPt2dO3du3bpFOgVtjRo16sGDBxIanP6z07W1tUlHAAAAAADJQo89wKebMmVKc3Mz6RS0NWvWLMkNTvM79teuXdu8eTPpFAAAAAAgWVwuNykpiXQKAOlmZ2c3aNAg0iloSygUlpaWSmhwmhf2ly9fdnV1JZ0CAAAAACQrNzc3Pj6edAoA6VZaWood7yRHVlZ22rRptbW1EhlcEoN2HTt37hw+fDjpFAAAAAAgWT169Bg2bBjpFADSrbm5+eTJk6RT0NmAAQPKy8slMTKde+ybmpr4fL6mpibpIAAAAAAgWRYWFhYWFqRTAEg3PT29KVOmkE5BZ3v37pXQyHS+Yx8XF3fs2DHSKQAAAABA4oqLi2/fvk06BYB0U1BQmDFjBukUdFZZWVlXVyeJkelc2AsEgn79+pFOAQAA/7UldPWKlSGkUwAADWVlZUVHR5NOASD1jh492traSjoFbZ08eTI2NlYSI9O5sA8ICJgwYQLpFAAA3c7kKS4lpcVvfcrTc4rPZ/6dnggA6E9PT8/e3p50CgCp98svvwgEAtIpaEtfX5/FYkliZDr32BcVFWloaCgpKZEOAgDQjZSVldbU8N717EDHIZ0bBwC6i759+/bt25d0CgCpN2/ePAaDzkUiWVOnTpXQyHS+Y79t27asrCzSKQAA6CB065qt29b+HBHm7jHi77+TKYri8aq/2bn582kebhOGL1w86979NIqi7t1Pm+rvSVGU//SJGzevEN+9j/799Jp1S8a7DeXz+a9PxW9tbY04cWTmrM9c3YcFzPSOvRBNUVR9fb2r+7DTURGvDt3S0uI1afSx8O/fdVAAAIqiXr58+fDhQ9IpAKTe9OnTJXRLGSiKqq2tra6ulsTIdC7sDQwMVFVVSacAAKADeXn5gqd5T3Kzd35zqE8fW6FQuGbtF48eZaxZHXrkcKSVZZ+165YUFOTZ2tht3rSDoqgjYZHr1myjKIrBYMTFnzPtZbZ/35E3viiEHTn462+npk8L+in8V1+f6d//sPePizHKysqDBw1PTrn26mV37/7D5/Odx7q966Ak/j4AoMt5+PDhqVOnSKcAkHoRERENDQ2kU9BWbGzsiRMnJDEynQv70NBQc3Nz0ikAAOhARFHFxUVr12zt399BTY2TdvefJ7nZK1dsdLAf2LNnr8WLVurq6p87f4bBYCgpKVMUpaKiqqysTFGUjIwMi8maP29J3779Xp/ax+fzYy+c/dxvhqurp5Fhj0kTfVzHe4pv1I8ZMz47+1F5+UvxK28kJfbq1dvU1OxdByX3twIAXYimpqalpSXpFABSLyoqCoW95Kipqamrq0tiZDoX9lwuFws/AAB0lB49eqqpqol/zsrKlJeXt+s/QPxHWVnZfrb2eXk5b/3Fvn3fskFJfv6T1tZWxwH/bbnv339AcXFRQ0PD0CFOLBYrJfW6eLr+zb+TnMe6fexBAaC7sbOzmzNnDukUAFJv/vz54kvzIAkTJ04MDAyUxMh0Xhdhy5Yty5cvt7W1JR0EAIAOlJXZr35uaKhvaWlxdR/26pG2tjYNDc1//cXXR6AoatmK+TIyMuJHRCIRRVFV1ZVGhj2GDnFKTr7qPdnv3v202tqasWNdP/agANDd8Hg8Ho9nYmJCOgiAdJsyZQrpCHRWW1vb1tYmiZv2dC7sjY2NsfADAIAkKCuzFRQUjh05/fqDsrIfMQtMXO1vWP+1aS+z1x/X0dYVz8bfum1tTW1NcvLVPn1s9fUMOuSgAEBjd+/evXz58u7du0kHAZBuERERfn5+2FlMQmJjYysrK5cuXdrhI9O5sN+6dSvpCAAA9GRl1be5ubmtra1Xr97iR0pLSzic/15+Ft9+fw9TU3N5efnq6irjUf+5vcbjVcvIyCgoKFAUNWjgMCaTefv2zdSbN6b7z/7AgwJAd6aiomJoaEg6BYDUi4qK8vT0RGEvIWpqakKhUBIj0/lGB3rsAQAkZIDDIHMzy292bLp//25JaXFC4p/z5vvHXjhLUZSqiipFUbdupRQWFrxnBDab7ek5JeLEkavX/ioueXHvftrK1Qt37g4VP8tkMocNG/Xrbyd5vOoxo8f960EBAAYNGvTll1+STgEg9QIDA9FjLznosW8P9NgDAEiInJzcrp3fHT5yYMvW1QJBo56ewYwZwb4+0ymKsrCwHjRo2OGw/bY2dt/uC3vPIAsXLFNhqxw9dqiyskJDQ3PY0JFzZi969ezY0ePXJ1wa6DhEXV3jXw8KANDY2FhfX6+lpUU6CIB08/f3Jx2BziTXYy/zr7MlpdeWLVsCAgKw4x0AwBuqSpsvRZRODDEmHYSA+CPPXabraBsySQcBgA6WmJiIHnuAT4cee4k6deqUhHrs6TwVf+vWrajqAQAAALoDFovF4XBIpwCQetjHXqIkt489nafic7lcHR0dLIwPAAAAQHvDhw8fPnw46RQAUg899hI1ceJECY1M5zv2W7Zsyc3NJZ0CAAAAACSupaWlvr6edAoAqefv76+oqEg6BW3V1tZWV1dLYmQ6F/bYxx4AAACgm0hKSsJWxwCfLiIiAlPxJSc2NvbEiROSGJnOhT167AEAAAC6CTk5OdzRAfh06LGXKPTYtwd67AEAAAC6idGjR48ePZp0CgCphx57iUKPfXugxx4AAACgmxAKha2traRTAEg99NhLFHrs2wM99gAA8H6VlZV5eXlpaWmkgwDAp7p27dr69etJpwCQeuixlyjJ9djTeSo+FlABAID/dfLkyaKXj3k8Xn19fXNzc1NTU0tLS0NDw82bN0lHA4D2Q489QIeIiory9PRUUlIiHYSe1NTUhEKhJEamc2GPHnsAAHhDS2vrjaQbL8qzKIqSkZEhHQcAOgx67AE6BHrsJQo99u2BHnsAAHiDPIMxd+5cDofzRlVvaGhILhQAdIDW1laBQEA6BYDUQ4+9RKHHvj3QYw8AAP9ryJAhixcvVlFRefWISCSytrZOSUkhmgsAPsmNGzc2b95MOgWA1EOPvURhH/v2wD72AABvJRLJyCvQ+fz/HvIKshQl4+3tPXv2bDU1NfGDKioqLi4u0dHRLi4uBw4cyM/PJx0TAD6agoKCqqoq6RQAUg/72EsU9rFvD/TYAwC8lQpHrvplE+kUZFSXN6lw5CiKmjFjRlNT06lTp+rr6zU0NFxcXFxcXHg8Xlxc3Lp165hMpqenp5eXF1YPApAWTk5OTk5OpFMASD302EuU5Hrs5UJDQyU0NHFLly61tLTU1dUlHQQAoAvJzMzcvuNrU90hxhaq8szudd9eUN9WnN/YfyRH3F/v4ODA4/FycnL++usv8QtYLFb//v19fX2trKzu3LmzadOm7OxsFovVs2dPwtEB4N80NDTweDwUJACfyNbWVl5ennQK2qqtrW1oaJDEKgYyIpGowwftIrZs2RIQEIDZ+AAAYo8fPz5y5EhNTc38+fM1FWye3Ksf5atHOlSnSj730qQPq8/gj5ism5iYGBcXl52d7ebm5unpaWZmJsmAANB+iYmJly9f3r17N+kgANItIiLCz88PE9Yk5NSpU5WVlUuXLu3wkek8FR/72AMAiGVnZx85cqSiomL+/PkjRowQPyhoECWfK3Oa0l2mNaXGvtQ3YX5UVU9RlLOzs7Ozc01NTVxc3IYNG+Tl5b28vDBFH6AL4nA4vXr1Ip0CQOphH3uJktw+9nS+Y48eewCA3NzcI0eOlJSUzJ8/f+TIkW88m5Fc8zSzvrVFpNtTUdAgkY8Z4lhKsmXcRjmGjIm1kt1ozieOlpWVFRcXFxcXN3To0MmTJw8bNqyDYgIAAHQJp0+f9vb2xo53UofOhX1QUNDy5cttbW1JBwEAIKCgoCAsLIzL5S5YsGD06NHvellTg7D8RVNNZUtbCz0Le4a8rKqGvKYhU1G5IxcUSExMvHTpUmZm5qRJkyZPnqyvr9+BgwNAO9TU1NTU1BgbG5MOAgDwTrW1tW1tbZJYGJ/OU/Gxjz0AdE+FhYVHjhwpKyubPn26s7Pz+1/MVJI1Mlc0MseF+Y8jnqJfUVERExMzd+5cY2PjyZMnjx8/nnQugO4rLS0NPfYAnw499hIVGxsroR57Ot+xBwDobl68eHH48OGsrKz58+ejyOxM//zzT0xMTEpKyrRp07y8vHr06EE6EUC38/fff6empq5cuZJ0EADp5urq+ssvv2hpaZEOQk8XLlyorq4ODAzs8JHpXNijxx4Auo+ysrLDhw9nZmbOmTPH3d2ddJxuqqGhIT4+/vTp04aGhr6+vu/pgAAAAOia0GMvpehc2KPHHgC6g6qqqsOHD6empoaEhHh5eZGOAxRFUbdu3YqOjs7MzPTx8fH19VVTUyOdCID+BAJBY2OjJDpXAQA6iuR67DtyJaGuBj32AEBvLS0t33777ebNm62trS9evIiqvusYMmTI3r17IyMjW1pavL29Q0NDMzIySIcCoLnU1NQdO3aQTgEg9SIiIhoaGkinoK3Y2NgTJ05IYmQ6F/Zbt241NzcnnQIAQCKOHTvm5OSkq6v7/fffT5kyhXQceAstLa2QkJCrV6+OGDFi//79QUFBiYmJpEMB0JaSkhK6ggE+XVRUFAp7yVFTU5PQxCI6T8VHjz0A0FJMTMzevXsDAgIWLFhAOgt8hIyMjMjIyMePHwcEBEydOpV0HAAAgLdAj72UonNhjx57AKCZxMTE/fv3T5w4cebMmbhqKaVKSkoiIyN///336dOnBwQEoB8YoKPw+fza2loDAwPSQQAA3gk99u2BHnsAoI2MjIygoKDLly+Hh4fPmzcPJzfppa+vv2rVqpSUFBUVFV9f3+3bt5eWlpIOBUAH//zzz4EDB0inAJB66LGXKMn12DMkMWgXsXXrVtIRAAA+VXl5+f79+0tKSpYtW9avXz/ScaBjMBiMWbNmzZo1Ky4uLjg42NHRce7cuYaGhqRzAUgxdXX13r17k04BIPWioqI8PT2VlJRIB6EnNTU1oVAoiZHpPBUfPfYAIO1+/PHHCxcurF69euzYsaSzgATFxcUdO3bMzs5u7ty5PXr0IB0HAAC6L/TYSyk6F/bosQcA6fXnn3/u2rUrICBgzpw5pLNAJ/njjz+OHTtmY2MTHBxsYmJCOg6AlME+9gDQ9aHHvj3QYw8A0ujp06fBwcHJycmxsbGo6rsVDw+PmJiYESNGrFixYteuXTU1NaQTAUgT7GMP0CHQYy9R6LFvD/TYA4DUOXToUF5e3uLFi+3s7EhnATLc3Nzc3NwuX77s7e3t5+eHTQ0BPpCCggKbzSadAkDqocdeotBj3x7osQcAKXLz5s3Q0NDp06cHBgaSzgJdxbFjxyIjI1esWDFx4kTSWQAAoFtAj72UonNhjx57AJAKQqFw48aNdXV1oaGhmpqapONA18Ln8/ft25eVlbVy5UpHR0fScQC6rubm5qamJhUVFdJBAADeCT327YEeewDo+q5duxYYGDhq1KjvvvsOVT38LzabvWXLlq+++io8PHz9+vVovAd4l+Tk5K+++op0CgCphx57iUKPfXugxx4AurjQ0FA+n3/q1CnSQaCrMzc3DwsLS05O9vb2XrhwoY+PD+lEAF0Om83W09MjnQJA6qHHXqLQY98e6LEHgC4rPT19+fLlK1eu9PT0JJ0FpMyOHTsKCwt37NihoaFBOgsAANANeuyllFxoaCjpDJKydOlSS0tLXV1d0kEAAP6P8PDwq1evHj16FIuAQDs4OTnp6+svWLCAyWTa2NiQjgPQVdTV1ZWXl6uqqpIOAiDdbG1t5eXlSaegrdra2oaGBklcN0GPPQBAp1qxYkVLS8u+ffuwwhO0m6Oj45UrV549exYcHFxRUUE6DkCXcPv27UOHDpFOASD10GMvUZLrsadzYb9161Zzc3PSKQAA/qOiomLChAleXl4hISGkswAdrF69evHixQEBARcvXiSdBYA87GMP0CGioqJQ2EuOmpqaJJbER489AEAnycvL+/rrr3ft2oX+IOhwW7duVVdXX7JkCekgAAAg9dBjL6XoXNiHhIQsXLgQLawAQNzjx4+3bdt25swZ0kGAtk6cOHH37l3MQ4burLW1tbW1FXd0AKArq62tFQqFHA6nw0em81R83K4HgK7g4cOHO3bsQFUPEhUYGPj5559PmDChrq6OdBYAMm7cuLF582bSKQCkHnrsJSo2NjYiIkISI9O5sEePPQAQV1VV9e2332KneugEw4cP//nnn728vO7du0c6CwABSkpKWlpapFMASD302EsUeuzbAz32AEBWZWXltGnT/vrrL9JBoHsJCAjYs2ePvr4+6SAAACB90GMvpehc2AcFBS1fvhw99gBAipub26lTp7S1tUkHgW5nxYoV7u7uLi4upIMAdB4+n19bW2tgYEA6CADAO9XW1ra1tUnipj2dp+JjH3sAIGjnzp1bt25FVQ9E7Nu379KlS9evXycdBKDz/PPPPwcOHCCdAkDqocdeorCPfXugxx4ASLly5QqPxxs8eDDpINB97du3LzU19c6dO6SDAHQS7GMP0CHQYy9R6LFvD/TYAwApI0aMSEhIwPkHiPPw8Pjpp5/09PRIBwEAAOmAHnspRefCHj32AEBEeHi4urr6Z599RjoIANXY2Dhu3LiUlBTSQQAkTiAQNDU1qampkQ4CAPBO6LFvD/TYAwAR4eHhkyZNIp0CgKIoSlFR8cCBA4sWLSIdBEDiUlNTt2/fTjoFgNRDj71Eoce+PdBjDwCd79y5cwEBAQwGg3QQgP9wdHQ0MzOLjIwkHQRAstTU1Hr27Ek6BYDUQ4+9RKHHvj3QYw8AnS84OHjx4sV2dnakgwD8H8uWLVuyZEmvXr1IBwEAgC4NPfZSis537Lds2ZKbm0s6BQB0I3V1dXl5eajqoQuaM2dOaGgo6RQAEtTS0lJfX086BYDU8/f3R1UvObW1tdXV1ZIYmc6FPXrsAaCTpaenjxo1inQKgLewsbExMzOLiYkhHQRAUpKSkrZu3Uo6BYDUQ4+9RKHHvj3QYw8AnSw3N1dfX590CoC327hx46VLl0inAJAU9NgDdAj02EuU5Hrs5Wg8MY/L5TKZTCxhBQCdJiEhwdraunfv3qSDALyFjIzMixcv7t+/7+DgQDoLQMczMDAYNGgQ6RQAUk9OTq5fv37y8vKkg9CTpaWlhHo26XzHHj32ANDJKioqlJSUSKcAeKe5c+cePXqUdAoAiWhubq6rqyOdAkDqocdeotBj3x7osQeATlZbW8tkMkmnAHgnOTm5RYsW/frrr6SDAHS85OTkr776inQKAKmHHnuJklyPPZ23uwMA6BwODg4yMjKvPyIUCo2NjWNjY8mFAni70tLS4ODg+Ph40kEAOoa7u/vLly/feFAkEqWnpxNKBCDdXF1df/nlFy0tLdJB6OnChQvV1dWBgYEdPjKd79hzuVyBQEA6BQDQn5WVlbiB+RUlJaW5c+eSzgXwFnp6er17905JSSEdBKBjBAQEyMvLv34GpigKzfYA7RYYGKisrEw6BW1NnDhRElU9zQt79NgDQOfw9/d/o/HHyMjI09OTXCKA9/Hx8bl+/TrpFAAdw9fX19DQ8PVH1NTU/P39ySUCkG7osZco9Ni3B3rsAaBzeHp69ujR49UfFRQU8J0SujInJ6fY2FihUEg6CEAHUFBQ8Pb2fn0XJEtLy5EjRxINBSDF0GMvUdjHvj2wjz0AdJoZM2a8WjavR48ekyZNIp0I4H2cnZ0TExNJpwDoGH5+fkZGRuKfVVVVp06dSjoRgBTDPvYSJbl97Olc2KPHHgA6jYeHh/imvYKCwvTp00nHAfgXzs7O//zzD+kUAB1DQUFh0qRJcnJyIpHI1NR01KhRpBMBSDH02EsUeuzbAz32ANCZ/P395eXljY2NJ06cSDoLwL+wt7dPTk4mnQKgw/j5+RkbGysrKwcEBJDOAiDd0GMvUZLrsWd8wGukFXrsAaRCa7OoIJNfU9nSWCfdHb8catjIPgusra2TzlWQzvJJ5BVkFNlyWgZMIwt8rtOWlpaWqqpqQUGBqakp6SwgWYWPGypeNDXWtdF+f2Pn/l88e/ZMtspG2k/C/0qRLauqKd/TWpmlROdbdEBKRESEn5+fkpIS6SD0FBsbW1lZuXTp0g4fGfvYAwBJRU8ab5wvV9dW0OmpJMJSXl0DgyFbXd7c2ixsaxG6B+mRjgOSsnv3bktLS6wHQWPNjcLfvy9S1VRQUZdXUmHgKx9tyMrJlj1r5PNaBo5T72WDKdPQwbCPvURJbh97Ot+x53K5Ojo6uGkP0GUV5wvuJFRPXGBMOgi8Xf79uj9+KvGYo086CEiEmZlZZmYmCnu6ahYILxwtGTZRV0OPSToLdDyLAaoURV2NKpGTlzW2xOwq6EjosZcoyTVs0nkCD3rsAbqypgZhfHixy3QD0kHgnXrbqegYK92ILicdBCTC2to6KyuLdAqQlJjDxQ4umqjq6W3sNP3EqDI+r5V0EKAV9NhLFPaxbw/02AN0ZQ+SeNZDOKRTwL+wGqSWebNGhCYJOjI3N3/x4gXpFCARZc8EIqFI2wjfgujPejDn/g0e6RRAK9jHXqKwj317YB97gK6ssqRZyxBfOqWAbk9WeVEz6RTQ8RgMhrKycklJCekg0PEqS5q1DHHDrVvQMmBVleEUDR0J+9hLlOT2sUePPQCQUc9rZbLofG2RNuTkZRvrWylKgXQQ6HgmJibPnj3T18cyCnRTX9sqz8QJtltgKsnyqzAVHzoSeuwlCj327YEeewAAgPfo2bMn7tgDAMDr0GMvUeixbw/02AMAALyHurp6aWkp6RQAANCFoMdeotBj3x7osQcAAHgPXV3dsrIy0ikAAKALQY+9RKHHvj3QYw8AAPAeWlpajY2NpFMAAEAXgh57iUKPfXugxx4AAOA9VFRUMBUfAABehx57iUKPfXugxx4AAOA9OBxOTU0N6RQAANCFoMdeoiTXY0/nqfhbt24lHQEAAKDrUlFRUVJSIp0CAAC6kKioKE9PT3w6vItIJGpubm73r/fs2VNTU7OpqandI8jKysrLy//v43Qu7NFjDwAA8B5MJpPL5ZJOAQAAXQh67N9PJBJ9ymQ3KysriqI+ZQQWi/XWwp7OU/HRYw8AAPAeLBZLIBCQTgEAAF0IeuwlSiQSiUQiSYxM58IePfYAAADvZ21t/SkTAgEAgGbQYy9RAoFAQn+9dC7ssY89AADA+3G53JaWFtIpAACgq8A+9hIlKysrKyuRGpzOhT2Xy8UMQwAAgPdgMBitra2kUwAAQFeBHnuJYjKZEup0oHNhjx57APhfBQV5Y5wdHz683+EjT/J2PnkqvMOH/RBBc/wOHtpF5NAg7aysrNra2kinAPJKS0tCFgWOdxsa/fvpc+d/dR436GNHOHhoV9Acvw6MRPCk+lFqanhjnB2v30ggHQSgY6DH/mPFxMRMeJupU6eKX+Dr6+vt7V1WVvZ6j/3169cnTJggfkF+fv6r3/Lw8Jg2bdrGjRtv3LjxUTHovCo+euwBuq3zMb/lPHm8dnXo/z6lpa2z9Mu1BgZGJHIBdDkFBQUo7IGiqEt/xj57VrBn1w89evSsqeEt/XIt6UQEPH2av27Dl2dOx5MOAkBSRESEn58ftrv7WJs2bXqj9mQw/ltrt7S0HD9+fN26dQKBQCgUvnVOxIwZM/r06SMSiSorK9PS0nbv3n3z5s3Vq1fLycl9SAA6F/bYxx6g23ryJOtdT6mqqE6a6NO5cQC6LllZWaFQSDoFkFdXV6urq9+/vwNFURoamr169SadiID3fHYAdB/Yx759bG1t2Wz2u54dO3ZsQkKCp6enhYXFu15jYmLSv39/8c/Ozs5OTk7bt2/v3bu3n98HTYai81R89NgD0MnTp/ljnB1v3kyaNds3ZOFMiqJaW1sjThyZOeszV/dhATO9Yy9Ei1+5dPm8Py/HXb4cP8bZMTcv53zMb96fjUtNveH92bjDYQfemIqfePXygpAZ7h4jpviM//6HfeKTRvhPP3hOHPX6imJRZ06MdxvK5/Pb2tp+jggLmDHZ1X2Y7+fuBw7ubGxs/Kg3Ehd/bqq/p6v7sGXL53O5hWOcHa9dvyKeZfB6ToqisnMer1y1cJK3s7vHiJCFM9Pu/vNqkIcP7wfPmzbOdciMwCk3khJfH/9JbvbqNYsneTt7eI3ctHllaWmJ+PHXx//jYswn/FMArVhZWaGwhy++nHM+5rfCwoIxzo6noyJen4rv/dm4c+fOHA474Pu5u+fEUes2LK2srBA/VVFRvmbdElf3YVN8xkecOPIhB/rwM/kb3npmu5N2a4yz4+PHD1+97HFW5hhnxztptyiKSkj8c9786RM8nSZ5O6/fuOxFcZH4NVu3rd26be2lPy/MCJwywdNp/oIA8QgRJ47s3B1aVlY6xtkx+vfT738jF+J+/3yah6v7sMVLZj99mv/6Uw8f3l+yNNhtwnB3jxHLVyzIyn706qnLl+NnzfZ1dR8WGORz6c8L4gfLykq3blvr/dk48eNx8ec+5G8SQHLQYy8Jtra2gwYNOnLkiLy8/Ad2OgwbNszJyen8+fMfuD0enQt79NgD0Im8vDxFUSdOHv3cb8aqlZspigo7cvDX305Nnxb0U/ivvj7Tv/9hr7he/XrbtxbmVmPHjI85l2Day0xeXl4gaDx3/sya1aGTJvm+PmZKyvWvt28YMGDwsaNRq1dtSUpO3Ld/O0VRY8e41tfX302//eqVSUmJQwaPYLPZ0b+fPh0VMXvrgj13AAAgAElEQVT2wp+OnVm9akvqzRvhx3/48HeRlf3o2/3fDBs26tiR0+5uE7/6ej1FUTIyMuI3+HrOpqamNWu/kFdQ2Lvnx8M/nOzTt9+mzSvKy19SFMXn8zdsWq6qohb246kN67++cCH61ffssrLS5Svmy8jK7t93ZN/esNq6mhWrQpqbm98Yf8jgER33LwPS7cmTJ6QjAHk7th+c4D7J2Ngk5lzCFO+prz/FYDCifj1hYmIa9Uvc8fDfcnOzT0X+p+99x87NhYX5O745uH/fkZoaXlLy1X890IefyV/3rjObg/1ADkc9OeXaq1cmJSVyOOoO9gOzsh9t/2bj4MHDw348tXPHIUFj45bQVeLXyDEYDzPvZ2VlHg375Vz0FTU1zq49WymKmvp54JQpU3V0dGPOJXh5fvaed5GRcW//gR2jRrqEH40KmD7ncNj+V089f/5s5eqF2lo6P3wX8f2hnxWVlFauCnn5soyiqBtJibv3bnNz9Tp08CdPD+/de7aJ2/J379laUVn+zfYDx3/6bYr31AMHd4ovTACQgh779mlpaWn6v17vdGtra5s7dy6Xy/3zzz8/fB/7wYMH19TUPHv27ENeTOep+OixB6AVGRmKouzsHN3dJoqL29gLZ6f7B7m6elIUZWTYIzc3+3RUhMeEyWw2W47BkFdQUFPjiMtmgUDg85n/kMHDxYvnvRry9JmI/v0d5gYvFo8wN/iLb3ZsmjtnsampmbGxSUrKNfGvlJWVZuc8njo1kKIoF2f3gY5DTU3NKIoyMjIeM3r8P7dTP/xN/PVXvLq6xqKQ5XJycsbGJqVlJXn5T/7/+/s/OVtbW/fvO6KpqSV+F7NnhZw7dybz0YMxo8fd+ielrq52yRerTUxMKYpau2ar39T/LL5yIS5aRkZm44btKmwViqLWr/1q2nSvG0mJ41zc3xgfAOAVNputoKAgKysrPuG8oadxL/GJV0dHd9DAYTk5jymKKi9/mX7vzpdL1jjYD6QoaskXq1+fVfROH3wmf/2X3nNmGzXSOTnl2vx5S8SvTE6+Omb0ODk5uR5GPcMOn+ptai7ucfX5zH/DpuXV1VXq6hoURQkEjQtDlou/Jbo4u+/YtUUgELBYLKYCU0ZG5q1/Ca/768ofGhqa8+ctkZOT69GjJ59ft/2bjeKnYi9EKyoqrVu7TXzcDeu+9v7M5fJf8TMC5pyN/mXE8NFTP59JUZSlhXVVVWVlRTlFUQVP87wnf25t1ZeiKMOJPhbmVrq6+h/xjwfQ0dBj3z7Tp09/45E5c+Z89tl/rxIaGhpOnDjx5MmTjo6OOjo6HzKm+GU8Hu9DXkznwh499gD006ePrfiH/Pwnra2tjgOGvHqqf/8Bf1yMaWhoeOtH0atffEUoFD55kjUrcP6rR+z6D6AoqqAgV0dHd8zo8bEXzi5ftl5WVjYpOVFZWVl8l1tNjfPXlT/2fvt1RcXL1tbWxsYGRcWP+OTjcgv79un3ahEUpxFjfo4Ie2tOBoPR0tpy6LvdeflP+Pw68cXd2toaiqKePStgsVjiqp6iKG1tHW3t/3w8ZGVlWln2FX/3pShKV1dPX98wLy9nnIv7u/4eoJuztLQUzxkBeBdTU/NXP6uoqNbW1VIU9Yz7lKIoK6u+4sdlZGSsrPrm5eV8yIAfeyZ/z5lt9KhxsReinz7N79Wr95Pc7OKSF85j3cSXKkpKXoSHf//ixXNBk6C1pUW8joC4sDc06PHq3o+Kiqr4qQ+/G/SM+9TCwvrVmdza2ubVU09ysyzMrV6tmKWkpNSjR8/8/CfiBv7XP3FeXYwYNnRk1JkIPr9u8ODh/WztXx8NgIj79+97eXmhsP9Y27dvf2Omw/9W79OmTUtMTIyOjl64cOGHjCm+5/+B+97TubAvKSnR0NBgMpmkgwBAh1FW/s+qJA0N9RRFLVsx/1VNIi59q6or3/pR9OoXXxEIBG1tbREnjpw8dez1xyurKiiKGjtm/ImTRzMzH/TrZ38jKXHE8DHik8l33++5knBx2Zfr+tr0Zyowo86cuHrt8ofnr62t0dTSfvVHVVW1d+UsKuKuWLnA3m7g+nVfaWlqC4XCV7flGxobmMz/8wX01cWF+np+bl7OeLehr55qaWkRv6N3/T1AN5eTk/PhcwKhe3rjq5T4nNvY2EBRFFPhv08pffBVzo89k7/nzNavn72mplZyyrVevXonJSXq6er37duPoqir1/766uv1MwLmfLF4lbIy+2Hm/a3b/rvOv8L/fDn8qP8LGhrqNTW0Xv1RkaX4rqcoilJSUm5oqBcIBC0tLSzWW6Y3L1u6zrSX2ZWEi2ejf1FWVp7o5TM7KOT1xbQBOtmAAQMwFb8dzM3N37N4npiysnJgYOCPP/7o5eX1IWMWFxdTFKWtrf0Br6V1Yb9+/frly5fb2uL2FAANib8Xblj/tWkvs9cf19HW/cARWCwWg8GY4j31jTmfHHUNiqKMjU1MTc2SU64ZGBg9epQROHOe+LrpxUuxMwKCx437T41dX8//qNjyCgpNry3qWVdX+65XXr32V1tb28YN28VfqcvKSv+bnMl647h8fp34B2Vltq2t3YplG15/9qPmFAAA/D/27juuieTvA/ikkUBC71WqFFEQOFFR7B1UiuXsvWKvp1hQ7KKcihUVTwXs2E5F7N4dp6JSlI6IdOkECKnPH/u7HA8HAQNhk/B9v/xDSLL5ZDPMzuzuzLQG1kdtWBcJK6LWa2VNLqJmIxKJAwYMff362Yzp816+ejp48Ajs0fv3b/V0dJkzezH2Y327zqZMoyk298HpdEaj+rmmhqmpoUWj0Wg0GnYioxEymezj87OPz89lZaXRj++fPXdcTU194oRp7RgYgB8yffp0vCPIs2HDht2/f//06dPDhw9v8ckvXrzQ19fX12/V8Bx5njxPXV0dm6MFACB/zM2tKBRKeXmZiYkp9k9FRVVVVU1BQQF7QouXX4hEopWVTVFRgXAL+vqGJDJZRVkFe8KggcNj/379x58v1NU1sEGkfD6fx+MJL7PX1NT8+dfLH7rOY2Rkkpr2WfiShnM+NcLhsKlUmvBC2eOY34UPmRibcrnc7Ows7MesrIyyslLs/7a29nl53wwMjIQfikAgaGpqNfUOAAAgPmOjLggh4SwhXC73Y3zcj26kxZocI7pmGzRgWHpGatz7N9++fcXuw0cIsTnshkPlnzx9+KOX5UUwNuqSmZUuXE6i4eQC1l3tUtOShYuqVDOrc3KysQELlpbWCQnvhc88GnLwaMhBJpP5OOYBl8vFVhmcPGmGnV33hnPBANDxrl+/DiuLSQ6bzZ45c2ZcXFx8fLzoZz58+DA+Pt7Xt7WLNMtzx/7QoUM2NjZ4pwAASASDwfDw8A67cOrps+j8grwPH9+tXb9k7/7t2KPKDOWMjNT0jNTKSlHTjUyeNOPlq6fhEWHfvn1Nz0jdvWfL8hVza2r+d0Vl0KDhubk5d+/dGDhwGDaWkkKhWFlaP4q+l5efm5mZvsl/paurW3V1VU5ONtYsa9FA96FFRYXnw07mF+TFPHn4518vm3umrY19ZWXFg4d3SktLom5fS0n9pKamnpmZxmQye/fup6SkdOTo/uSUT4mJH4OP7MVGjSKEPD186upq9+3fnp6Rmpub89vF0NlzJ6Y0WGwJAADahZ6evp1d9/CI82/fxaZnpB4MChTjaoromlxIdM3WrVsPXV29EycPm5tbYjObYlXou3exyclJhYUFh4P3aGhoIYRSUz+L7q4wGMqlpSUJCR+EC4U2aciQkeXlZSEnDmVlZbx89TQ6+p7woXHjJtTXs/Yf3PHt29esrIzAXZvpdMaI4R7YBH5v38WeDzuZkvr5xs3IqKirtjb2BALhyNF9B4MC0zNSseNCWlqyo6Pzj+5JANrRmTNnmMwfuyERYHMTvPuP/+5JIpHYrVu3/v37R0dHN3ooOzs7Pj4+Pj7+1atX+/btO3LkyODBg0eOHNnKAPJ8K35tbS2VShVObQIAkDNLFq1SZiifPnOktLREQ0Ozbx/3uXOWYg95eU3es3fr8hVzA7YfELEF9/6DN/2yMyIy7HzYSTqdYW/vcDjolHDtVkMDo65WNmnpKatXbhK+ZN3arQcO7pgzd6KensGc2Yttbew/JcUvXjoj9ExkazL37es+Z/bim7cir98Id3BwXr1q04KFUxsOUm34zEkTp586feT4iUOuvdw2rg+4fuNyROQFIpG4csXGHQEHj4UcXL5irq6u/vx5ftdvhGNXovT09A8FnTp9+sjyFXNJJJKpqUXgzkMwYR4AQBL8N+86eHDnZv9VdDpjrKfPsKGjW7PiXSMianIh0TUbgUAY4D706rVL2BInmKlT5+QX5K5Zt1hJie4xxnvG9Hmlpd8PHgokimwWDhk88lH0vTXrFk/5edbsWYuae9pPLr2XLlkdeeW3u3dvWFnZrFnjv2DhVKwSNjQwOrAv5HTo0XkLfiaRSN3tHQ8HnVJTU0cIDXAfsnLFxqvXLkVEXtDV1V++bP3QISMRQvv2HgsNPbZ6zUI2m62nZzB71qKRI1o1+BYACRkzZgysLCaG3bt3//eXBw4c6NatW8PfYDdjzpkz582bN40uC128eBH7D41GMzc3X7NmzeDBg1s/wS1BjqfMmT17NoyxB0BqXT+c6zRMS9u4cx05BAJBWVmp8A7ShIQPK1bNPxd6xczMAu9ozYq5nO80SK2LLQzUl0/Lly/fuHGjgYEB3kFAe3obXVZXg3oO1sA7CJC4imL2qxuFUzaa4B0EgM6Cz+eXlJS04olNw3rfbVmPhkajqaio/Pf38nwrPoVCgSV8AABSJT7+ve/Ekb9dDM3NzUlKij9+4pCNTTfhwnUAdLysrKxWrqMDAACgM3jy5El9fT3eKeQWi8Wqra2VxJbl+Vb806dP4x0BANDphEeERUSGNfmQiYlZyNHzv2wIuHLtYnjEeQZD2dHBeeGCFXAKEuCIz+dDCQTtqMU6sMMTiUM+PgUA4tm/f7+DgwMsGS4hkjuZLs8dewAA6Hienj6DBjW9fgmFTEEIDR8+ZvjwMR2eC4Cm8fl8uGIP2lGLdaBMkI9PAYB4+vfvD716yZHcvpXnjj2MsQcAdDxlhrIyQxnvFAC0lkAggCv2oB3JRx0oH58CAPH4+/vjHUGetX2MfXPgJD0AAADQecEVewAAAA39+eefbDYb7xRyC8bYi+P06dNksjx/QAAAAKCNdHR0oGMPAABAKCAg4PLly1paWngHkVIEAqHJSelbKSUlpaamZtCgQWJvobkerjz3eykUGAQFAAAAiJKfnw8dewAAAEKurq4wxl4EAoFAo4m/WrO7u3u7xvmXPB/LFyxYkJSUhHcKAAAAQHrxeDwSiYR3CgAAANJix44dysowx4SkVFVVlZeXS2LL8tyx53A42OQEAAAAAGgSdOwBAAA09Pfff8MYe8m5ffv2hQsXJLFlee7Ynz592t7eHu8UAAAAgPTi8XgwHw0AAAChrVu3VlVV4Z1Cbqmqqqqrq0tiy/J8LIcx9gAAAIBoXC4XrtgDAAAQcnNzgzH2kjN27FgJbVmer9jPmzcvMTER7xQAgMZKSkpWrFhRWFSEdxAAOjuBQKCtrQ3r2AMAABDaunUrjLGXHBhjDwCQbSwWa+XKlVOnTsWuEE6YMEFHRwfvUAB0dvX19XC/JQAAgIaeP39eX1+Pdwq5BWPsxREaGtq9e3e8UwDQSXG5XITQhg0bhg0bho3j9fHxOXfuHEJIT0+vX79+yhrkejYf75igZQIBUqTDrdryicVitWXNHiC1FJVJPA5UsJ0Cm8VX1oDBp6A97dmzp7q6Gu8UcktyY+zluWPPZDKxrgUAoGNg53cPHjw4ePBgJpOJEPL09IyKikII0en0/v37NxyypaFLLc1l4ZoXtEpBVq2WIYy1k0/19fUwkFIuaelTv0MF2zmU5LHUdKBjD9rTqFGj4Jyv5IwdO3bmzJmS2LI8d+yXLVuWnJyMdwoA5BzWgQ8NDR06dGhubi5CqF+/frdu3VJTU8P+T6fTm3xh936q6e/hHmBpl/6+yq63KhEu2MspuGIvr/RMaQihskK4mVb+pcVVOvRXwzsFkCsrV65kMBh4p5BbMMZeHPr6+nAhAgBJKCkpQQhFR0cPGzYsKSkJIeTk5HTt2jULCwuEUO/evVVVVVvciJIyaegU3SfhBR0SGYjjSxIzN5U5aII23kGApMAVezk2bpHB2wffK4phMWp59jSioP94bRVNeV7lCnS8K1eu1NXV4Z1CbklujL08VwS7d+/GOwIA8uP79+/a2tqZmZlLly718PDw8/MzNTW9cuWKhoYG1rEXY5vGXRX5PMG909/UdRR0uigigQRygx9HohAriurZ9fz6Gu7YRQZ4xwESxGazjY2N8U4BJIKqRPSYb3DjaK6GHk1Zg6ykQoY6Vm4QSITi7LqqcnbPgWqm3ZTwjgPkzblz54YMGaKoqIh3EPmkqqrK50tkDhSCQCC31XxxcbGampqCggLeQQCQVWVlZRoaGikpKWvXrnV0dAwMDMSu1WtpabXju7BZgqwEZmUpp6ZK5ifFePPmjaWlJXayQzp9+/YtKSlp4MCBIg7YClSiIoOkbUg1sYX2opyLjY29dOnSsWPH8A4CJCgzoaYkr762iieQWM+ew+G8evXKxsbGwKCznwpks9kPHjzo27evtrYE73Wiq5BVNMimdgxFZXm+9xbgJSwsbOLEiUpK0AaQMfLcsZ89e/bq1athYnwAfgjWmWcymdOmTbOwsAgKCiosLMSmssc7mgxYuHDh/PnzXVxc8A4iSklJCYvFMjIyOnPmzOTJk2Gt2s7s8ePHT5482bt3L95BgKzKzc3V09PLzs4WCARWVlZ4x5EWz58/HzhwYEJCQo8ePfDOAgCQLlVVVTweTxIT48vzeT4Gg0Emy/NYAwDaS01NDfafn3/+GVtqnkwmHz16NCgoCOvSQ6++lfbt2yf9zTgtLS0jIyOEkIqKyrx58xBCMJSu02IymTBDEhDb9evX/fz8iESipaUl9OobGjhwIELo48ePc+fO5fF4eMcB4MfcuXOHxYJlNSQF1rEXx9GjR21tbfFOAYCU4vP52IT2fn5+o0aNwn65a9euBw8eIIRoNBqMvBWDbA3/mTRp0pUrVxBCqampK1euzMvLwzsR6GjV1dVwywYQw8ePHxFCOjo6UVFRRKI8NybbYsaMGcuWLauvr8/Pz6+srMQ7DgCtFRISgjURgSTAOvbiqK2thbOkADSCDZI/f/68q6sr9n8/P7+XL19ij5qbm+MdULbt2rUrMTER7xQ/zNHR0dfX9++//0YIvX//Hu84oOPAFXvwowQCwejRo7H7vNzd3fGOI+0cHR2VlJTodPrKlSvT0tLwjgNAq8A69hIF69iLY+nSpZ8/f8Y7BQD4w1bLfPny5YABA969e4cQGjBgwNu3b01NTRFCNjY2eAeUHyUlJVyuTE4B2K9fP29vb2z+P09Pz+rqarwTgY5AoVAkOsUXkCfp6elxcXECgeD8+fNubm54x5Elqqqq58+fx25tuHfvHt5xAGgBrGMvUbCOvTiUlJRIJBLeKQDABzZqOjk52cPDIzw8HCFkamp6//79kSNHwpV5yTl8+HDPnj3xTtEmixYtOnXqFIfDKSsrCw0NldHzFKCV0tPT6XQ63imADPjzzz+3bNliYWFBJBJ1dXXxjiOTLC0tEUIfPnzYvHkz3lkAEOXBgwcwxl5yYIy9OEJCQuzs7PBOAUBHy83NnTFjxs6dO7GrBGfOnFm6dClCyMTEBM6/gtYwMDDQ0NBQV1fncrmrV6+G2fXkWGlpqaamJt4pgFSLjY1FCGlra0dGRqqpqeEdR+Zt2bJl/vz52Gk1GMYMpFNwcDAUTsmBMfbiKC8v53A4eKcAoCOUlpauWrVq0aJFCCEikbhhw4bdu3djPTR9fX2803UiGzduTEhIwDtF+yAQCIsWLTpy5AhC6P79+/7+/tC9lz+lpaVaWlp4pwBSisfjeXl5YbO+waT37QgbB6eurj5mzJj09HS84wDQ2Lhx4xQVFfFOIbdgjL04Vq9enZKSgncKACSlpqZm//7969atQwjV19d7eXkdO3YM68x369YN73SdVHl5OZvNxjtF+/P19XVzc/vy5QtCKC4uDu84oN2UlJTAFXvwX9XV1RkZGVwu99dffx0xYgTeceSTlpbWixcvsEMGNv0NAFJiyZIlMEpLcmCMvThMTExgRkcgZ7hcbnh4eEBAANbw6tKly5o1a7DOvLu7O5lMxjtgZ3fq1CkXFxe8U0jEqFGjsMFNZ8+e3bhxI95xQDuoq6sjk8lwWQY08vnzZ09PTw0NDSqVamJignccOYediL9+/Tp2ah4AaRAWFlZbW4t3CrkFY+zFERAQAHeOAfkQGxt7/PhxhFBlZWVBQcG4ceMQQnp6epMmTdLT08M7Hehcjh8/Pm/ePOwSU1RUFN5xgPgKCwvhPnzQUFZWFkKIxWI9f/5cQ0MD7zidyN69e3v16oVNeYt3FgBQREQEdOwlB8bYiwPWsQcyraysLCoqisvl8ni8S5cuYR14TU3NNWvWODo64p0ONG358uUfPnzAO4XEYXM729vbJyYmHjhwAO84QEy5ublGRkZ4pwDS4tixY+fOnUMIOTk54Z2lM8I69lVVVbNmzYIJyQG+xowZA3c9S47kxtjL8427S5cuXb16dffu3fEOAsAPSE1N1dTU1NLSWr58uY2NzdixY4lEItyhJyvq6+s7z/lEGo22ZcsW7KT+0aNHKRTKwoULCQQC3rlAa0HHHmBKSkq0tLT09PT8/PzwztLZubq60un05OTk7t27w/A6gJfly5fjHUGeVVVV8Xg8SVy0l+cr9gDIkKKiIoRQYGBgQECAQCBACF26dMnf359IhD9SWXLkyBFZX8f+RykpKWEnUslkcmZmJofDkdCUMKDdQcceIIR27dqVkZGBzZGJdxaAsJuhevbsSSAQJk6cWFJSgncc0Bk9f/68vr4e7xRyC8bYi+P8+fNwuR5Ivzdv3gwYMCApKQkh5OfnFx4erq2tjXcoICYqlUoikfBOgQMikThv3jxLS0sCgTBhwoRLly7hnQi0DDr2nRyPx4uNjbW1te3duzfeWUBjJBJpz5494eHheAcBndGePXuqq6vxTiG3YIy9ODrPDbFA5lRXV69fvx6bgUxHR+f+/ftDhgxBCKmpqeEdDbTJwoULO/mqRWQyOSYmxtzcHCH06tWr1NRUvBOBZjGZTGw9bdAJHTt2jMvluri4eHt7450FNM3CwgK7Izo4OBhG3YOO1L9/fyqVincKuQXr2Itj3rx5iYmJeKcA4F8PHjzYvXs3tgT9iBEjQkNDEUKmpqYMBgPvaAC0p759+2JrjgYEBHTyMx1Si8lkZmZmwhX7zunSpUt0Op1KpcIobpkwfvz4SZMm4Z0CdCL+/v7Kysp4p5BbsI69OFRVVeGIBaRBTEwMi8ViMpl//PHH0KFDsZXqsEv0QM7I8Tr2YujSpUt4eHiXLl2w9Uffvn2LdyLwr+TkZBsbG7xTgI6GLdsxdOjQ2bNn450FtJapqent27extW/xzgI6hQcPHsBNIpIDY+zFERwcbGtri3cK0HmVlpYihJYsWRITE0MmkxkMRmBgILaeDQCdBzZnhK+v79mzZ7GFSPFOBBBCKCUlBTr2nU1ERMSjR4+wk8t4ZwHiYDAYcEYGdIDg4GAmk4l3CrmlpqamqakpiS2Ttm/fLontSoPi4mIKhdI5J7IC+IqJiVm6dGmPHj2MjIxGjhw5fPhwmNy+k/Dz89PT09PX18c7iNTR0dHx8PDAFtZavHixra0tTBKJr6tXrzo7O1taWuIdBHSctLS0BQsW4J0CiE9HR8fc3JzJZCopKcFNqUBy6HS6ra0thULBO4h8sra2dnBwkMSW5bmzsWHDBpi3CXSkO3fu3L9/H1vf+8KFC66urtjEtnjnAh2Hw+Hw+Xy8U0g1fX39zZs3x8XFIYQyMzPxjtN5ffz40dHREe8UoIOcPHkSIeTj44N3ENBWPXr0sLCwyMzM/Pvvv/HOAuSWt7c3tpYtkISKigoJrWQpzx176FCBjpGTk4MQevz48YcPH7A77fv166ejo4N3LoCD4OBg6Cy1yNbWdtq0aVjHfsKECbBQc8fLzs5WVFSE+7E7CV9fX5h6Tc5069btwoULFRUVeAcB8unJkyewjr3k3L17V0KrAhMEAoEktgtAZyAQCJYtW6atrb1t2zaBQEAgEPBOBICMycrKYrPZNjY2z58/HzhwIN5xOovIyMjc3Ny1a9fiHQR0hPr6eli5Si7l5ubCwhZAEkaMGHH58mUtLS28g8inu3fvVlRUTJ8+vd23LM9X7AGQnHv37lVUVAgEgmnTpm3btg0hBL16gBAKCgpKSkrCO4UsMTc3x6Zwe/Pmzbp16/CO01nExsb27t0b7xRAsrhc7i+//IIQgl69vDIyMrp48eKff/6JdxAgb9zc3KDekBxPT09J9OrlvGMP69gDCdm1a9e7d++UlZWJRCI0jkFDaWlpsEKMeNavX798+XKEUGJiYkxMDN5x5ByLxYK6S+6tXbsWO+8M5Nj06dPj4uLghDJoX1u3boV17CUHxtiLg0qlwjB70I4ePnwYGBiIEFq2bNn27duhdIH/2rhxIywhJjZjY2OEkJWVVUxMTFhYGN5x5NbTp0+VlZVhSm25FxwcTKPR8E4BJG7ZsmX29vZ4pwByJTo6Gq5SSI7kxtjLc8c+JCTEzs4O7xRAHvB4vIyMjNevX/v5+SGEVFRU8E4EpJSZmRmDwcA7hWyj0Wh79+7F1sY7ceLEX3/9hXcieRMdHT1ixAi8UwAJunPnTmxsLN4pQMepqanZtWsX3imA/AgKCoJ17CVHcuvYy3PHvri4mM1m450CyLxdu3bV19cbGRkFBmlPy08AACAASURBVAaqqanhHQdItdOnT8MSbu0Cm7Nn3Lhxly9fLikpgcq8vfD5/CdPngwdOhTvIEBS3r59+9dff8FQi06FTqc7OTkFBQXhHQTIiWnTpsFyd5IjuTH28jwr/uzZs1evXt29e3e8gwAZdvbsWXV1dW9vb7yDANmwcOHC+fPnu7i44B1ErrDZ7Kqqqu3bt/v7+8MKbW307NmzhISEFStW4B0EAAAA6IwqKiq4XK4kFh2Q5yv2ALTFzZs3EUIzZ86EXj1ovTlz5piZmeGdQt4oKChoaWlNmzbt4cOHCKHS0lK8E8mwS5cuDRgwAO8UQFISExOTk5PxTgHwUVNTc//+fbxTAHnw/PlzWMdecmCMvTjOnz8Pl+uBePbv30+n0xFCML8U+CGurq4SGjcFevfuPWvWLITQ9evXt2/fzuFw8E4ke9LS0mprax0dHfEOAiSCx+PNnTvX1tYW7yAAH3Q6/a+//nrw4AHeQYDM27NnT3V1Nd4p5JbkxtiTtm/fLontSgMOh0MkEmF1cSAGbW1tV1dXvFMA2XP69Gk1NTUNDQ28g8gzFxcXJpPJ4XB0dXW5XC6RKM9nqNvXiRMnBg0aBB0/eZWQkODp6QnDVTozZ2fnjIwMWJwFtFFubq6bm5uCggLeQeSTtbW1g4ODJLYsz+2hBQsWwMKe4EcFBATU1tZ27doV7yBAJsXFxZWXl+OdQv55eHj06NEDITRs2LDbt2/jHUc2sNnsjIwMLy8vvIMASXF0dITbMTo5VVXV8ePH450CyLxffvkFlviRHFjHXhz6+vpUKhXvFECWbN++fcGCBTARKBDbpk2b4HJoR3r27Bl2Tz6MK27RmTNn3N3d8U4BJCUtLS04OBjvFAB/r1+/joiIwDsFkG1hYWG1tbV4p5BbMMZeHLt374brruCHbN++XV9fH+8UQIZ16dIFm50BdBhfX1+EUHl5uYeHB6y72xyBQHD+/Pk5c+bgHQRIysOHD9XV1fFOAfBnaWl5+fJlvFMA2RYREQEde8mR3Bh7eV7ujsfjkUgkvFMA2ZCVlfX+/XushwCA2AIDA729ve3s7PAO0hkVFBQQCAQ9Pb34+HgJjV6TXZGRkTweb+rUqXgHAZKSlZVlYGBAo9HwDgLwl5mZaWRkBHetArHt2bNn2bJlcDe+zJHnK/bz5s1LTEzEOwWQDTt27LC2tsY7BZB53759g5PceNHX18emDTtz5kxAQADecaQIi8U6evQo9Orlm7m5OfTqAcbCwgJ69aAtYIy9RMEYe3FoaWlRKBS8UwAZwGQyd+zYAYsjgraDMfbS4NixYyNHjkQIJSUl1dXV4R0Hf8HBwatWrcI7BZCgwsLC1atX450CSItr165FRUXhnQLIsDt37rBYLLxTyC0YYy+OAwcOwIIfoDUYDIaJiQneKYA8gDH2UgJbrlJFRWXYsGFfvnzBOw6e8vLySktLYZyRfMvPz4dFp4EQgUBISUnBOwWQYSEhITBnjeTAGHtxcDgcMpkM69iDFh08eHDw4MFOTk54BwEyb/fu3V5eXnDRXqpkZWVpamq+fPnS09MT7yw4WLBgwcKFC52dnfEOAiSopqamrq5OS0sL7yBAKtTW1jKZTB0dHbyDAFm1f//+JUuWwN34Mkeer9jDOvaglT59+kQmk/FOAeTB169fa2pq8E4B/h9zc3MVFZW4uDg/Pz+8s3S033//XVdXF3r1co9Op0OvHggpKSlBrx60xfr166FXLzmSG2Mvh1fssRaM8EK9QCAgEAj6+vp3797FOxqQLs7OzgTCv38CBAKBz+ebmprevHkT72hAxjg5OREIBKwIYWWJQCAYGBjcuXMH72jgX1++fDEzM/v06ZOysnInGX3Tt2/fP//8E+8UQFJGjRpVXFyMNXWELR+BQPD+/Xu8owEceHh45OfnYyWhYdsmLi4O72hANvTs2RNbUIzP5wtbNTY2NuHh4XhHkysXL14sLS1duXJlu29ZDq/YGxoaNrz9nkAgUKnUmTNn4hoKSCOsZU/4BzYiF9Z5BmLo2rUrVoSIRCKRSMSqnSlTpuCdC/w/ZmZmCCEDA4MVK1akp6c3erR///5nz57FKZpE+Pv7b926Fe8UQIJGjhyJVTjCmodAIMBQoE7Ly8tLQUGhYZEgEolWVlZ45wIyQ19fH/sPVooQQurq6osWLcI7l7yR3Bh7OezYe3p6NhpXb2ho6OXlhV8iIKWGDx/eqKgYGBh4eHjglwjIqvHjxzdaW8jY2HjcuHH4JQLNUldXv3XrlpKSUnFx8cWLF7Ffenl51dXV3bhxIy0tDe+A7eP169cUCgVbHQDIKy8vL+x0lRCcUuzMfHx8unTp0vA3FArF29sbv0RAxri6uja6ldvMzMzd3R2/RPLJ09Nz+vTpktiyHHbsJ0yYYGhoKPxRQUFhwoQJ2I0lADQ0YcIEIyMj4Y8MBmPSpEm4JgKyysvLy9jYWPgjmUz29PRUVFTENRQQxdDQUEdHp7S09MCBAwihoqIihFBxcfHOnTvxjtY+/P39t23bhncKIFkmJiZ9+vRpeIba2Nh4zJgxuIYCuFFTUxs+fHjDFq+xsbGPjw+uoYAsmTFjhq6urvBHVVXVadOm4ZpIPsE69j9ATU1t1KhRwh+NjY1hmR/QJC0trWHDhgl/hEusQGxUKnXcuHHCKRiNjY3hLiGZsHLlyoULF3p7e7PZbOw3GRkZISEheOdqq7Vr127fvh3vFKAjTJw4UXiRVklJacaMGXgnAnjy9fUVlgcqlTpp0iS4sgVaz8zMDFssFmNhYTFw4EBcE8knWMf+x0yePBm7eqagoODr6wsr3oHmTJo0CRtpj93ZgXccIMO8vb2xG0BIJJKnp6eSkhLeiUCrqKio5OTkCH/kcDh37tyJj4/HNVSb3LlzR1lZGVpjnYShoWG/fv2wdo6pqeno0aPxTgTwpKqqOnLkSOwss6GhIdyHD37UzJkztbW1sbIE43okBMbY/xisXsPuUoPrZkAETU3NoUOHEggEExOTsWPH4h0HyDDhRXsTExM4SSRD/jutRmlp6e7du3GK01aVlZXBwcFwE36nMnHiRCMjIzqdLqFBm0C2+Pj4GBsbKygoTJo0Ca5sgR9lamrq6urK5/OtrKzgBLGESG6MfctrdzPLuSX59bXVPEm8veT8ZO0VZ1nUr1+/tHe1eGf5MRQqUV2HomVIbcVz8cfnou95rMoSDpcjq+sm/mTtFW9Z6u7u/jm2Cu8sYiIQCEoqJE09BYZ6y3/R0qC6jPs9v57FlLFapUU9TEc7mn91cXH5Es9BiIN3nPZEUiCoaVK0jWhEGbmpsySvvryYw6nnt/hMPSUXPXMkEAiwpQr5fL5AIODV8nZtuCCL54UvXPhtw+Kj0lKbEZCSMllTT0FZQ0aqpnJeWUF9TRUX7yA/itGvx+QvX74YKrtKy1ffagqKRE09BXVdBbyDtAqrll9WUF9dzuVxpbnNQxjRZ+7bt29tDYdJeXmg0UlaBgoqmhS8g7RKTQWvrKi+ppLH50vzt98OBrvMyE8hjugzSsrLT7tQVCZrGSgod2z7uaKigsvlamlptfuWW1jH/tHFou+59Qw1siJDNo7KcoBGJ+Wl19CUSH08NPXNaHjHESU1rvrTX1VsFt/AQqlO7jppMoRIJDIr2fU1PB0T6uBJOnjHEUmA7p0tKM1naxpQKVT5vGNILikxSHmZtQpUon1fla7OynjHESU/s+6v38vqa3mGlnRWLdRLuCIQ6qo5NZU8bSOF4dN0W/ECPD28UPg9j62iQaHRZeT0lVygUIl56TUMNcrQKTod3Lb+Ue+fVWR/quVx+TrGilC3tAuBABVm12roKoyZo0+iSPXNBa+iSgqzWSQSQVWbyuW0fMoYyAo2i19eVK9loDB6jn6Hvank1rEX1bGPOp5v1l3ZvIdUt+HkFZcteHQhb8hkHW0jKT2NnZlQk/C6cuhUA7yDgH+lvKn8nssaPVtKG9A8ruDmsTy7PuomNnS8swAxxVzKd3BXM+8upTMIFH9jP40sGjHLiKwg1W3EzibjQ/W3lOqxi6T3eHHzWJ6lo4pZd2jw4KO6jPPyRtHo2XoqmlLat3//tOJ7HrvvWOk+dS6bCrPrPjwtHb/YQIEmpaf7n0QW0+iUHu7qeAcBkvL1MzPlTaW3n2HH3JZ49+7diooKSdyN32zH/kFYoaElw6w7o93fErTelQNfpmwwUVKWuqsHeRl1f94rGznbsBXPBR0q5U1ldVm9dF63vxWS181NQ98MFoGTbQ/O5vYbr2VgLnX3E9VU8SIP5Exca9aK54KOlpVQXZBVM3KmHt5BmnD/bIGJnYqpHZxwxBOXLbhyMGvRPgu8gzThU2xVTgqrn5c0HljlQ2lBfezd4snrjFvx3I72x51SgYDgMFAD7yBAsvIza5NjK8Yvkd4T0K3R9Lmx77n17DoB9Opx5zpa++2jMrxTNOHDs4peo7TxTgGaYNNLtayQU1kidWNEc1PraEpk6NXLgV6jtD88K8c7RRPeRZdDvSS1zHso19cJir/V4x2ksaKvLB6XAL163JEVCA7umnFPKvAO0piAj5L+qOo1sv1HwwIhTX2qliEtM56Jd5DG6mr431JroVffGRhYKFFoxNwMVge8V0evY1+SV0+FMWZSQEWDUvClI0rYj/qWVqsqI5OddEIKisTSfKlrPZcUQK0iJ1Q0Kblp0jgpaV5mraqWlI5dAgghBRqxrJCNd4rGSvLZNLqU3gDc2TDUycU5Utfmqa3m1VRyFBShkEiWojK5OFfqmi7lhfVSPvgftCOaEqk0vyOqIMmtY9/0WKaaKp6KjMxhK9/o6hQpnG2+roavrEGBmk5qqWoqMCul7op9bRVPRQNOBskDCpWopEKpr+VTlaSrpcvjIroqHLmkl4oGpVb6JpyvqeJC1SQlGOoUNkvqpiWrruBo6MnGQkUyTVmDXPJN6k7rMCu4atrw7XcWyhqUjlkGTk1NTUJbbroNxOcJeFJ38O2U+IhVI3XfBAEhFlPqUgEhHk/A50nd+SA+XyDd6wOBH1BXw0XSd2avrgZKmFTj8xFP+qomAR9xoeBIBwFfUC99HXuEkHSmkjN8HpLC2eYFAsRlS10qICF8noDfIetdeHp6SmjL0nW9BQAAAAAAAAAAkEsdPcYeAAAAAAAAAAAA7aijx9gDAAAAAAAAAACgHXX0GHsAAAAAAAAAAAC0IxhjDwAAAAAAAAAAyDAYYw8AAAAAAAAAAMgwGGMPAAAAAAAAAADIMBhjDwAAAAAAAAAAyDAYYw8AAAAAAAAAAMgwGGMPAAAAAAAAAADIMBhjDwAAAAAAAAAAyDDJjbHviCv247yG/HYxtAPeqJUmTBp19tzxtmxh2/b1a9Yubr9EAAAApNrbd7FTpo4dNqJ3alqynB0CsrIyBg1xSUz8iHcQAACQZ4WFBYuXzhw+ss/1G+E8Hi9gx8ZRY/pt2bpWom8KNbwU8vT0nD59uiS2LJO34o/3HlpQmN/Bb7o9YMPDR3fbsoVbUVf37t/eboHAD4L9D9pF26sCIIsuXT6rrKwScizMxNjUw8Pb12cK3ona5MuXzMlTPLD/a2nrrFyx0cDACO9QoE2gagKiQSsIdw8e3v76NevAvpDBg0YkJH54/iJm8aJVixevEv2qNvZ6oIaXQjDG/l9FRYWVlRUd/75pacm4bwG0Bex/0C6gIHVO1dVVdnbdu1rZKCoq/uTSu0+f/ngnapOGxVhFWWXcWF9NTS1cE4G2gqoJiAYlBHfV1VW6uvoODk4aGppVVZUIoQHuQwz0DUW8pO29HqjhpZAMjLEvLy87cSr4/fs31dVV2tq63uMneXtPFj7K5/OOhQQ9jvmdza53ce69do2/qqoaQqi4uOjEycNxcX/XseqMjbv8PGnmsGGjEUIpqZ8XL5lx4vhvNtZ22BamTR/v5jawd+9+q9csQghNmTrWzW1A4I4gEZE4HE7YhVPRj+8zmdWWltYL5y+3t3fAHiISiRd+O3P7zjUms7pnz582rt+urq6BvW9o6LH0jFQ2u960i/ncuUtdnF0RQoOGuCCE9u0PCDkedPf2c4QQgUD4/cHtixdDS8tKzM0sV6/e3NXKBiHEZrPPnjv+7Hl0eXmZpqbW0CGjZs1cSCaTV65eEB//HiH06NG9Z0/etddulyHJyUknTgWnpSWrqKgOHjRizuzFCgoKCKGYJw+vXr2Ym5dDoSh069Zj6ZI1hgZGCKGAHRsRQr169Q2PCCst/W5s1GXF8g12dt1FP9Sa/X/61GUrS+vmcvJ4vN8unnny5OH3kmIVFVW3vgMWLlihqKgo+n2LigpPngr+GB9XW1ujp2fg6zPF08N7Z+Cm8vKyQ0EnsS3PmOVTXV1168Zj7McdO3+pravdu/vXiory4ycPx8fHVVZWmJtbzZ/n19PRBTu5/tvFM2tX+x88FDh82JjFi1Z21HclLUpKvgcd3vXhw1sGQ9nXZ0pNDfPlq6cXzl9HCDW3075+/TJrzoRDQSdv3IxITPxIJBIHDRy2dMkaEokk4lX/3dWtrwqePH107dqlrzlfFBWVBg8aMW/uUhqNJvpziagtvXyGTZ86t6i48OmzR3V1td2791y72h87Ht//Per6jfCCgjwqlebQw8lv6VoWq27mbN9fD5/p0aMnliRw1+aVKzaOG+uLEMrJyZ452/d4yAVbm27NhdwesIFAIJiYmF69dmmr/x5Z76z+qP9+71wu99Lls0+fRRcVFWhr607wnTpurC+Xyx02ojd2lTvq9rWQo+evXL3IZFYHHTwhXnkT7fad6+ER5ysrK6ysbJb5rVu4aNrmTYFDh4y8cvVi2IVTD+6/xp5WXFw06ecxuwMPY99ac19xk1VT2IVTF347g5XnpUtWO/XsNXf+5CPBod27O2Il7eq1S/n5uYqKSq69+i5etEpDQ1N04exsRFRNTRahdqyamqs92qVq8vIZNnXK7OzsrFevn/F5vNGjx0+eNOPgocDEhA+KSkqzZy0aOeJ/SzQ1d0BvrvR2yNciRbhc7vETh2KePOTxuO79h7j1HbBl29qb16OxpmZzX42IP7HmyhV2OXfa1Dlv38V++PD25vXHioqKTbZh/tsKSktPCQ09lpqWzOVynHr2WrpkjZ6efouf61jIwSdPHgqQoLdrv379BgXs2Hj96kNNTS0RbadOqMladNmKuUlJ8dhfq6Ojy8eP77Cv7yeX3vv3HWtyOx8+vmvU62mulYsQ8hg7YMrPs3NysmP/fs1i1bm49F63ZouqqlpWVkbDGv7Ro3sRVy4UFOTp6RlMnjRj1Mixoj/Lf9sJzZUcLpd7JvTY8xePy8vL1NTUB7gPXTB/GYVCuXb98sVLZ7f47w45HlRUVKCmqj5r5sIRIzxE7CsxmtzY1sSo93AhA2Ps9x/c8flTwpbNu0NPR0z5eVbIiUOv/3gufPTBwzt8AX/f3qPr12378PFt8K97sY73ug1Lv+V+3bkj6PzZq+79B+/eu/WPP16IeJfu9o5bt+xBCJ06eemXDTtERzpx8vD936OWLF4dfPiMoaHx+o1++QV52EPPnj+urCzfs/tX/827Pn9OCLtwCiFUX1+/YeMyioLCwQPHT4T8Ztetx5ata75/L0YIXY38HSG0zG/dpYu3sS18zfny5MnDXzbuOLAvhM1h+29ZzeFwEELBv+598PDOooUrw85fnztn6a2oK6dOH0EIBe441NXKZvCg4VE3Y9pjf8uYgsL8teuXGOgbHTp4cpnfuoeP7p44eRghlJzyadduf1dXt5PHL+7dc4RVV7dt+zrsJSQyOTHpY3Jy0umTl29ef6yqqrbvQECLD7Vm/5ubWYqIev1GeHhE2Jw5S86eiVy/btsff74IPRfS4vvuPxBQUvp9967gc2eventNDv5179t3sU5OvZJTkrhcLkKorKy0uLhQIBB8+/YVe0lC4gcXZ1c+n79h47JPnxI2rN9+6sQlG2u7jb8sz8rKQAhRKBQWq+7mrcgN67ePGzdBYl+O9Dp4KDA9PWXnjqB9e47GJ7x/+iyaSCQihETsNBKZjBAKOR7086SZt2898d+861bU1Zevnop+VaNd3fqq4PXr54G7Njs7u545HbF+3baXr54EHd7V4ucSUVuSyeSIKxdMTc0jLt89F3o1PT3l4qVQhFBCwoeDQYE+3j+fDb2yZ/evlVUVATs3mpiY6ujoJn2Kx16bkPBeR0c3MfED9mN8wntlhrJ1V1sRISkUStaXjLT0lL27j2DHy07lv39iJ0/9euXqxak/zz4bemWC79RjIQfv/x5FJpOjbsaYmJiOHjUu6mZM1662wi2IV95EiI9/H/zrXvf+Q06fvDxl8qzDh3djpUL0q0R8xU1WTZMnzfT2nqyjoxt1M8bTw6fhpqKj7x8MChw+bMy50Cs7th9IS0/5ZdMKgUAgonB2Qs1VTc0VofaqmkTUHu1SNZHJ5KvXLrn1HRB1M2b+/GVXr13a+MvyKZNn3Y56OmK4R/Cve6uqq0Qc0MUrvXLp+o3wu/duLpi/7ETIb1pa2idP/4pdUhL91Yj4E2uuXGGvunvvprmZ5eGgUzQarbk2TKNWUFFR4eo1CwlE4uGgU0EHT1ZVV65Zt5jNZov+XJfDz9//PWrJktUnT1yyt3c8eSpY+BWLaDt1Ns3Vont2/Tp61DgTE9OomzHbtuxdv24rQui3sBtbt+xtblP/7fU018pFCJFI5Mgrv/V0dLl5Pfr0ycvp6SlHQw422uCLl0/2H9wxcoTnkV/Peozx2n9gx/MXLfRKGrUTRJSc8Iiw6Mf3167Zcv7ctdUrNz17Ho11r0gkck0N89q1S0EHTty+9XT48DH7DgTk5GSLPuL8aJNb7HoPFzIwxn7pkjX794c4ODgZG3cZPWqcpUXXd+9ihY9qqGsu91tnY203aOCwcWMnvP7jOYvF+vvvP3Jysjes3+7g4GRkZDJr5kJ7e4dbUVdEvAuZTFZSoiOElJVV6HS6iGfW1NTc/z1qxvT5gwYOs+5qu2bV5p9c+uTlfcMepdMZy5ett+5q695/cO/e/ZOTkxBCJBLpcNCpjeu3W1lam5qaz5m1mMViYY1mFRVVhJCSkpKqiiq2hYqK8m3b9vXo0dPBwWnxolXfvxd/jI+rrKyIfnx/xvR5gwcNNzQwGjZ0lLfX5Hv3b3I4HAaDQSKTKQoK2K0Knc39+7cUFKjr1m6xs+vev9+gJYtWYedBjI26nDxxceaMBSYmprY23Xx9pmRmppeXl2GvYrHqlixeraioSKPRhg4ZlZOTzWKxRDzUyv2PXSFpztAho06duDR40HAjI5OfXHoPGji8YUluLlLWl4yfXPrY2nQzNDAaN9b32JFzFuZWzk6uLBYrIzMNIfQxPs7Coqu1tV1C4geEUG7et9LSEmcn13dxf6elp6xd4+/U86cuXcz8lq7V1dW/eSsSuyuExWL5+kzp7eom+k4tuVRWVvrmzZ/Tps79yaW3hYWV/6ZdVf/cjSZip2EGuA/t1q0HQsjZqZeBvmFq6mfRr2q0q1tfFYRHhjk4OM2f52dkaNzb1W3+vGUxMQ+Ki4tEfzTRtWUXE7NRI8eSyWQdHd1eP/XFwn/JzqRSqSNHeBoaGNnZ2m/bsnfpkjUIoZ6OPyUm/W9GnI/xcWNGeyU06Ng7OfUiEokiQgoQys/P3bghwMHBqRNWTY2+dyaTefvOtUkTp48Y4WFkaDxurO+I4R7hEWEIIVVVNSKRqKCgoKqq9t+Oyo+WNxEex/yurq6xeNFKExPTPn36jx83sTUfRMRX3GTVRKPRqApUAoGgqqpGpVIbbura9ctubgOmTpltbNzF0dF5md+6tPQU7CpTc4WzsxFRNYkoQpg2Vk0iao92qZoQQpaW1n369CcQCIMHjUAI2dl179atB/ZjfX197revIg7o4pVeufQo+l4/t4EeY7xMTEznzlmiq6MnfEj0V9Pkn5jockUgEGhU2sIFy7t160Emk5trwzRqBd25e51AIPhv3mVubmljbbdp486CgrwXL5+I/lzRj+/3cxs4auRYI0Pj8eMm9HT8SfiQ6LZTp9JcLcpgMBQUFIhEoqqqmpqamqKiEvaXy2AwmttUo16PiFYu9nwrS+sRIzyIRKKJiamnh8+rV0/r6uoaZevnNnDypBnWXW0n+E6dPGlGacl30R+nUTtBRMn58iXD3MzyJ5fehgZGvXv3O3TwpPAeHz6fP33aPE1NLQUFhWlT59JotCdPH7Z4xPmhJndb6r2OJ7kx9u12JlWRphgeGfbx47vKygo+n19dXWVoaCx8tHv3nsL/d7PrweVy8/Nz0zNSqFSqpUVX4UNdu9o+efKwXfJkZ2ey2Wxbm27YjxQKJWD7/oYZhP9XV9P4XJuI/f1wuJwjR/dnZKYxmdXYGSNsDMx/mZtZqiirYP+3s+2O3fhKIpF4PB72I8ba2o7FYuXm5piZWbTL55JRaWnJXa1shD3q4cPHDB8+BjvSFBTkhYYey8v7xqpncTkcbAwSdruaoYGx8BYaZWUV7CHsN00+9C33a9v3v6qqWvTj+wcPBZaUFHO53Lq6WqzyxTQXqW8f94jIMCaz2tXVrUf3nra29v883+hTUryNtV1Cwvvu9o5KSvTEpI9jRo9PSHivqallZmbx8tVTCoXi6OCMPZ9IJPbo3jMjI1X4jp3wOiomL++bQCCw7/a/4TN0Ot3Z2fVrzhfsLlDROw2r4jEMhjKTWd2aVwl3dSurAj6fn5aWPGvmQuFvsI1nZaXr6OiK+Giia0vzBuGVlVWwS2Q9HV0IBMLylfNGjxrn7Oyqr2eA3avm7NTr6LEDAoGgoqI8L+/buLG+l8PPFRTm6+sZJCV9nDplToshjY27CM9Xdk7C7z0zM43L5bo49xY+5ODgfP/3qNraWiUlpeY3IGZ5a9LXnC8W5lbCy7/d/hk+JoLor7i5qqlJfMwG3AAAIABJREFUXC43Myt90KDhwt9YW9shhDIy07B7OJssnJ2NiKpJRBHCfmxj1dRi7YERu2rCzrb/E4+BEDI2NsV+xHoXzBqmiAO6GKVXLgkEgtzcHI/RXsLf9Os36P2Ht635apr8E2uxasLOFmFEt2GEkpOTbKy7KTOUsR91dfX09Q0zMlKHDR3V3OficDj5+bkN79y2t3cQztfYyveVey3Wom2RmZUuupVrZWUjfMi0izmbzS4pKW64hUbFb+GC5a1534btBBElp28f9917t+7Y+Yu7+xAnp14mJqYNNyLMRqFQDA2M8/K+tbivfqjJ3ZZ6r+M9fvy4srJy3rx57b7l9unYc7nc9Rv9eDye39K1JsamJBLJf+uahk+g0/89HUVTVMROwzBrmDSaIoFA+PdpSvTa2pp2iVRdXYUQolKbHlnRcNgP4Z8Eubk5a9Yu6un406ZfdmppavP5/ImTRze3/YafCNtafT0LC48d//55SAkhVFdX2y4fSnZVV1fpNDhjLfT0WfTOwE3Tp81d5reOTmckJn3EBtVgFP7/pSTseCnioXbZ/0ePHXgc8/uqFb90s3egKlAjIi88ffaoxUirVv5ibmb5OOb3a9cv0+n0sZ6+c2YvJpPJTk69EpM++vj8/DE+buH85VQa7dGju9h9+M7Orgih2toaDoczYlRf4QZ5PB7WZ8M0LGmdCjZbjGKDDpXKP8eVFndao68J+45av6tbWRWwWCwejxd24dRvF880/H1pmaizsC3Wlo2uoGK1k4mJ6bEj5yOuXDh95mj1oV22tvZ+S9fa2do7OfWqZlZnZ2dhTWpVVTVra7vEhA/YIDRnZ9cWQ3baAiYk3ANYBbJqzULhUQkrOWXlpaI79uKVtybV1tZoqP/7HKVWtIxFf8XNVU1NbqqOVScQCBpWoUr/vwptsnB2NqKrpuaKEPZjG6umFmsPjHhV0/8SKig0/JHaVODmDuhilF65xGKxuFxukyWkxa+myT+xFqumhtW46DaMUE0NMz0jdfjIPsLfcDgc0SWkjlXXZBPrh95X7rFYLNG1aFu02Mpt+I1gva1qZjXtn64Qi8XicDg02g9PfNCwgIkoOcOGjVZSot++c23P3q08Hs+t74CVKzZiF+oQQg3HutMUFauZ1S0ecX6oyc1ms8Wu9zoejUYT3oPcvtqnY5+cnJSVlSGcwwkhVFlRrq9nIHwCi/XvrSB1tbUIIRpNkUFn1NXVCgQCYVVVU1uDlZ6Gvf3/baH+xz6/qpq68G+glZ4+i+bxeP6bd2EVa1FRoYgn1zX4RLX/fCIsfMM3xf4PTWdVNfUmv4v792/1dHSZM/t/K0LXt62Ut33/83i83x/cnj5tHjaJI1aFteaFZDLZx+dnH5+fy8pKox/fP3vuuJqa+sQJ05yceh0LOVhRUZ6Tk93N3kGBolD8vaik5HtC/PvZsxZh2RQUFM6cCm+4NeEVj84Mq9AbFonqfy4PirfTWv+qVlYFNBqNTCZ7e00eM3p8w9+r/XMYa1KLtWVzLCys/DcF8ni8xMSPZ88f37R55dXI3zU1tbp0MUv6FJ+ZmYbdGNXd3jEx6aNAIDA0MDLQN+Tz+WKE7JywimLzpsBG03DoaItzsl+8UkqjKTY8XGJXdDGNDotsdv0/LxFVDpurmpp8d0WaIpFIbFiF1sAh7D9EV03NFaHi783eDtr6otLK2kO8qqn1mjugiyi9nQp24ozVVAkR76tpfdXU+jYMnc7o3t1xzarNDX8p+ho71j9s+BULP5fYbSf5Q6PRJFeLttjK/e9DKsoqwqkTaDQajUZr4wVU0SXHzW2Am9uAurq62L9fhxwPOhC0c3fgYeyhuro64VXV2toaPV19sY84TR7XfH2myFBrx9PTU0Jbbp/+Qz27vuEpyU+fEgoK84UXVxFCwlGgCKHUtM8UCsXAwMi6qx2bzU5LTxE+9PlTgo1NN+zSfcOjQnl5WWnp/zvj0nDjTTI26kKj0eIT3mM/8vn8FavmP3p0T8RLOBw2lUoTni59HPN7oyc0fNPs7Ewmkyn8RAghU1Nzc3MrEokknMsK2xUMBkN4p1yLseWVlaV1ckpSff3/WqLR0feXr5zH5/PZHHbDkb3YkBux91Lb9z+fz+fxeMKSXFNT8+dfL1t8FZPJfBzzAJskT0NDc/KkGXZ23bGpj3o6upSWljx8dNfMzEJFWYVGo1ladH367FFBYb6TUy+EkI1NN+wso4mJKfZPQYGqpaUj3h6QJ9i3lpL6CfuxpqYmLu5v7P/i7bTWv6qVVQGRSLSysikqKhBuUF/fkEQmCwfpNKnF2rJJyclJnz4lYFOBODo6z5m9uLKyoqysFCHk7Oya9Ck+PuG9g4MT1rFPSPyQmPQRuyVEvJCdk7m5FYVCKS8vE+4rFRVVVVW1RtcwW0m8Umps1CUzK53P52M/Cg9h2FUa7Eog9iM2eYfor1hE1dQkMplsadG14fH686cE4e2RACOiahKvCLW+qLRYe7Slamq95g7oIkpvp0KhUHR0dIUlBCH0+vUz7D/ifTWtL1cttmGE/7e1tc/L+2ZgYCTcJoFAEL3IhYKCgp6ufsNBIsK5WsVrO8klCdWi2M5ssZWb0OCPLjX1M41G0/7/Z38sLa0bPudoyMH/TrAnmoiS8/r184LCfOxG5kEDh40ZPf5Lg8NNfHwc9p/a2tqcnGxjY1Px9lVzxzXZau1UVFSUlpZKYsvt07G3tOiqoKBw81ZkaWnJ23exR47u/8ml97fcr8JZ0AoL83+7GJqXn/v2Xeyduzfc3YfQaLRevfp26WIWFBSYnPIpLz/3TOixlNTPE3ynIoR0dPSw4TpcLreaWX3k6H5hfYF9Q7Gxr7Ozs0REYjAYo0aOvRx+Ljr6fmpa8qHDu9PSku1Fjm+xtbGvrKx48PBOaWlJ1O1rKamf1NTUMzPTmEwmlUqlUqnxCe/TM1KxwqSkRD9wcEd2dlZWVkbo2RA9Xf0e3XuqqqiOGjn2cvj516+fFxUVPnp07/adaz7eP2Onb5UZyhkZqektjbGUSx5jvLlc7q7d/klJ8a9fPz915kgXEzMikWhrY//uXWxyclJhYcHh4D0aGlpYZSTeDSqt3P8iVgSlUChWltaPou/l5edmZqZv8l/p6upWXV2Vk5MtbE//F4FAOHJ038GgwPSM1PyCvJgnD9PSkh0dnbFRZ1aW1reirvT4Z5oJe3vHm7cizc0tsXrQ2amXlaX17j1bPn6MKyjMj3nycMHCKbfvXBPj48sZQwOjrlY2ly+f+/QpIScne8++rer/3Jsq3k5r/ataXxVMnjTj5aun4RFh3759Tc9I3b1ny/IVc2tqRJ0Ob7G2bNLfb/7cvGX1i5dP8vJz0zNSb96M1NPV19XVQwg5Of704cPbr1+/dLd3xMa15ubmvIuLxTr2CCExQnZODAbDw8M77MKpp8+i8wvyPnx8t3b9kr37t4u3NfFK6ZAhI0tLS44dD8rMTH/6LPru3RvCh7DZ+H9/cBub0uX27X831dxXLKJqYjCUS0tLEhI+FBYWNAwwYcK02NjXV69dKiws+PDx3dGQgw4OTjbQsW9ARNUkXhFqfVERUXu0vWpqveYO6CJKb2czwH3oixcxT59F5+Xnhl049b3BOGcxvprWlyvRbZiGrSBPD5+6utp9+7enZ6Tm5ub8djF09tyJKSmfmnj7BoYMGfnq9bM7d29kZWWER4QJe5gi3rcTdu/btxZt2OsR3cpFCJWUfg+7cCovPzc29vWdu9cHDxrRaHCHr8+Ut+9iz4edTEn9fONmZFTUVVsbUROv/JeIknPjZsSOnb/Ex7/HSunzFzEOjv+bOoREIoVHhiUmfvz27Wvwkb1YWRJvX4k4rslQa+f69evXrkmkqd8+t+KrqamvX7ctNPRY9OP7Xbvabli//XtJ8c7AX1avXXT+7FUejzt1yuzCwvzFS2ZwOGzXXm4rlm/ATmvt33vs+IlD6zcsZbFY5maWOwMOOvX8CTsvuHFDQMjxIM9xA3V09ObNXVr8vQg7Ddy1q22vXn1PnDzc3d5RuEJ4kxYuWEEgEk+e/rWurtbMzHLPrl+xBdKb07ev+6SJ00+dPnL8xCHXXm4b1wdcv3E5IvICkUhcuWLjz5NnRV658Ndfry5djOLyuN3sejg7u27ctLy0tMTKyiZw5yHs72r5svVKSvTgI3srKsp1tHWnTZ075edZ2Pa9vCbv2bt1+Yq5woWIOw9dXb19e46ePP3rmnWLVVRUBw4cNn+uH0Jo6tQ5+QW5a9YtVlKie4zxnjF9Xmnp94OHAokiJ64XoTX7P2D7gV4/9WluC+vWbj1wcMecuRP19AzmzF5sa2P/KSl+8dIZoWeanc6aTqfv23ssNPTY6jUL2Wy2np5Bw/V+nZx6Xbl6sUcPJ+zH7t0dr98I9/WZgv1IIpH27T164lTwtoD1LFadnp7B9OnzsNNbwH/zrgNBO1etWailqT116hxNDS3s4CHeTmv9q1pfFbj3H7zpl50RkWHnw07S6Qx7e4fDQadEL9ghurZs7lXTps7hcjknTwaXlH7H3mjvniPYvdkODs5lZaXGxl3U1NSxE1impuZfvmQ6/rNkuhghO60li1YpM5RPnzlSWlqioaHZt4/73DlLxduUeKX0J5feSxavunL14r17N62sbJYuWbNy9QLsoa5WNvPmLv3t4pnTZ46YmVkuX7Z+wcKp2GFRxFfcXNU0ZPDIR9H31qxbPOXnWQPchwoDDB0ysr6edfXapTOhx+h0Rj+3gQsXrhBvD8ix5qom8YpQ64uK6NqjjVVT6zV3QBdRejub2bMWlZeXHji4g0qlDRkyctqUObv3biWTKWJXyK0vVyLaMI1aQYeCTp0+fWT5irkkEsnU1CJw56EWJ+udPm1eeXnZ6TNH+Hx+b9d+M6bPP3Bwp+j3vXEtWjoXEpec9q1FG/V6RLRyEUJjRo+vZlYvWTqTza7v07v/Mr91jbY2wH3IyhUbr167FBF5QVdXf/my9UOHjPyhPHp6+s2VnK1b9hw/cWhbwPqaGqamplZv137z5voJX7hg3rKjxw5kfcnQ1tLZGXAQ65GJsa9ENLllqLXDYDCo/5lBoF0QmjyX9uZhWT0LOQ6SxmEJnUp9LT/qWPa8XeZ4B/l/WDX8S7uzJ62XrlRA6O2jEg0dsuNA6Vq97HVUCYVGtuvzA6lYLBaHyxFOvrp6zSIVFdXt2/ZJLCNorYh9WTO3mFIVpWsyiNObsrxXmFJp0pWqLSorK8Z7D922de/AAUNb8XRp9/FZGU0J/TRcupoWfz8o43CQw4AfSAVVU2uIUXq/57LeRZdMXCXqGkzHK/zKenGjZPTcH0jF5XKZzGrsZCtC6LeLoTdvRUbdbGHBcJnz/EVMwI6NUTdj2mW11Mz46uKvtcOnS9cE5qnvqrMSa/t5S1eqJo3zGuLj/fOM6e0/0Xob3bx1JeR40JPHb/AO0rJPf5bzOHy3sS1McyvN5KcBBACQM5s2r1y2fE5i4sfc3Jxr1y9/+PhOeB8EAADgBaomINrl8PNTpo19/iImLz/39R/Pb96KHDHcA+9QAABpUVxcXF0tkelF220d+46XmPhxk//K5h69dPF2J1+cGTTnl80rkxrM1dHQmNFei+C+U6nhv3nX8ROHtmxbW1/PMjAw2rh+e+/e/fAO1TKomoAIUP/IARmtmhBCnuMGNvfQxvUBbm4DOjaO3Jo6ZTabXX/yVHBZWamOtu6Y0eNnTJ+Pd6hWgQqq44VHhEVEhjX5kImJWcjR85IOANVCx/P391+4cKGzs3O7b1mGO/Zdu9qe/v/LwzQkvEcOgEbWrvZnc9hNPtRwOU2AOw0NTf/Nu/BO8cOgagIi/FD9o6qq9uzJuw7JBX6AjFZNCCERVZO6WjsPkejMpZdMJs+f5zd/nl8rnitdfqiCGjhg6MDO+hW3I09Pn0GDhjf5EIVMaf12bt96Il4ASVcL3l6TvL0mtX078kRZWdnExEQSW5bhjj2VSm3N4s8ANCJ6QRcA2giqJiAC1D8AR1A1AdGggup4ygxlfM/4Q7XQ8YKCgiS0ZRhjDwAAAAAAAAAASFZdXV1qqqTWPpfhK/YAAAAAAAAAAIBMuHr1amVlpbW1tSQ2DlfsAQAAAAAAAAAAyaqrqxsxYoSENg5X7AEAAAAAAAAAAMlatGiR5DYOV+wBAAAAAAAAAAAJSk1NjY2Nldz2oWMPAAAAAAAAAABI0IYNG4yMjCS3fejYAwAAAAAAAAAAklJUVLR161aJduxhjD0AAAAAAAAAACApurq6urq6En0LuGIPAAAAAAAAAABIRGRk5K1btyT9Lk137Gl0EolEkPR7gxbxeQJNQxreKRojkQmqWgp4pwDNIpEJNCWpO2dHo5MIUhcKiElNW4FEkbqvU8uAyufhHQI0j0giKNJJeKdojKZEJJGhwSMV+AKkpk3BO0VjJAqRrgL3t0oeAdHVpG4/U2gEiqLUHeyAhBBIBEWGRL7urKystLQ0Ly8vSWy8oabTa+gqFGTXSvq9QYtK8lkUitQ1OChUAquWV1XKwTsIaFp+Zq2GPhXvFI2paVOKc1h4pwDtoOI7m8Pik6WuAYYoCoTSvDq8U4BmFX6pVdORupPC6roKhV+g2EiFkm8sJYbUnfrRNlDI/swUCPDOIe+Kc+pUNaXuuKKlT8tNq8E7BeggRdl1apK5cmlubr5161ZJbLmRpjv2hpaKPA6fzeJ3QAIgQlF2nVVPZbxTNMHGRTkvE079SKPaKq4CjahjLHUdezN7esV3Nt4pQDsoyKyzdpHGeqmrk0phNvTQpBSbxedx+YYWingHacyoq1I9i89lQ78NfyV5LAsHBt4pmmDnqgK9O0krL6y36C51RxYVTbKmLrXiO1zKkn8CAWKWc0y7KbX7lk+dOlVYWNjum21S0x17AhEN9NV5FlnQMSFAkz48KSORkbWLNB7kfhqhkZ9R8yWBiXcQ8P8I+OjFtcLBk3TwDtIEEpkwwFsr5nI+3kFAm2TFVxdm1bgMU8c7SBOsXRhEouDD0zK8g4AmPIssGDRRRwrH4xCJaICP1tMIqJpw9uedYkMLmr6Z1A0/RAgNnqQT97ikogjOTUvKs8gCl2EaisrSV0EgNHiyzutbhXCxU+49uZzv7q1NbO+h6Hv37h0wYICenl77brY5BEHzdxeV5LGvHv7Wc4immhZFkSF1t8fILQIqyWVVl3MEfL509tD+R4BuHc/T66JEZZC0DGh8HlzuwA2RgKorudVlnLjHJdM2dVHVkroxikL5mXX3zxV066uuqUejSt9EAKA5BCIqLahnVXOLcuq8lhgiqRsh9K+YiGISmaisTtE2pEGthC8CAdVUcStL2O+flE5ea6KpL3X34Qt9z62/cSS3x0ANdR2qFE4EIMcEfEFxLqskl2VoSXMcoIZ3nGZx2YLIoBwrRxUag6yhS+VBm6c9cOr5JfmsrIRqt7Fapnbtf6W0vdRUci/vzXEYoEFXJatoKkCLV56wanllhfVJr8s9FxhI54nFHyKqY48Q4nEF75+WF31lMStlb0qi8vJyBoNBoUhvJ6dJ6npUKo3QxUbJzJ6Od5aWJb+pzs+q43IE5bJ8JrusrExVRYUkhYOGW4esQFCkk/S60JyHSuN11EZYNfz4FxWlBfVV5Vy8s7S/iooKOl2JQvm/9u48Pqry7B//bJnMZPYlmZlkkkxWEpKQkAWiAoJlFRSwiop1o+Kj/IQgRauttlYeK1ht1VrtD6q4g0gLlk1ZiqxZCFkIIQvZl9kz+75+/7jLeY6ToCxJzszkev9xXvecQHKFJcnnXq4TvgHmxggSYmh0SlIGM6cs7LZKDtfVZO9rc3hcAYM6gr8uRQEKhRzHpUpSYkvmCilhP4/n8wTrjxu1/W6rKfK+NLlcLo/Hw+VyiS7kugkldCabmlnEjogfqZtOm1U9Lp8naDGE9d5sj8fjdDp4vPCdKEH44hiuKCb/Vh43/E7XD1f/H5O61+VxBZz2yMtE10uv1wuFQkr4f+G+aVwBTZQUW3Q7P3ZUuyR6PJ6f//zn+/btG8X3eS1+IthHtMcff3zDhg0FBQVEFwLC3f333//aa69lZmYSXQiIeP/zP/+zevXq0tJSogsBAEwgBw8erKys3LRpE9GFgLBw6tSpf/7zn2+//TbRhYBItWDBgi+++EIsFhNdSKT6+OOP77rrLpFINM4fN/pnYgAAAAAAAAAAgDH1wQcfkEikxx57bPxTPQR7AAAAAAAAAADgpvzqV79SKBQEFhDNwT49PZ1KhRY44KdNmjQJ/qmAUaFQKGgR26wBABChYmNjYdMswMTExMhkMqKrABFsypQpZHIYt8kNM263++DBgyQS6eWXX160aBGBlURzsKfT6R4PdE4CPy02NtbtdhNdBYgGMTExPl/kdd4CAEQ0t9ut1+uJrgKEi0AgAN+JwE2KuO7jRDEajXPmzElJSSGRSHw+wR0roznY5+bm1tfXE10FiACJiYkdHR1EVwGigUAg0Gq1RFcBAJhYYmJiIrElPhgjdrudTo+2h7OAcWOz2QKBAHxJ+Un79++3WCw+n+/s2bP5+flEl0OK8mB/9913W63Wo0ePEl0ICHfLly8/fvw40VWAaFBUVHTx4kWiqwAATCxer9disRBdBQgXOp0uPj6e6CpApKqpqUlLSyO6inD35ptv1tbWstnssPq/Fs3BnkQirVu37tSpU19++SXRhYCwxufzf/GLX/z6178muhAQ8UpKSlwuV3NzM9GFAAAmEDqdLhAIiK4ChIvBwcH09HSiqwCR6vDhw3fffTfRVYSpnTt3fvHFFyQSadWqVa+88gqFEl5ROryqGQt/+MMfgsFgRUXF4cOHia4FhK+pU6du2LBhw4YNra2tRNcCItuGDRvQw04AAGB8eDweo9FIdBUgXPT09EybNo3oKkBE+vOf/1xWVoZOjAOMWq0mkUhHjx4dGBhYunQpiUQSCoVEFzUCcjAYJLqG8aDT6Xbu3PnNN9/cf//9y5cvh+axYERqtfrtt9+Wy+UPPfQQrH6AG+bz+Z5++ul3332XyWQSXQsAIPodO3bswoULzz77LNGFAOKdPHny7NmzL7zwAtGFgMjz8ccfp6enz5o1i+hCwsvGjRuNRuOHH34YCATCbYk+BPWVV14huobxwGKxpk+ffvfddzc3N3/55Zf79u0jk8nx8fHwYzfAY7PZc+fONRgM27Ztq6mpSUlJgXgPbgCFQpkxY8aLL77I5/Nh2hsAMNZaW1svX758xx13EF0IIN4LL7ywZs0akUhEdCEgwrz66qs8Hg8tRwOlUvnRRx9lZmbGxcXx+fw1a9aQSKTwfwTgRAn2CIPBKCkpWbJkiUwmu3jx4qZNm77//nuDwcBgMMKq8wEgVmZm5qJFiywWy7Zt26qqqtxud3Z2NtFFgQjDZDIXL168a9euqqqqvLy82NhYoisCAESty5cvDwwMQLAH+/btCwaDy5cvJ7oQEEm+//77NWvW3H///ffccw/RtRBsaGior69PLBa/9dZbiYmJ06dPJ5PJSUlJRNd1rSbKVvyraWxsPHv27JkzZ3g8HovFKi0tLSsrg1aQAFNfX79nz56Ojo60tLQFCxbA9iRwvU6cOPHZZ59NmTJlzZo1NBqN6HIAAFHoyJEjDQ0Nzz33HNGFACJ5vd5169ZBkxdw7bq7u//+97/7/f5XX301Li6O6HIIY7fbWSzWsWPHtmzZsnnz5uLiYqIrukETPdhjLBbLuXPnamtrDQZDdXV1YWFhYWFhQUFBXl7eRP6HDjDffvvt8ePHjx8/fvvtt8+fP7+4uBj2uYFr98knn+zZs2fp0qVLly4Nz4YrAIDIdfDgwcrKyk2bNhFdCCDSk08++fzzz2dmZhJdCIgAra2tX3zxhc/nW7p0aXl5OdHlEKarq+u1117Lz89/9tlnNRqNRCIhuqKbAsF+BDabraGh4eLFiw0NDc3NzVKpdObMmRKJZNKkSTk5OQwGg+gCAWH8fv+JEyeam5v37dsnFovvuOOOvLy8srIyWIkF1+Lrr7/eunXr4sWLZ82aFbnzwQCAcHPo0KHq6uoJdbgShFi7du39998/Y8YMogsB4e7kyZOnTp26dOnSL3/5y4l5fsfv93/wwQf9/f1btmxpbm72er1FRUVEFzU6INj/tK6ursuXLzc2Nra1tbW1teXk5IjF4szMzKysrKysrMTERKILBMRoa2traGg4depUbW3t/PnzExISSkpKiouL4TQ1+HHHjx//8ssvhUJhbm7uXXfdBVs/AAA3CVbsJ7hf/vKX//u//yuTyYguBISvoaGhPXv2tLS0BAKBlStXlpWVEV3ReDtw4MCZM2c2bdrkdrt37do1d+5cuVxOdFGjDIL9devr62tvb798RWpqqs1mS09PT09Pz8jIyMjISEhIILpGMN6amppqa2vPnz9vt9vdbndBQUFBQUFhYWFycjLRpYEw1dvb++9//7uzs9Plci1atOhnP/sZm80muigAQESCYD9huVyujRs3PvrooxMwp4Fr4XK5jh8//s033zAYjJycnOXLl0f6bvPrUl9ff/z48Q0bNpBIpNdee620tHTBggVEFzWGINjfLIfD0dnZ2dXV1dXV1dnZSafTa2pqFDipqanJycmwgX/iaGtra2pqampqcrlc1dXVkydPzsvLKyoqysjIkEqlRFcHwk5tbe1//vOfgwcP5ubmLl68uKysbEJ90wUA3LzDhw/X1dXBo8snmnPnzq1fv/6LL75QKBRE1wLCi9PpPHPmzIEDB2pqau65555Zs2ZNnKmfrq6ub7/99rbbbissLNy8eXNycvJDDz1EdFHjBIL96HM6nb29vT1XqFSqzs5ONpudckVqaqpMJpPL5dCWL+rZbLbm5ubm5uahoaETJ044HA7UqSEnJycjIwM63AC8mpqa+vr6b775hsfj3XnY5TaQAAAgAElEQVTnnQUFBVFz6AsAMKZgxX4CevPNN3U63ZYtW4guBISRwcHBs2fPnjhxoqGh4ec//3lJSckEeZxTe3v7oUOHCgsLZ8+e/dlnn3k8nvvuu4/L5RJd13iDYD9OdDpdX19ff39/b2+vXq/v6OgYGBhgMBhyuTwpKSknJ4fH4yUmJiYmJsIRqShmNpvb2tpaW1u7urpaWlq6urqys7Pz8/OTk5MzMzMzMjLi4+OJrhEQr729va6u7siRI5cvX162bFlaWtr06dOhnQcA4Gog2E8ojY2Nzz///OOPP/7AAw8QXQsIC1VVVZWVlTU1NXa7febMmTNnzpwIje47Ojp27Ngxc+bM2bNn79q1y+VyLV68eIL3LYJgTySDwTAwMDA4OGg0Gtvb25VKpVKpVKvVSUlJMpksJyeHzWbLcIiuF4yyQCDQ3t7e2dmJrh0dHW63OyMjo7CwUCwWp6WlKRQK2L0/kdnt9nPnzp0+fbq6ujotLS0hIaG4uLi4uBj+VQAA8I4ePdrQ0LBx40aiCwFjy2AwbNmyhclkPvPMM2KxmOhyAJEuXbp07ty5tra2w4cPl5eXl5eX33bbbWlpaUTXNVZsNhubze7t7f3Tn/4kl8tfeOGFM2fO6HS6uXPnQosiDAT7sBMMBgcHB1UqlV6v7+3tVSqVKpVKpVKp1WqpVCqTyaZMmUKhUCQSiVQqlUgkEolkAm41iVYWi6Wzs7O/v7+9vb2np6e7u9tsNk+ZMkUoFKJ+DehKp9OJrhSMt8HBwXPnzp0/f76uri47O5vD4RQVFRUVFaWnpxNdGgCAYLBiH/UCgcAnn3zy5Zdf/vrXv547dy7R5QBiXLx4sa6urq6uzuv1WiyWsrKy8vLysrIyMplMdGmjz2azqdXqzMzM9vb2jRs35uXlvf766319fYODg1OnToXmZSOCYB9JUMI3Go29vb0ajUaj0ajVao1G4/V6pVJpQUEBiURK+CGBQEB01eCmOJ1O1KwBa9zQ29srEonS09MTExOTk5OTk5NTUlLkcjmNRiO6WDBOVCpVXV1dQ0NDQ0MDk8kUCARTroCnLQIwAUGwj27btm3bunXrhg0bHnzwQaJrAePK4XA0NjY2NjY2NDR4vV6fz4c27pWUlERfo65AIFBVVaXVapctW1ZfX79p06ZFixatXr1ar9e73e6kpCSiC4wAEOyjgdPp1Gg0Op1OpVJpf8hms6Hnq7tcrvgrxGIxGkTfF4UJQqVSoZYN6IrMmDHD4XDIf4jFYhFdLBhbFovlwhXBYNBkMuXl5eXl5RUUFGRnZxNdHQBgPBw7dqypqWn9+vVEFwJGk81m+/TTT5uamgoLC5966imiywHjpLu7u7GxET1ficvlMhiMoqKiwsLCoqKimJgYoqsbZcFg8G9/+1t3d/dbb71lNBp/97vf3XrrrQ8++KDL5YI1+RsAwT7Keb1erVY7NDSkVqt1Op1Op9Pr9borKBRKfHx8amoqk8kUi8UikUiMw+FwiC4fXAeVStXf3z/wQ/n5+Q6HIxEnKSkpMTGRSqUSXS8YEx0dHehBDBqN5syZM7m5ubm5uTk5OXl5eZmZmfD3DkBUghX7KNPX1/fpp58ePXr04YcffvTRR2FHXnTr7++/dOnSpUuXmpubW1paZs2aFRcXV1BQUFBQkJGRQXR1owYdMUZrjU888URfX9/JkycDgcCnn36ak5MzEbr9jQMI9hOazWbT6/VDQ0Mo8Idwu91isbigoMDj8YhEIqFQiJI/GohEIphLC38Gg0GpVKKuDYODg2isVCqLiooCgYBMJkMPYkBXmUwGPz1Ek2Aw2NLS0tra2tra6nA4Dh8+nJ6ePmnSpOzs7MmTJ6enp/N4PKJrBACMAgj2UWPfvn179+4VCAS33Xbb8uXLiS4HjImenh70rbmlpaWlpSUjI0Mmk02ePDkvLy83Nzc6frr2+/1UKvXQoUONjY1PP/00j8dbvHhxfn7+li1bfD5fR0dHZmYm/Mw56iDYg6vyeDx6vd5oNKLYbzAYhn6ISqWKRCKFQkGj0UQikUAgQPkfA20qw5ZWq1VeoVKpsB6NxcXFTqcT35oRjaH7bnTo6OhobW1tb2+3WCwnT56k0+mZPwTfZQGIRMeOHWtubl63bh3RhYAbdOnSpb179+7du/fOO+9ctmxZUVER0RWBUWOz2S5fvtze3o6u7e3tcrl80qRJaD9dbm5uFJyaNBqNly9fzs7O5vP5mzZtOnHixD/+8Q+FQrF161ahULhs2TL46WJ8QLAHN85utw8NDRmNxqGhIcMV2B2j0eh2u4VCYWFhoc1mEwqFAoFAIBCEDKDXV1jR6XSoKSPqy4gxGAxYyJfgSKVSPp9PdNXgBul0uo4fSk5ORgl/0qRJqampKSkpRNcIAPhpsGIfodxuN8rzNBpt2bJly5YtgwNTUaCnp6evr+/SpUsoxttstszMzOzs7Ozs7KysrOzs7Ig+Kh8IBDweD4PB+Oabb2praysqKsRi8erVq2k02h/+8IeEhITW1lb44ZAoEOzBGPJ4PAaDwWQyoZxvMBiMRmPIgEqlCoXCtLQ0MpnM5/NR5kcDPp+PBlEwlxnp/H4/FvLxmV+tVqNeDBKJJD4+Hj2LIT4+HnsZlY9giWI9PT0o4ev1+vPnzw8ODqanp6elpaErGsDfKQDhBoJ9xPn+++/r6+u//vprlOeh12nk6u/v7+zs7Orq6urq6ujo6OrqSk5OLi8vFwgEKMbLZDKia7wp3d3ddXV1+fn5kyZN2rx58z//+c+PPvqooKBg9+7dcXFx8+bNi+h5iigDwR4QzOFwoPCPrijwm65ALz0eD8r5kydPdjqd/KuAp7sTwu12a7Va9FwGrVaLrhj0CAYs52PhPyEhAR7KEP78fn93dzf6eaW7uxuNFQoFFvLT0tJSUlKYTCbRlQIwoR05cqShoeG5554juhDwE06ePHnkyJEjR47MmDHjzjvvvOOOO4iuCFwf1Jm4tbUVfWfs7OyUSCQZGRnp6ekZGRloEKHbLmw2G/p0pFLpV1999c033zz88MOLFi3avn27SqVauXKlQqHQ6/VwNjOcQbAHEcDr9aK0b7Va9Xq96SpoNBq2yC8SidhsNo/Hwxb/0ZjP58M5n/Gk1+vxOR8L/xqNhkKhlJSUOBwOFP7RsxiwAcT+sNXT04PlfLRSweFwUq9ISUlRKBRyuZzoMgGYQGDFPsydPn366NGjR44cmTZt2rx582CRMyK4XK4enO7u7p6eHplMVl5ezmKxUJJPT0+PxFUlvV7v8/mkUunp06cPHDiwYMGC2bNnb9q0qbu7e+PGjZMnT7548WJMTExGRgb8zBxZINiD6OFwOLB1fovFYjQazWYzemkymcxmM3pJp9OxnB8fHx8XF8fDQW/icrmw/3+soYcyYI9gRM9iwAZkMnnEwI9AX8awotVqe6/o6+vr7e1VKpUo4aOon56enpSUJBQKia4UgOh0+PDhhoaG559/nuhCwA9UV1d/9913R44cKS4unjdv3ty5c6Oj4XlU0ul0/f39aM4aJXmj0Yh2qClwIivoBoNBi8XC4/FaW1sPHTqUm5u7cOHC7du379y5c+3atUuWLKmurjabzdOmTYMj8dEBgj2YcOx2O8r5JpPJYrGguQAzDrrv8XhCAr9cLieTyegll8vFBtD/byzY7XZ8zsegO36/XywW5+fn+3w+9BRG0RUo+RNd/kTn9/tRwkc9hDweT3V1tcfjSU5OTk5OTklJQdeUlBT4YQKAmwcr9uHDbrefOnXqxIkTJ0+enDVrVnl5+bx582APWlix2+3YNDQ2YLFYOTk5CQkJKMmnpaVJpVKiK70ODocjLi6ur6/v2LFjWVlZM2bM2LFjx1tvvfXss88+9NBDVVVVHR0dt912W1pamtfrhQ0j0QqCPQAj8/l8IYHf4/Go1Wo0F2CxWLABhULhcrlcLpfP52MDsVjMYDBQ8kd4PB5M1Y8Wl8ul0+mMRqNWq0WBH3sKIxoLhUIs8OOvCCz4E8Jms/X39/f39/f19WFXn8+HEj6K+gqFQiaTQdoH4LpAsCfcwMAACvMtLS2zroBv+oTz+Xz9/f0qlaqzsxOL8U6nEzs7hg0iZfLF5XIxGAybzbZ//34SifTAAw/U1dWtX79+0aJFL7744unTpxsaGubPn5+dnW21WlF7YzBxQLAH4Ga5XC6z2WyxWFD+RwPUUg69xPj9fizq83g8DoeDXkokEjqdjp8CgK/FNwkf8tEAH/79fj9K+JMnT/b5fEKhEE0EYNdI+QYfBaxWK5bz+/r6gsFgVVWV3++Xy+VyuTw5ORm7JiQkEF0sAGHq6NGjDQ0NGzduJLqQCaexsfHkyZMnTpzw+XwozJeWlhJd1ASFMjz6hoJNIuv1erlcPm3aNDqdrlAo0DxyRGzrQwHe5/Pt2bPHaDQ++eSTBoNhxYoV8fHxO3bsGBwc3LFjR1FR0dy5c+12O4lEggOkAII9AOPK4/Gg2I+uVqsVjSkUSm9vL/bSbDbbbLbh+R+NBQIBm83mcrkcDgddYU3gerlcLpTzLRaLRqMZGhoyGAzoigbBYHB42se/hDX/MWW1WlHn4f7+fuxqMplQwscHfplMFqH9hwEYRbBiP56sVuvZs2fb29v37NmjUChmzZp1++23p6WlEV3XBOLxeAYGBtRqdVdXV0iGR/u/sGNf4f+oObSu7vf7v/76a51Ot3btWq/Xu3DhQgqFcuTIEafT+c4776Snp69YscLn89lsNtjRBn4EBHsAwtTw/I+gXehWqxW9tFqtgUAAW+1HaR8/EAgEcXFxMAtwXVwu1/C0j3/pdruxtC+XyxkMhkgkEggEQhyiP4lo4/F4UMLHor5er+/q6kpISEhKSkpMTExKSpLL5WggEomIrheA8XPs2LHm5uZ169YRXUg0u3DhQmVlZWVlZU9Pz6233jpnzpxp06bxeDyi64pyFosF+8qPMZlMcrm8pKQkNjY2UjI8elCc0+n86quvrFbr2rVrrVbr4sWLORzOgQMH3G73u+++m5yc/MADDwSDQbPZDAEe3AAI9gBEPLQRAMv52BWh0WhoOwB+FgCL/WjxH7/+z+fzWSwWegk70q/G4/FgOd9sNut0uqGhIaPRaDAYjEYjGvP5fHzOR09hROEfjeHx76NCrVYPDAwolcpBHIfDgRI+Ri6Xy2Qy+DMHUQlW7MeIXq8/e/bs2bNnKysr09PTb7nllltvvTU/P5/ouqKTWq1Wq9W9vb34DE8ikbC9WpiwPZmFHsmUmppqNps//fRTKpW6Zs2arq6uFStWlJaW/v3vfzeZTJ999llaWtqSJUv8fr/L5YIt9GAUQbAHYGJBswBYzg+ZCLBarT6fT6PRoDtutxsf/kMGHA4HP0HA4XBgUzQeyvkIfoyFfxKJhF/kF4lEfD5fcAXK/5H1ZJ3w4XK5UMJXKpUDAwODg4NkMrmmpobBYCQmJqLML5PJsKV++HMGEe3YsWMXL16sqKggupAoUV9ff/LkycrKSpPJhML8LbfcAiewRovD4UBfn9EXZ2wgFouLiopiY2PxGZ7L5RJd7wh6enp0Ol1ZWZnH43njjTdsNtvmzZt1Ot2KFSsKCwvffvttvV6/f//+nJyc8vJyn88H32LA+IBgDwC4Kr/fjw//VxsIBILm5mar1cpgMDhXYMkfjVHyx7YGsNls2A7gcrnwad9kMqGlfgTdYTAYWMhHWwBCkr9AIID5lGtnNBqVSiVa3lepVCj5K5VKPp+PQj6SnJwskUgSExPJZDLRJQPw02DF/ua1tLRUV1fX1NTU1NQsW7YsJSXl1ltvzczMJLquyKZSqVQqFcrt2NXtdqNdVPgdVeE5wVpTU6NWq++66y4ymVxRUaHRaHbu3On3+1esWJGcnPz222+73e5Dhw7J5fLS0tJgMAjfMgCxINgDAEaN3W63XmGxWGw2G5b/8Te5XG5LS4vb7UaxH7/+j/I/BnvJ5XInZncAq9WKhXxsqz8++RsMBhaLFZL8ExMTGQwGfv0/DH9gCis6nQ4L+Uql0uVyXbx4UalUSqVSqVSK0r5MJkNX6NgHws3Ro0ebmpqeffZZoguJMP39/SjJV1dXy+Xy6dOnT5s2bdq0aRDPrtfQ0BCaMMVmTtFVKpXm5ORwOByU3lGAFwgERNf7X2azmcvlksnkf//730ql8oknnqDRaA899NDAwMCRI0fodPratWvFYvHLL79MoVBOnz4tkUiysrKIrhqAq4JgDwAgBtoOYLPZsPV/NMbgX6alpdXV1V0t9o/4cuJMBFgslpDkHwwGu7u70R2j0YhW/vE5H80ChNyZOH9i106tVqtUKqVSia5ooFKpxGIxPuonJycnJCTIZDKYQAHj6d5773U6ncFg0OVyeb1eLpcbDAbdbvexY8eILi18mUwmtDJfXV1No9FQkp8+fTo8ZfZaWCwWpVKp0+l6e3vxGZ7FYqFjTdgVDcJhikSj0Wg0mvz8fAqF8v777yuVyt///vcxMTGzZ8+mUCjfffddTEzM5s2bRSLRqlWrqFRqT0+PWCyGkxcgEkGwBwBEBp/Pd7XYP+JLiURiNpvZV2DJP+SKvZXD4VAoFKI/y7Fis9mMP2QymbDkj16SSKSQqM/j8VDDOXSfz+eH53HH8afRaPBRn0KhnDt3Tq1W8/l8qVQqw0EL/nDwBIyF3/72t99++21IdkpPT9+1axdxRYUjs9lcW1t7/vz52tpamUzGYrFQmA/zPuoEslqt+AlN/Ne6xMTEnJwcNpuNz/DhMC9cVVWl0WjuvvtuMpm8YcMGjUazfft2Op2+fPlyPp+/bds2Go32+eefi8XiBQsWkMlkr9cbExNDdNUAjCYI9gCA6ISe+IpCPjbAX0Puu91uCoWCX/nHZ/4Rb9LpdKI/y9HkcrlCwr/ZbKZQKB0dHWgKwGQy2e12bKkfu2Kwm1H2J3Pt9Hq9Cgdb8I+JicFyPlrhF4vFUqkUHosIbkZLS8tzzz2nVquxO7GxsevXr7/vvvsIrSssWK1WLMxrtdrS0tKSkpLS0tKMjAyiSwsjFosFfbEyGAzd3d1YkieRSPgjSNiYqHVsm82m1WoVCgWFQvn888+1Wu369espFMqyZcvUavWZM2eoVOr69euFQuFLL71EoVDOnDkjEolycnIIqRYAokCwBwCA/3I4HMPzP35HQMjNrKwstVo9fPGfPQx2M9LPZvv9fmyp33QFfv0fXWk0Wkj4FwgEEokELf5jiP5sxo/ZbMZyvkqlcjgcbW1tarXaZrOhY/wo8+NN2MkRcF1efvnlQ4cOYS8zMjI+++yzCfuPx2azoSRfW1urUqlKr4AeeKhvKDbnqFQq0ZcjCoWContmZiaXy0XpPSkpafwDPOo819DQoFar77jjDjqd/sorrwwODv71r39lMBgLFizgcrk7duyg0Wh//etfhULhypUryWSyWq0Wi8VwBgoABII9AADcILfbjV/2Hy5kv4DNZisrK+vq6vqR5D/8ZjicUbxeDocDn/NR7CeTyejkP4bH4/F/SnQffPV4POjRzSj247HZbJTws7KyWCwWGkskErFYTHTVIIw0Nzc///zzGo0GLddXVFSsWLGC6KLGlcFgqLtCrVaXlpYWFxeXlpZmZ2cTXRoB0CkhxGQyoUV4lUrFZDKx3p9YcxCpVDqeAd5ut2s0moSEBDabvW/fvvb29kceeSQ+Pn716tUtLS179uyJj4/fuHEjg8F4+eWXY2Njjx07JhAIpk6dGonfBAEgBAR7AAAYP06nc8RZgB+5mZaWZrfbh8f+q+FwOJHyY5DpGjgcjpCoLxKJOBwOmhTApgair9GRwWBACd9oNPb29qKxRqMxm81YyMeW99EYTvJPTC+//PLBgwfJZHJ6evqXX345EVYvNRoNSvL19fVms7n4ignSsdztdmOHfbBpQXSNj4/H0rtcLo+Pj09MTJRKpeNwBj4QCJDJZDKZXFVVpVKp5s+fz2KxXn/99ba2tt///vdpaWkVFRVKpfKNN95IS0vbuXNnIBBYunQpi8VC3UnC4ZQ+AJEOgj0AAIQ17IDANVIoFB0dHWw2m8ViXftcQNieEcA2/2NsNpterzebzSaTCbs6nU4s52NpP2RHAI/Hi4L1f5/Ppx5Go9Go1WoajaZQKHg8Hpb2UeCXSCRh+/cLbl5LS8uvfvUrs9m8du3aBx54gOhyxkp/f39dXV1/f//hw4d9Ph8W5hUKBdGljRWTyRSS21UqFZvNbmxsxHp2YAd50HWsW8D29vbq9fqSkhISifT+++9rtdrf/e53FArlzjvv1Ol0p06dYjAYL730EoPBWL9+PZvNrqmpYTKZOTk50KYOgHEAwR4AAKKNw+Gw2Wx2u/0a5wKcTieFQrnaRMCI91ksVmxsLNGf6P/x+Xz4nI+mAEJeovV/fPjHFv8R/NRApOx6wLNYLCjhoys20Gg0QqEwJOqjJADd+wjh9wbtVr/b4R+tH8Hef//97u7uP/7xj6MTn8gkeiwljkOlMwh+UEhHRwdamW9oaGAwGMXFxeXl5Xl5eUlJScQWNoqCwaBardZqtYODg1gbDvT/NzY2dnh6l8lkY/QceJ/Pp9VqxWIxnU7fv3+/Uql85JFHGAzGU089NTg4uHfvXiqVumLFCj6fv3XrVhKJ9MknnwiFwiVLlpDJZJPJNKHapgAQniDYAwAAILlcrqvF/uETBCwWq6urKxAIDA//aBDyksPhYHeI/TT9fn/IUj82BYDdQQMOhxOyBQCf/7GXkdKlTK/Xh0R9tVrN4/FqamokV2DJH4Ef00eXZcjXecHW0WgfUrr9/iCdSeWIYp1WL9F1jYBKoXg9fo/LFwyQElLjpCn0rKlsSco4TeRdvHixra3t9OnT9fX1Uql06tSpxcXFU6dOjfTuEmj5PWSXjVqt1ul0Uqk0Ly+PTqdj0R0NRnd3usfj8fv9TCazo6Ojubl58uTJWVlZn3/++YkTJyoqKvLz8x999FGDwfDhhx8mJCS89957MTExq1atiomJaW5uFggEiYmJo1gMAGAsQLAHAABwI7xe7/DMj+5g99EAf5ogLi5uePLH4/P5sbGx+AkCQrYGWCwWfM7HxiF3qFRqaWmpXq8fcdkfG7BYrPH/FK6Fz+fT4KC8gbhcLizwZ2RksFishIQEdCcKTjSMJ1W3q/o7o27AzRbFcSUsBodOpRG8En6NgoGgx+mzaOy2IQebR508nZNXfh1/9c8888x77733k7/M6/XWX9HQ0JCTkzN79uz09PTi4mLCpwKvF9YOE3G5XK2treh/FpPJHN4XQyqVJiQkjMqHDgQCFApFpVJ1dnYqFAq5XL5v376zZ8/ee++9JSUlmzZtOnjw4Ouvvz579uydO3e2t7evWLEiJyenoaEhEAhMnjwZjrgDEAUg2AMAABg/IyZ//IDNZnd0dOB/GdoawGKx8GkfXdGDjlhX4GcKxqeFmNPp/JFlf+zq8XjwOT8k/wuFQjSjEVZHAFwuF5b2rVZrd3e3VqtFd/x+v0QiwXI+NhjnJtvhz2nzH/xYYzX6JVkiJi+Mjq7cAJ8noLk85HW459wXn5r7E20adTrdb37zm6ampqqqqhF/gdlsRjG+vr6+ra1tKk5ENP/T6/Wo/3zIIjz2AEskNTUVPelzVNrXGY3GgYGB+Ph4qVRaVVX1/fffl5eXz549+5NPPtm+fXtFRcXy5cu3bt166dKl1atX5+XlnT592uFwTJs2jc/nu1wuiO4ARD0I9gAAAMKaz+cbvh0Ay/w6nQ69xO6jAdY1AIv6KSkpLpcrZHYgZEZgjEJFSAuAkGV/DofT3NyMHQHg/RA2F8DlcrExsQ3wHQ4HFvLxA7PZbLVasbSPViOxAZfLJbDm8dff7vjPV0PCVD4nPnqeVuC2e81KS3Im7ZY7r9qdoampacuWLa2trcFg8Pz589h9tVrd0NCAWtkPDQ2hGF9UVJSfnz9e5V8f1LRieMcKjUbD5/MTExPRv238IvwNN61wuVwqlYpOpyclJV24cOHMmTNlZWWlpaUff/zx3r17n3rqqYULF77zzjv19fVPPfVUeXn5mTNnlErltGnTUlNTTSYTlUqFfTQAAAj2AAAAopDb7Q6J+l6v12AwhNwMGaDpAC6Xy2QyscMCw3cKYPc5HE5cXNwo9py3WCz4UwD4xX+LxYKNvV4vFvKzsrLcbjdK/th0AJoF4HK549wFwOl0Dg/8aOD1elHmz8zMZDKZaJ0fJf/oO8/fcs567og5ZaqM6ELGhLbDEMf0L3lCOvxNhw4d+uijj7q7u9HLhISEJ554Am2zDwaD2LJ8enr6uFc9MrQzBUvsaECj0Wpra2NiYrAN8yF9KK5rBjAYDOr1eiqVKhQKm5ub6+vrp0yZMmXKlN27d//rX/9avnz5fffd9/nnn+/du3flypX33HPPiRMnLl++PGfOnIyMjIGBARKJJJVKI2IjAwCAWBDsAQAAgP9C0wEjnhcImQhAYzqd3t/fT6fTWTgj7gjg8XixsbH4mYKb+Und6/XiH/Wn1+tNJhNK/gg2plKpIQv++PyPnwgY60fiYZkf7SjWarUo82u1WqfTieV8iUSSmprK5XLROBL79l86Z6v73irPH52z0+FJ120WioM/WyHC39y2bdu+ffuUSiV2h0wmL1u2DIV5mYywaQ7UeR7L7W63Gzv6jnpJ4KM7alyXkJDAZDKv5Z3bbLZgMMjhcDo6OhoaGtLS0kpKSiorKz/88MPp06evXr36o48+2rVr19q1axcvXnzgwIHLly8vXLgwJyenp6fH7XYnJycTuwEHABA1INgDAAAANwU9U8COgyV/DIPB6O3txU8NoO4AIXsBsN6B+DkC/Ph6pwNQFwD8gj8+/zscjqGhIXQzLi5uxMwfsgVgLHbUu91uLORrtVqXy9Xe3o7uWK1W/GF+/Dg826T3tjhO7jUmF42wmh1lhr3Sqq0AAAzgSURBVHrN4oTA7ff8929h48aN9fX1ZrMZ/2tCduOPeUlDQ/gGkNgWetR5HkvvaWlpXC4Xxfgf3y3i8/nsdjuPxzMYDJWVlSwWa/bs2bW1tZ9++umsWbPuvffeDz74YOfOnRs2bFi6dOn+/fubmprmzZtXWlo6MDCg0+kUCsUYPZoOAACGg2APAAAAEMDlcg3fC+BwOCwWS8gcAX5Ao9Hy8/O1Wm3IoQD87MCN7Q6w2WzmYbBzAdh0QEZGRk9Pz7VMAYzKOiS+bz+2yI/GRqMR370PNRVDx56JyvwOS2Dnn/vTp8sJ+ejjT9M+VHgLM2cah0QiPfnkk0qlEv0DRj9bksnkQCBQV1c3uh/UarXiQzt+Iz2Xyw1Ze8f+hYz4rux2O4vFslqt1dXVsbGxM2fO7Orq+uCDD5KTk9etW1dVVbV+/fqFCxe+8sorFy5c2L17d1lZ2V133dXX19ff35+dnR0fH+/3+8d6qwsAAFwjCPYAAABAxHC5XA6HY/ihAPwUQExMzMDAAH7LAOodgN8CgE0KxMXFhWwN4HA4aHC18/khLQCuNgWAGgGETAGEnAi4mUYAfr8ff4xfp9Op1Wo0HhoaCunbj9/qf5N/BUuWLHnwwQcfeuih4W/6+p1BpojHFl3TFu7ocPFw9zN/ycRednd3Nzc3V1dXV1dXG43GQCAgEokOHz58ve8W/1CGkOV3KpWKD+3YRvqQg+gej4dOpzudTrRlYMaMGYODgx988IFYLF6/fv2FCxeeeOKJWbNmvfnmmy0tLR9//HFpael9992nVqsvXbqkUCjS09N9Ph+cbAcARBAI9gAAAECUC+kdgN8p4HA4hr8JjYPB4Ig7Alg/FNJiEHuqFmoEMDz/Dz8RQKVSf3IKAKFQrukJ8IFAAFvbR5kfy/9arRZb20fr/PgpgGt5/6WlpUwmMz8/v6KiIicnB7vf3+48vtuQMjX6N+Hj6XvMCdLArOX/t0Wiqanpz3/+c0tLi9frpVKpNTU1V/u9gUAgJLRjL9HRd3xox67YThCv19vU1OTxeMrLy/V6/bZt21gs1rp16zo6Oh5//PHc3NytW7d2dHS89957RUVFjz32mE6nq62tVSgUubm5Xq+XQqHAYjsAIJpAsAcAAADACLxeLz7w4zM/ftdAyIECn883YoMANpuNdgcMnwugUqkej2fElf+QKQAWi/Ujm//RS4FAwGKxfuTzwu/nx2/v12g0IpEI364fe1Yf1gh9+vTpfr8fnR5PSUlZtGjRk08+id7t7neVbKmQwYkZp7+esNFzbvDBjfLYOAqJRPrb3/62f/9+rVaL3kQmk2tra6929F2v14eEdizMczic1tZWp9NZWlpqtVq3bdtGpVIrKiqUSuWqVasEAsGOHTv6+/tfffVVNMMyNDR0/PhxhUJRWlrq9Xq9Xi90pAMATDQQ7AEAAAAwalC/sZBdAD8+ttlsbrd7xGaBIWMymYw24ft8Po/H43K58Jv/EaPR6PF4hncBwO7g9wJg+wsQvV6PX9vHTwFwOByJRHLp0iX8qj6DwcjMzFy3bl2KJH/fP9Rp05II+BO/Bna76febFzx8/x8L83826u9cc9mQlU8jC3reeOONzs5ONPGB/qYCgQCdTg85+i6RSHw+H4PBmDNnjsPh2L59u8/nq6ioMBqNjz32WGxs7K5duzQazXPPPTdp0qTf/va3ZrN5//79KSkpM2fO9Hg8FotFKBRe494NAACYOCDYAwAAAIBggUBgxMMCPzkvMOKJACaTSaPRULYMBoOBQMDr9Xo8HnQkATV4Q3sBSCQSPudjnf+HHw2wWCwajeYXv/gFercYv98vFos3bfiqrzOQkBGmLdDHNNjbjS6b2rj98BM6nQ7dwf6IAoHAo48+WlFRYbPZVq1aFQgEdu/ebTQan376aYVCsXnzZpvNtmvXrsTExIULF3q9Xo1GIxaLQ2ZbAAAAXAtoCgIAAAAAglEoFA6Hw+Fwrvc3Xu1EwI9MCthsNiaTyWKxZDIZk8mMjY2NiYmh0WhutxttFPf7/WgiwOVyOZ1O9NvpdDqPx8M+bjAYDAaDZDI5NjY2Ly+vs9EuTAvHx++NA5aA0d/oiaWxyGR9yJvIZHJycjLa2vD666+LRCISiSQQCHbu3Il+AZvNXrVqFRrHxMTI5RPlgQIAADDqINgDAAAAIFKh0/vX+7tGbBmIBlj7AJvNhpb9A4FAMBi02Ww+nw+FeSzVk8lkn89XW1s36VZPUuGN9Pa/Fja7cd+hdzp76uwOk0ySdee8NZnpJSQSSaPt/tNfH3jq8fdPVe7s7mukkCmF+XPvXvQs6glXWfOvYyc/ttmNclnOwnlPjVFtCEfE+P9Wv/Sfyq9aW1sHBwex3aBkMvmee+4hkUg0Gi0jI2NMawAAgAkOgj0AAAAAJpa4uLi4uLj4+Pjr+l0ul+uWW25BqZ5CoaD4KhKJ8iYV02hjdeQ7EAhs+2S9y227/57fcdmiszX//Mdn6yv+Z7tMmkml0kgk0jeH/vLzu55/POVPlzvP/f8fP5OWWlRUMLerp/6f+7bMunVleemyIePgvkPvjlF5CJlKSUnM3Lx5s0ajOXbs2HfffadWq/X60AV8AAAAYweCPQAAAADAT2MwGOj0OFqrT0pKmjNnzvz58+O5GQc+0ozRB73cWTOoan3q8ffRKv3SOze0d9acrtp137LfoF9QmHeHImUKiUTKyigTCZIGBluKCuaebzjEYYsWz3+GSqUmxKc6XdYvv/7dGFVIIpEoMVSH1UcikSQSycqVK1euXFlbW3vw4MGGhoax+6AAAADwINgDAAAAAFwTMpkcFxeXnJy8ePHi+fPnozX/gcvOOEHsGH3E3oGLVGpMRloxekmhUNJTiwZV7dgvkEmzsDGDwXG6rCQSSaPrkSflYM9pT5HnjVF5CJ0ZE/D/oBlzaWlpaWnpmH5QAAAAeBDsAQAAAACuSX5+/uOPPz579mz8TSabaje4x+gjut0Ov9/7wh9mYncCAT+HLcJextB+MKcQJAVJJJLbbedy/u/X0GOYY1Qe4rF7aDFj1WIAAADAtYBgDwAAAABwTT755JPhN+M4VI/LN0YfkcFg0Wj0DWs+w98kk3/iSD+dznS5bNhLtIw/dvw+fxyXOqYfAgAAwI+DYA8AAAAAcOMYLGocN2aM3nlKUp7P5/EH/DLJf7vKG4wqNkvw478rXpTS2lEZCAQoFAo6qD9G5SExdDJrzP4EAAAAXIuxauIKAAAAADARkMkkJotiG3KOxTvPTC9Lkk3asfuVju7zBqOyrvG7v7z/8Nma3T/+u6YWLrDZDP8+9LZK03Gh+Xht/cGxqA2j7bYlZTLG9EMAAAD4cbBiDwAAAABwU7Kmsi7VOtii0T/KTqVSn3jk7f3fvvvpzhc9HqeQnzh39qrbb1v5479rUub0uxet//7055Xn/iVPzLlv6Yt/+eAR7PHyo8uidSRPYo3FewYAAHDtyGP0VR4AAAAAYIKwmvy73xlMm5ZEdCEEULcNFd3KzJnGIboQAACY0GArPgAAAADATeHwqSJpjFljJ7qQ8eb3BUwqG6R6AAAgHGzFBwAAAAC4Wbf/XPz1O4M8yVU3pb/02s9GvB8I+ClkColMHvGtLz77L1Ycb7SK/PDzDd29jSO+icXk2Z3m4fcpZMqrvzlytXeo6zTcskR0tbcCAAAYN7AVHwAAAABgFBzbqbPY6YJE9ohvtVj0I973+b1UKo1MGjnYczgi8lUy/w2wO8x+n3fkMnxeGm3kzvZcrnjE+16XX9umeeiF5NEqDwAAwA2DYA8AAAAAMDr+8VJ3aklSDGNCPNS9s3Jg2RqZSEonuhAAAABwxh4AAAAAYJT84sXUruoBoqsYD8qL2tvuFkKqBwCAMAEr9gAAAAAAo8Yy5N3zd01qsYzoQsZQ/wXtLYv4mVNG//F+AAAAbgys2AMAAAAAjBquKObuJyTNR7o9Dh/RtYyJ3vPKgnImpHoAAAgrsGIPAAAAADDKAgHS7ncHA2S6NFtIdC2jxjBgdZvts5YLkzIg1QMAQHiBYA8AAAAAMCaqvzWe+24oMVfETWDRYiO1o14wSLLpnZp2fXJ23JwVYjoD9nsCAEDYgWAPAAAAADCGKg8YLp4102KpbBGLwYmlxVJjYqm0WCopPH8EI5P83oDP7fe6fT5PwKKxWnXOnGn80rk8nnjk5+EBAAAgHAR7AAAAAIAxp+13dzTa1T0uh9XntPmZnBiTxkV0USOgxVDIFBKDRY3j0BJSGIpcZmpuHNFFAQAA+AkQ7AEAAAAAAAAAgAgGp6QAAAAAAAAAAIAIBsEeAAAAAAAAAACIYBDsAQAAAAAAAACACAbBHgAAAAAAAAAAiGAQ7AEAAAAAAAAAgAgGwR4AAAAAAAAAAIhg/w9GjOSBe+WVUwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a742fa",
   "metadata": {},
   "source": [
    "### Q&A Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "41f39982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [], 'question': HumanMessage(content='Make me an question to develop about pooling in CNN?', additional_kwargs={}, response_metadata={})}\n",
      "Entering agent\n",
      "messages = [HumanMessage(content='Make me an question to develop about pooling in CNN?', additional_kwargs={}, response_metadata={}, id='e8fb9ad2-8a7d-4442-bf08-fc236f399471')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering qa_tool\n",
      "retrieve_for_QA: Retrieved 10 documents\n",
      "Entering tool_router\n",
      "state['tool_used'] =  qa_tool\n",
      "Routing to find_relevant_docs\n",
      "Entering find_relevant_docs\n",
      "subjects: Leçon #3 - Deep Learning\n",
      "Leçon #7 - GAN - 2025\n",
      "Leçon #8 - Graph neural network\n",
      "Leçon #2 - Neurone artificiel\n",
      "Leçon #1 - Introduction\n",
      "Leçon #4 - CNN\n",
      "Leçon #5 - RNN - 2025\n",
      "Leçon #6 - Auto-apprentissage\n",
      "Leçon #9 - Transformers and generative AI\n",
      "\n",
      "question_classifier: related_subject = Leçon #4 - CNN\n",
      "Entering exercise_router\n",
      "state['tool_used'] =  qa_tool\n",
      "Routing to generate_qa\n",
      "Entering generate_qa\n",
      "generate_qa: rephrased_question: Make me an question to develop about pooling in CNN?\n",
      "generate_qa: Generated Q&A: {\n",
      "    \"1\": {\n",
      "        \"qa\": \"question to develop\",\n",
      "        \"question\": \"Expliquez en détail le rôle de la couche de pooling dans un réseau de neurones à convolution, en tenant compte de son impact sur l'apprentissage et la représentation des données. Comment contribue-t-elle à la réduction des variations causées par des translations mineures dans l'entrée?\",\n",
      "        \"correct\": \"## Rôle de la couche de pooling dans un CNN\\n\\nLa couche de pooling joue un rôle crucial dans le traitement des données au sein d'un réseau de neurones à convolution. Son objectif principal est de réduire la dimensionnalité des représentations intermédiaires, tout en conservant les caractéristiques les plus significatives. Cela se traduit par plusieurs bénéfices :\\n\\n1. **Réduction des variations** : En appliquant des statistiques sommaires, comme le max pooling, la couche de pooling aide à rendre la représentation moins sensible aux petits changements dans l'entrée. Par exemple, une légère translation d'une image ne doit pas affecter le résultat de l'analyse, ce qui est essentiel pour la robustesse du modèle.\\n\\n2. **Amélioration de la généralisation** : En simplifiant la représentation, la couche de pooling aide à prévenir le surapprentissage en supprimant les détails non pertinents qui pourraient amener le réseau à apprendre le bruit plutôt que les véritables motifs présents dans les données.\\n\\n3. **Efficacité computationnelle** : En diminuant le nombre d'unités à traiter dans les couches suivantes, le pooling permet des économies significatives en termes de temps de calcul et d'utilisation de mémoire, ce qui est essentiel pour traiter de grandes quantités de données.\\n\\nAinsi, la couche de pooling est essentielle non seulement pour maintenir la qualité de l'apprentissage mais aussi pour améliorer l'efficacité des calculs dans les CNN.\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"qa\": \"question to develop\",\n",
      "        \"question\": \"Décrivez les différences entre le max pooling et l'average pooling dans le contexte des réseaux de neurones à convolution. Discutez de l'impact de ces techniques sur les performances du réseau et sur la nature des caractéristiques extraites.\",\n",
      "        \"correct\": \"## Différences entre max pooling et average pooling dans un CNN\\n\\nLe max pooling et l'average pooling sont deux techniques fondamentales utilisées dans les réseaux de neurones à convolution pour réduire la dimensionnalité des données, mais ils fonctionnent de manière distincte et ont des effets différents sur l'apprentissage :\\n\\n1. **Max pooling** : Cette technique consiste à sélectionner la valeur maximale d'une fenêtre glissante sur l'entrée. Elle est particulièrement efficace pour conserver les caractéristiques les plus significatives au sein d'une région, ce qui peut aider à détecter des caractéristiques saillantes, comme des bords ou des textures. En raison de cette sélection, le max pooling tend à conserver les détails importants et à ignorer les variations inférieures à un certain seuil. \\n\\n2. **Average pooling** : Contrairement à la méthode du max pooling, l'average pooling calcule la moyenne des valeurs dans la fenêtre glissante. Bien qu'elle puisse réduire les informations perturbatrices, elle risque d'indiscriminer les détails importants, diluant ainsi les caractéristiques de l'entrée. Ce type de pooling peut parfois atténuer les effets de bruit, mais il peut également mener à la perte d'informations critiques. \\n\\nEn termes de performances, le max pooling est souvent préféré dans les architectures actuelles, car il a tendance à produire des représentations plus compactes et discriminantes. Toutefois, l'average pooling peut être utilisé dans des contextes où une réduction plus douce de la dimensionnalité est souhaitable, ou en complément d'autres techniques pour améliorer le comportement global du réseau.\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"qa\": \"question to develop\",\n",
      "        \"question\": \"Discutez du concept de 'downsampling' et de son rapport avec la technique de pooling. Comment le pooling contribue-t-il à la structuration des données pour les couches suivantes dans un réseau de neurones à convolution?\",\n",
      "        \"correct\": \"## Concept de downsampling et son rapport avec le pooling\\n\\nLe downsampling fait référence à toute technique utilisée pour réduire la résolution d'un ensemble de données, ce qui est exactement le but des couches de pooling dans un réseau de neurones à convolution. Le pooling, en réduisant la taille des représentations intermédiaires, facilite le downsampling de plusieurs manières importantes :\\n\\n1. **Réduction de la dimensionnalité** : En appliquant le pooling, particulièrement avec des méthodes comme le max pooling, le réseau peut transformer une carte de caractéristiques large en une version plus petite mais riche en informations cruciales. Ce processus prépare l'ensemble de données pour les couches suivantes en réduisant le volume d'informations sans perdre l'essentiel des caractéristiques pertinentes.\\n\\n2. **Invariance locale** : En compressant l'information, le pooling aide à rendre les données moins sensibles aux variations minimes (translations, rotations) dans l'entrée. Par conséquent, les couches suivantes peuvent apprendre des représentations plus robustes et invariantes, essentielles pour des tâches comme la classification.\\n\\n3. **Efficacité de calcul** : En diminuant le nombre d'unités de traitement, le pooling permet d'utiliser moins de ressources au fil des couches, rendant l'architecture plus efficace en termes de temps de calcul et de mémoire. Ce downsampling contrôlé est fondamental pour l'évolutivité des modèles lorsqu'ils sont appliqués à de vastes ensembles de données ou à des tâches complexes comme la segmentation d'images ou la détection d'objets.\\n\\nAinsi, le pooling joue un rôle central dans le downsampling et la structuration des données au sein d'un CNN, assurant que les représentations extraites soient pertinentes, compactes et prêtes pour l'apprentissage approfondi.\"\n",
      "    }\n",
      "}\n",
      "generate_qa: Generated review: ### Analysis of the Quiz on CNNs (Convolutional Neural Networks)\n",
      "\n",
      "The quiz presented consists of three detailed questions that probe into the workings of pooling layers in convolutional neural networks (CNNs). Each question requires a thorough understanding of key concepts in deep learning, specifically related to the processing and representation of data through pooling techniques. Below is an evaluation of the complexity of the questions along with an analysis of their effectiveness in assessing comprehension.\n",
      "\n",
      "#### Question Complexity\n",
      "\n",
      "1. **Depth of Knowledge Required**: \n",
      "   - Each question necessitates a good grasp of both theoretical and practical aspects of CNNs. Understanding pooling, including max pooling and average pooling, involves knowledge of how these methods affect the learning process, data representation, and model efficiency.\n",
      "   \n",
      "2. **Analytical Thinking**: \n",
      "   - The questions demand not just recall of facts but also analytical skills. Students are asked to compare techniques, evaluate their impacts, and explain their relevance in the context of modern neural network design.\n",
      "   \n",
      "3. **Technical Language**: \n",
      "   - The vocabulary used (e.g., \"invariance locale,\" \"réduction de la dimensionnalité\") is technical, indicating that students should be comfortable with the specific terminology of deep learning, which adds to the complexity.\n",
      "\n",
      "4. **Length and Detail**: \n",
      "   - The required responses are expansive, directing students to construct detailed explanations rather than short, concise answers. This demands considerable writing skills and the ability to articulate complex concepts clearly.\n",
      "\n",
      "#### Effectiveness of the Quiz\n",
      "\n",
      "1. **Thorough Assessment**: \n",
      "   - The quiz successfully evaluates students' understanding of key concepts associated with pooling layers in CNNs. By addressing both definitions and their implications, the questions encourage integrated thinking about theoretical and applied aspects of machine learning.\n",
      "\n",
      "2. **Encouragement of Critical Thought**: \n",
      "   - The questions challenge students to not only describe what pooling is but also to consider its impact on the overall performance of neural networks. This critical thinking approach is valuable in the study of advanced machine learning.\n",
      "\n",
      "3. **Contextual Relevance**: \n",
      "   - The incorporation of current practices such as max vs. average pooling situates the quiz within a contemporary framework, making it relevant and applicable to real-world scenarios in deep learning.\n",
      "\n",
      "4. **Clarity and Structure**: \n",
      "   - Each correct response is emphatically structured, fostering clarity in understanding how the questions should be approached. This structure can guide students in how to format their own responses.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "In summary, the quiz is well-crafted to test students’ comprehensive understanding of pooling layers in CNNs. The complexity of the questions encourages deeper engagement with the material and promotes a stronger command of technical language related to machine learning. Overall, it successfully balances theoretical knowledge with practical understanding, making it an effective assessment tool for students at this level.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages_': [HumanMessage(content='Make me an question to develop about pooling in CNN?', additional_kwargs={}, response_metadata={}, id='e8fb9ad2-8a7d-4442-bf08-fc236f399471'),\n",
       "  AIMessage(content='{\\n    \"1\": {\\n        \"qa\": \"question to develop\",\\n        \"question\": \"Expliquez en détail le rôle de la couche de pooling dans un réseau de neurones à convolution, en tenant compte de son impact sur l\\'apprentissage et la représentation des données. Comment contribue-t-elle à la réduction des variations causées par des translations mineures dans l\\'entrée?\",\\n        \"correct\": \"## Rôle de la couche de pooling dans un CNN\\\\n\\\\nLa couche de pooling joue un rôle crucial dans le traitement des données au sein d\\'un réseau de neurones à convolution. Son objectif principal est de réduire la dimensionnalité des représentations intermédiaires, tout en conservant les caractéristiques les plus significatives. Cela se traduit par plusieurs bénéfices :\\\\n\\\\n1. **Réduction des variations** : En appliquant des statistiques sommaires, comme le max pooling, la couche de pooling aide à rendre la représentation moins sensible aux petits changements dans l\\'entrée. Par exemple, une légère translation d\\'une image ne doit pas affecter le résultat de l\\'analyse, ce qui est essentiel pour la robustesse du modèle.\\\\n\\\\n2. **Amélioration de la généralisation** : En simplifiant la représentation, la couche de pooling aide à prévenir le surapprentissage en supprimant les détails non pertinents qui pourraient amener le réseau à apprendre le bruit plutôt que les véritables motifs présents dans les données.\\\\n\\\\n3. **Efficacité computationnelle** : En diminuant le nombre d\\'unités à traiter dans les couches suivantes, le pooling permet des économies significatives en termes de temps de calcul et d\\'utilisation de mémoire, ce qui est essentiel pour traiter de grandes quantités de données.\\\\n\\\\nAinsi, la couche de pooling est essentielle non seulement pour maintenir la qualité de l\\'apprentissage mais aussi pour améliorer l\\'efficacité des calculs dans les CNN.\"\\n    },\\n    \"2\": {\\n        \"qa\": \"question to develop\",\\n        \"question\": \"Décrivez les différences entre le max pooling et l\\'average pooling dans le contexte des réseaux de neurones à convolution. Discutez de l\\'impact de ces techniques sur les performances du réseau et sur la nature des caractéristiques extraites.\",\\n        \"correct\": \"## Différences entre max pooling et average pooling dans un CNN\\\\n\\\\nLe max pooling et l\\'average pooling sont deux techniques fondamentales utilisées dans les réseaux de neurones à convolution pour réduire la dimensionnalité des données, mais ils fonctionnent de manière distincte et ont des effets différents sur l\\'apprentissage :\\\\n\\\\n1. **Max pooling** : Cette technique consiste à sélectionner la valeur maximale d\\'une fenêtre glissante sur l\\'entrée. Elle est particulièrement efficace pour conserver les caractéristiques les plus significatives au sein d\\'une région, ce qui peut aider à détecter des caractéristiques saillantes, comme des bords ou des textures. En raison de cette sélection, le max pooling tend à conserver les détails importants et à ignorer les variations inférieures à un certain seuil. \\\\n\\\\n2. **Average pooling** : Contrairement à la méthode du max pooling, l\\'average pooling calcule la moyenne des valeurs dans la fenêtre glissante. Bien qu\\'elle puisse réduire les informations perturbatrices, elle risque d\\'indiscriminer les détails importants, diluant ainsi les caractéristiques de l\\'entrée. Ce type de pooling peut parfois atténuer les effets de bruit, mais il peut également mener à la perte d\\'informations critiques. \\\\n\\\\nEn termes de performances, le max pooling est souvent préféré dans les architectures actuelles, car il a tendance à produire des représentations plus compactes et discriminantes. Toutefois, l\\'average pooling peut être utilisé dans des contextes où une réduction plus douce de la dimensionnalité est souhaitable, ou en complément d\\'autres techniques pour améliorer le comportement global du réseau.\"\\n    },\\n    \"3\": {\\n        \"qa\": \"question to develop\",\\n        \"question\": \"Discutez du concept de \\'downsampling\\' et de son rapport avec la technique de pooling. Comment le pooling contribue-t-il à la structuration des données pour les couches suivantes dans un réseau de neurones à convolution?\",\\n        \"correct\": \"## Concept de downsampling et son rapport avec le pooling\\\\n\\\\nLe downsampling fait référence à toute technique utilisée pour réduire la résolution d\\'un ensemble de données, ce qui est exactement le but des couches de pooling dans un réseau de neurones à convolution. Le pooling, en réduisant la taille des représentations intermédiaires, facilite le downsampling de plusieurs manières importantes :\\\\n\\\\n1. **Réduction de la dimensionnalité** : En appliquant le pooling, particulièrement avec des méthodes comme le max pooling, le réseau peut transformer une carte de caractéristiques large en une version plus petite mais riche en informations cruciales. Ce processus prépare l\\'ensemble de données pour les couches suivantes en réduisant le volume d\\'informations sans perdre l\\'essentiel des caractéristiques pertinentes.\\\\n\\\\n2. **Invariance locale** : En compressant l\\'information, le pooling aide à rendre les données moins sensibles aux variations minimes (translations, rotations) dans l\\'entrée. Par conséquent, les couches suivantes peuvent apprendre des représentations plus robustes et invariantes, essentielles pour des tâches comme la classification.\\\\n\\\\n3. **Efficacité de calcul** : En diminuant le nombre d\\'unités de traitement, le pooling permet d\\'utiliser moins de ressources au fil des couches, rendant l\\'architecture plus efficace en termes de temps de calcul et de mémoire. Ce downsampling contrôlé est fondamental pour l\\'évolutivité des modèles lorsqu\\'ils sont appliqués à de vastes ensembles de données ou à des tâches complexes comme la segmentation d\\'images ou la détection d\\'objets.\\\\n\\\\nAinsi, le pooling joue un rôle central dans le downsampling et la structuration des données au sein d\\'un CNN, assurant que les représentations extraites soient pertinentes, compactes et prêtes pour l\\'apprentissage approfondi.\"\\n    }\\n}', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='### Analysis of the Quiz on CNNs (Convolutional Neural Networks)\\n\\nThe quiz presented consists of three detailed questions that probe into the workings of pooling layers in convolutional neural networks (CNNs). Each question requires a thorough understanding of key concepts in deep learning, specifically related to the processing and representation of data through pooling techniques. Below is an evaluation of the complexity of the questions along with an analysis of their effectiveness in assessing comprehension.\\n\\n#### Question Complexity\\n\\n1. **Depth of Knowledge Required**: \\n   - Each question necessitates a good grasp of both theoretical and practical aspects of CNNs. Understanding pooling, including max pooling and average pooling, involves knowledge of how these methods affect the learning process, data representation, and model efficiency.\\n   \\n2. **Analytical Thinking**: \\n   - The questions demand not just recall of facts but also analytical skills. Students are asked to compare techniques, evaluate their impacts, and explain their relevance in the context of modern neural network design.\\n   \\n3. **Technical Language**: \\n   - The vocabulary used (e.g., \"invariance locale,\" \"réduction de la dimensionnalité\") is technical, indicating that students should be comfortable with the specific terminology of deep learning, which adds to the complexity.\\n\\n4. **Length and Detail**: \\n   - The required responses are expansive, directing students to construct detailed explanations rather than short, concise answers. This demands considerable writing skills and the ability to articulate complex concepts clearly.\\n\\n#### Effectiveness of the Quiz\\n\\n1. **Thorough Assessment**: \\n   - The quiz successfully evaluates students\\' understanding of key concepts associated with pooling layers in CNNs. By addressing both definitions and their implications, the questions encourage integrated thinking about theoretical and applied aspects of machine learning.\\n\\n2. **Encouragement of Critical Thought**: \\n   - The questions challenge students to not only describe what pooling is but also to consider its impact on the overall performance of neural networks. This critical thinking approach is valuable in the study of advanced machine learning.\\n\\n3. **Contextual Relevance**: \\n   - The incorporation of current practices such as max vs. average pooling situates the quiz within a contemporary framework, making it relevant and applicable to real-world scenarios in deep learning.\\n\\n4. **Clarity and Structure**: \\n   - Each correct response is emphatically structured, fostering clarity in understanding how the questions should be approached. This structure can guide students in how to format their own responses.\\n\\n### Conclusion\\n\\nIn summary, the quiz is well-crafted to test students’ comprehensive understanding of pooling layers in CNNs. The complexity of the questions encourages deeper engagement with the material and promotes a stronger command of technical language related to machine learning. Overall, it successfully balances theoretical knowledge with practical understanding, making it an effective assessment tool for students at this level.', additional_kwargs={}, response_metadata={})],\n",
       " 'messages': [HumanMessage(content='Make me an question to develop about pooling in CNN?', additional_kwargs={}, response_metadata={}, id='e8fb9ad2-8a7d-4442-bf08-fc236f399471'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TnTuLSbS4Ol6BGnltwlLy6bv', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Make me a question to develop about pooling in CNN?\",\"type\":\"human\"}],\"messages\":[],\"documents\":[],\"related_subject\":\"Convolutional Neural Networks (CNNs)\",\"related_subject_content\":\"Pooling is a downsampling operation that reduces the spatial dimensions of feature maps in Convolutional Neural Networks (CNNs), which helps to reduce the number of parameters and computation in the network, while also controlling overfitting.\",\"language\":\"en\",\"topic\":\"Deep Learning\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"qa_tool\",\"rephrased_question\":\"Can you create a development question about pooling layers in Convolutional Neural Networks?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"Discuss the significance of pooling layers in Convolutional Neural Networks (CNNs) and how they contribute to feature extraction and computational efficiency. Include different types of pooling techniques and their impact on model performance.\",\"type\":\"human\"}}}', 'name': 'qa_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 2312, 'total_tokens': 2521, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2304}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLbVYAYTbkoTR6V8Qe2nmN2mc9tf9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c75d7d7d-4594-4a45-bb07-ff96cb24b0ee-0', tool_calls=[{'name': 'qa_tool', 'args': {'state': {'messages_': [{'content': 'Make me a question to develop about pooling in CNN?', 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': 'Convolutional Neural Networks (CNNs)', 'related_subject_content': 'Pooling is a downsampling operation that reduces the spatial dimensions of feature maps in Convolutional Neural Networks (CNNs), which helps to reduce the number of parameters and computation in the network, while also controlling overfitting.', 'language': 'en', 'topic': 'Deep Learning', 'path_txt': '', 'subject': [], 'tool_used': 'qa_tool', 'rephrased_question': 'Can you create a development question about pooling layers in Convolutional Neural Networks?', 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': 'Discuss the significance of pooling layers in Convolutional Neural Networks (CNNs) and how they contribute to feature extraction and computational efficiency. Include different types of pooling techniques and their impact on model performance.', 'type': 'human'}}}, 'id': 'call_TnTuLSbS4Ol6BGnltwlLy6bv', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2312, 'output_tokens': 209, 'total_tokens': 2521, 'input_token_details': {'audio': 0, 'cache_read': 2304}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\\'messages_\\': [BaseMessage(content=\\'Make me a question to develop about pooling in CNN?\\', additional_kwargs={}, response_metadata={}, type=\\'human\\')], \\'messages\\': [], \\'documents\\': [Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\\'Strides>1 plutôt que pooling Juste des couches de convolution, pas de denses! Sauf au début pour la source\\'), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"Par exemple, une couche d\\'un CNN peut être formulé comme: h_v^(l+1) = φ(∑_(u∈N(v)∪v) W_l^u h_u^(l)) où N(v) représente les 8 pixels voisin de v pour une convolution 3 × 3\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"## DEEP CONVOLUTIONAL GAN (DCGAN) [*Diagramme montrant l\\'architecture DCGAN avec générateur et discriminateur utilisant des couches de convolution*]\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\\'On peut ajouter une couche cachée de neurones pour former un réseau de neurones multicouche à propagation avant (multi layer feed forward NN)\\'), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\\'## CONVOLUTIONS Un CNN peut être considéré comme un cas spécifique de GNN\\'), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\\'DiffPool: clustering hiérarchique + avg des nodes embeddings\\'), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"## DISCRIMINATEUR Très similaire à nos CNN standard. L\\'entrée est 28 x 28 x 1 (nos images MNIST). 4 couches de convolution avec stride=2 sauf le dernier: - On downsample les filtres - Encore de taille 5.\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"## PROGRESSIVE GROWING GAN 2017 On augmente progressivement la profondeur du modèle durant l\\'entraînement. On garde le générateur et le discriminateur progressif!! ! Toutes les couches sont entraînables durant tout le processus.\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"Si + d\\'un niveau caché, alors besoin des techniques du deep learning\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"Il s\\'agit d\\'un ensemble d\\'algorithmes développés pour l\\'entraînement de réseau de neurones artificiels à plusieurs couches\")], \\'related_subject\\': \\'Convolutional Neural Networks (CNNs)\\', \\'related_subject_content\\': \\'Pooling is a downsampling operation that reduces the spatial dimensions of feature maps in Convolutional Neural Networks (CNNs), which helps to reduce the number of parameters and computation in the network, while also controlling overfitting.\\', \\'language\\': \\'en\\', \\'topic\\': \\'Deep Learning\\', \\'path_txt\\': \\'\\', \\'subject\\': [], \\'tool_used\\': \\'retrieve_for_QA\\', \\'rephrased_question\\': \\'Can you create a development question about pooling layers in Convolutional Neural Networks?\\', \\'proceed_to_generate\\': True, \\'rephrase_count\\': 0, \\'question\\': HumanMessage(content=\\'Discuss the significance of pooling layers in Convolutional Neural Networks (CNNs) and how they contribute to feature extraction and computational efficiency. Include different types of pooling techniques and their impact on model performance.\\', additional_kwargs={}, response_metadata={})}', name='qa_tool', id='f0b8a549-654c-4fed-a30e-04a2ebfb2d78', tool_call_id='call_TnTuLSbS4Ol6BGnltwlLy6bv')],\n",
       " 'documents': [],\n",
       " 'related_subject': 'Leçon #4 - CNN',\n",
       " 'related_subject_content': '# RÉSEAU DE NEURONES À CONVOLUTIONS\\n\\n## Par Kévin Bouchard Ph.D.\\nProfesseur titulaire en intelligence artificielle et apprentissage automatique\\nLaboratoire d\\'Intelligence Ambiante pour la reconnaissance d\\'activités (LIARA)\\nDirecteur de l\\'Espace innovation en technologies numériques Hydro-Québec\\nPrésident du Regroupement québécois des maladies orphelines (RQMO)\\nUniversité du Québec à Chicoutimi\\nwww.Kevin-Bouchard.ca            Kevin_Bouchard@uqac.ca\\n\\n## CONTENU DE LA LEÇON #4\\n\\n### Vous apprendrez:\\n- L\\'intérêt d\\'inventer des opérations particulières dans les réseaux de neurones\\n- Comment on entraîne un réseau profond sans boucle\\n- L\\'implémentation concrète et celles assistée par les librairies TF et PyTorch\\n\\n### Contenu spécifique:\\n- Origine des réseaux convolutifs\\n- Opération de convolution\\n- Éléments avec un rôle spécifique\\n- Fonctions d\\'activation\\n- Inversion des couches\\n\\n## IMAGENET ET LE RETOUR DES NN\\n\\n*Le graphique montre l\\'évolution des architectures de réseaux de neurones pour le Large Scale Visual Recognition Challenge (ILSVRC), indiquant une progression du taux d\\'erreur de classification qui a diminué au fil des années, de 28.2% en 2010 à 3.57% en 2015 avec ResNet. On observe également que le nombre de couches des réseaux a augmenté significativement, passant de modèles \"shallow\" à des architectures profondes comme ResNet avec 152 couches.*\\n\\n*Référence: Kaiming He, Xiangyu Zhang, Shaoqing Ren, & Jian Sun. \"Deep Residual Learning for Image Recognition\". CVPR 2016.\\n\\n## IMAGENET\\n\\n- ImageNet contient aujourd\\'hui 14 millions d\\'images annotées couvrant plus de 20000 catégories\\n  - Le plus couramment utilisé est le concours ILSVRC 2012 avec 1.3 millions d\\'images en 1000 classes\\n  - Mais il y a eu d\\'autres concours tels que la détection d\\'objets, les voitures, le mutiétiquette, etc.\\n\\n*L\\'image montre une grille d\\'images diverses à gauche et une image avec détection d\\'objets à droite, où plusieurs objets sont identifiés et encadrés avec des étiquettes comme \"person\", \"dog\", \"chair\".*\\n\\n## DE IMAGENET VERS LES SUIVANTS\\n\\n*L\\'image présente différentes bases de données qui ont suivi ImageNet dans différents domaines:*\\n\\n- SpaceNet (DigitalGlobe, CosmiQ Works, NVIDIA)\\n- MusicNet (J. Thickstun et al, 2017)\\n- Medical ImageNet (Stanford Radiology, 2017)\\n- ShapeNet (A.Chang et al, 2015)\\n- EventNet (G. Ye et al, 2015)\\n- ActivityNet (F. Heilbron et al, 2015)\\n\\n## RÉSEAU DE NEURONES À CONVOLUTIONS\\n\\n- Convolutional Neural Network (CNN)\\n- Un type particulier de réseau de neurones qui utilise les convolutions comme opérations plutôt que des opérations de multiplications matricielles\\n  - Pas nécessairement à chaque niveau!\\n  - Très utile pour les données qui ont une topologie sous forme de grille (sons, images, séries temporelles)\\n\\n- Nous commencerons par une brève introduction sur l\\'opération de convolution\\n\\n## ARCHITECTURE\\n\\n- Un CNN est en fait une architecture de réseau profond basé sur quelques types de blocs cruciaux\\n- Cet assemblage peut être compliqué\\n- Malgré tout, individuellement, chaque bloc est relativement simple\\n\\n*L\\'image illustre l\\'architecture d\\'un CNN simple avec différentes couches: entrée (32x32), convolution 5x5, subsampling 2x2, convolution, subsampling et couche entièrement connectée pour la classification.*\\n\\n## PRODUIT SCALAIRE DE MATRICES\\n\\nC = AB\\n\\nC_{i,j} = ∑_k A_{i,k}B_{k,j}\\n\\n*L\\'image montre une représentation visuelle du produit matriciel avec des matrices de dimensions m×p et n×p produisant une matrice m×p, avec indication que les dimensions internes (n) doivent être identiques.*\\n\\n## OPÉRATIONS DE BASE DU CNN\\n\\n- Convolution\\n  - Similaire à une multiplication de matrices\\n  - Prend une entrée, produit une sortie (couche cachée)\\n\\n- Deconvolution\\n  - Similaire à une multiplication par la transposée d\\'une matrice\\n  - Utilisée pour la propagation arrière de l\\'erreur des sorties vers les entrées\\n\\n- Calcul des gradients de poids\\n  - Pour la propagation arrière de l\\'erreur des sorties vers les poids\\n  - Prend en compte le partage de paramètres\\n\\n## CONVOLUTION\\n\\n- Dans le cadre des CNN, les éléments d\\'une convolution sont souvent appelés\\n  - L\\'entrée (input), la fonction sur laquelle on applique le filtre\\n  - Le noyau (kernel) et le filtre de convolution\\n  - La sortie est parfois appelée « feature map »\\n\\n- Tensors(tenseurs): Ces éléments servant à la convolution sont des tableaux multidimensionnels en ML que l\\'on nomme tenseurs\\n  - torch.tensor(list ou np.array, dtype=torch.int32) - il existe de nombreux types!\\n\\n*L\\'image montre un exemple de code PyTorch pour la création de tenseurs avec torch.zeros et torch.ones*\\n\\n## CONVOLUTION\\n\\n*L\\'image montre une illustration d\\'une opération de convolution où un kernel 3×3 est appliqué à une image 5×5 pour produire une feature map. L\\'exemple calcule la valeur 4 comme résultat de la somme pondérée.*\\n\\n- La convolution dans PyTorch:\\n  https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\\n\\n- Et dans TensorFlow:\\n  https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\\n\\n- Attention! Pour une Conv2D, l\\'ordre est différent entre PyTorch et TF\\n\\n```python\\nconv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)\\noutput = conv(input_tensor)\\n\\nconv = Conv2D(filters=16, kernel_size=(3, 3), strides=(2, 2), padding=\\'same\\')\\noutput = conv(input_tensor)\\n```\\n\\n## CONVOLUTION\\n\\n- Même si mathématiquement leurs définitions diffèrent, en pratique en ML, nous appelons convolution/cross-correlation → convolution\\n\\n*L\\'image montre une représentation de grilles 3×3 avec des indices montrant la différence entre convolution (lecture de droite à gauche) et cross-correlation (lecture de gauche à droite)*\\n\\n- Dans le cadre du ML, les noyaux sont ce que nous souhaitons apprendre\\n  - Les convolutions sont généralement très petites (beaucoup plus petites que nos entrées)\\n  - Elles fonctionnent conjointement avec d\\'autres opérations\\n\\n## EXEMPLE\\n\\n- Une opération de « flou »\\n\\nH = 1/25 [1 1 1 1 1\\n          1 1 1 1 1\\n          1 1 1 1 1\\n          1 1 1 1 1\\n          1 1 1 1 1]\\n\\n*L\\'image montre une photographie originale nette à gauche et la même image floutée à droite après application du filtre de convolution H.*\\n\\n## CONVOLUTION\\n\\n*L\\'image illustre une opération de convolution détaillée avec une matrice d\\'entrée 4×4 (avec des lettres a,b,c,d,e,f,g,h,i,j,k,l), un kernel 2×2 (avec w,x,y,z) et le calcul des valeurs de sortie.*\\n\\nAutre exemple de convolution\\n\\nProblèmes?\\n\\nTenseur 2D en entrée → Tenseur 2D en sortie?\\n\\n## CONVOLUTION\\n\\n*L\\'image montre une visualisation de l\\'opération de convolution avec un filtre de Sobel appliqué à une image, montrant le calcul détaillé d\\'un pixel de sortie.*\\n\\n- En général on utilise des noyaux impairs\\n  - En ML, moins dommageable\\n  - On peut même sauter certains pixels avec le « Stride »\\n\\n- L\\'avantage des convolutions vs les multiplications matricielles des réseaux multicouches standards: connectivité locale!\\n  - E.g.: Image 32x32x3couleurs=3072. Un seul neurone caché aura 3072 poids à apprendre.\\n\\n- Les convolutions peuvent en plus travailler avec des entrées de tailles variables!\\n  - Pour tirer avantage, noyaux plus petits que l\\'entrée!\\n\\n## CONNECTIVITÉ (ILLUSTRÉE)\\n\\n*L\\'image montre deux diagrammes comparant la connectivité dans des réseaux neuronaux:*\\n1. En haut: connectivité locale/éparse où chaque neurone de sortie se connecte seulement à quelques neurones d\\'entrée\\n2. En bas: connectivité dense/complète où chaque neurone de sortie est connecté à tous les neurones d\\'entrée\\n\\n## PORTÉE DES POIDS\\n\\n- Dans une multiplication de matrice traditionnelle, chaque poids de la matrice W est utilisé une seule fois\\n\\n- Dans un CNN, les poids d\\'un noyau sont utilisés sur toutes les entrées\\n  - Plutôt que d\\'apprendre des poids différents pour chaque entrée, nous n\\'apprenons qu\\'un seul ensemble\\n\\n*L\\'image illustre cette différence de connectivité avec deux diagrammes montrant des connexions entre couches d\\'entrée et de sortie.*\\n\\n## GAIN EN EFFICACITÉ\\n\\n- Au niveau du temps:\\n  - Multiplication matricielle O(mn) (m entrées x n sorties) par exemple\\n  - CNN → O(kn) avec k<m représentant les connections des nœuds de sorties\\n\\n- Au niveau de la mémoire:\\n  - Le réseau feedforward standard demande de conserver mn paramètres en mémoire\\n  - Le CNN, grâce au partage de poids, n\\'a besoin de conserver que k paramètres\\n  - k est en général beaucoup plus petit que m ou n\\n\\n## E.G.: DÉTECTION DE BORDS\\n\\n*L\\'image montre un exemple de détection de bords où une image d\\'un chien (entrée) est traitée avec un filtre/kernel [1 -1] pour produire une image en sortie où seuls les contours sont visibles.*\\n\\n## E.G.: DÉTECTION DE BORDS\\n\\n- L\\'image d\\'entrée: 320 pixels par 280 = 89 600 dimensions\\n- Noyau: 2 x 1\\n- Sortie: 319 pixels (on perd un bord) par 280= 89 320\\n\\n| | Convolution | Matrice dense | Matrice creuse (+++ zéros) |\\n|-------------|-------------|-----------------|------------------------|\\n| Mémoire | 2 | 319*280*320*280 ≈8 milliards | 2*319*280 =178 640 |\\n| Multiplications/ Additions | 319*280*3 =267 960 | ≈16 milliards | (égal à conv) 267 960 |\\n\\n- La multiplication de matrice directe nécessite 8M de paramètres en mémoire et plus de 16M d\\'opérations\\n- En considérant les 0, on se rapproche de l\\'efficacité de la conv, mais on doit toujours garder 178 640 paramètres\\n\\n*Conv: a*1+b*-1 ⟵3 opérations\\n\\n## PADDING ET STRIDE\\n\\n*L\\'image illustre différentes configurations de padding et stride dans les opérations de convolution:*\\n\\n- Pas de padding, Pas de stride\\n- Avec Stride, Pas de padding\\n- Stride et padding\\n- *Une quatrième configuration est également illustrée*\\n\\n*images: https://github.com/vdumoulin/conv_arithmetic\\n\\n## TYPES DE DONNÉES\\n\\n| | Canal unique | Multiple cannaux |\\n|-----------|--------------------------|----------------------------------|\\n| 1-D | Signal audio: Amplitude du signal par temps (discret). Convolution sur le temps. | Données d\\'animation: Animations d\\'un personnage via différentes positions d\\'un « squelette » dans le temps. À chaque moment, le personnage est décrit par les angles de chaque joint. |\\n| 2-D | Audio Fourier: Transformation en données 2-D avec FFT. Colonnes: Fréquences. Lignes: points dans le temps. | Image en couleurs: Un canal par couleur. Matrice d\\'intensités correspondant à chaque pixel dans l\\'image. |\\n| 3D | Données volumétriques: Imagerie médicale, par exemple tomodensitométrie (CT scan) | Vidéo en couleurs: Même que l\\'image, mais un axe de plus pour le temps. |\\n\\n## COUCHES SPÉCIFIQUES\\n\\n*La diapositive montre uniquement un titre \"COUCHES SPÉCIFIQUES\" avec un numéro 23 dans un cercle rouge.*\\n\\n## POOLING\\n\\n- Une autre brique de base des CNN\\n- En général, une couche de convolution implique l\\'application de nombreuses convolutions en parallèle\\n- Ensuite, on passe dans une couche d\\'activation non-linéaire similairement aux modèles précédents (ReLU)\\n- La couche suivante, de pooling, modifie la sortie\\n- Cette couche remplace les sorties à l\\'aide de statistiques sommaires\\n\\n## POOLING\\n\\n- Le pooling sert à rendre la représentation peu variable à de petits changements dans la couche d\\'entrées\\n  - E.g.: une petite translation de la même image ne devrait pas affecter les sorties de la couche de pooling\\n\\n  - Par exemple, Max Pooling permet de prendre la valeur maximale dans un rectangle de voisinage\\n  \\n  - Ici, un exemple simplifié avec un pixel de décalage\\n\\n*L\\'image montre deux exemples de pooling avec des valeurs numériques, montrant comment le max pooling préserve les valeurs maximales malgré un décalage des entrées.*\\n\\n## POOLING\\n\\n- Le pooling permet d\\'améliorer nettement la qualité de l\\'apprentissage\\n- Le pooling sur une région spatial réduire les variations face aux translations\\n- On peut aussi utiliser le pooling directement sur les sorties des convolutions:\\n\\n*L\\'image montre trois filtres appris pour détecter différentes rotations du chiffre \"5\", puis un max pooling qui capture la réponse maximale, rendant la détection invariante à la rotation.*\\n\\n## POOLING\\n\\n- Il peut y avoir moins d\\'unités de pooling que d\\'unités de convolution\\n- Le sommaire peut être calculé pour des régions à k pixels d\\'intervalle\\n  - La couche suivante à donc (à peu près) k fois moins d\\'entrées à gérer!\\n  - On appelle cette technique « pooling with downsampling »\\n\\n*L\\'image montre un exemple de downsampling à travers un schéma qui illustre comment le pooling peut réduire la dimension spatiale des features.*\\n\\nLe downsampling peut être directement fait par les convolutions!!!\\n\\n## POOLING\\n\\n*L\\'image montre une architecture typique de CNN avec plusieurs couches de convolution, pooling et couches pleinement connectées, illustrant le flux de données des images d\\'entrée jusqu\\'aux probabilités de classe.*\\n\\n- Le pooling est intéressant pour bien gérer les entrées de tailles différentes\\n- Par exemple, si nos images en entrées diffèrent, le pooling pourrait permettre que la couche de classification reçoive toujours le même nombre d\\'entrées\\n\\n⟵Exemples d\\'architectures complètes de CNN\\n\\n## KERAS\\n\\n- Keras offre le MaxPooling, l\\'AveragePooling\\n\\n*L\\'image montre un exemple de code TensorFlow/Keras pour créer et utiliser une couche de MaxPooling1D.*\\n\\n- Mais aussi les global max et average\\n  - Ceux-ci s\\'appliquent sur l\\'entrée entière\\n  - GlobalMaxPooling1D dans l\\'exemple donnerait 5\\n\\n## PYTORCH\\n\\n- PyTorch offre aussi plusieurs options à ce niveau dont le MaxPooling et l\\'AvgPooling\\n\\n```python\\ninput_tensor = torch.tensor([[[1, 2, 3, 0], [4, 5, 6, 1], [7, 8, 9, 2], [0, 1, 2, 3]]], dtype=torch.float32)\\nmax_pool = nn.MaxPool2d(kernel_size=2, stride=2).max_pool(input_tensor)\\navg_pool = nn.AvgPool2d(kernel_size=2, stride=2).avg_pool(input_tensor)\\n```\\n\\n*L\\'image montre le résultat de ces opérations avec les matrices correspondantes:*\\n\\nInputTensor = [\\n[1 2 3 0]\\n[4 5 6 1]\\n[7 8 9 2]\\n[0 1 2 3]\\n]\\n\\nMaxPool = [\\n[5 6]\\n[8 9]\\n]\\n\\nAvgPool = [\\n[3 2.5]\\n[4 4]\\n]\\n\\n## DROPOUT\\n\\n- On peut parfois ignorer certains neurones artificiels\\n  - On les choisit au hasard!\\n  - pour chaque couche cachée, à chaque instance, ignorer p unités (activations)\\n\\n- Pourquoi veut-on faire ça?\\n  - Prévenir le surapprentissage (overfitting)\\n  - Dans les couches denses, les neurones sont complètements connectés et développent une co-dépendance!\\n\\n*L\\'image montre une comparaison entre un réseau neuronal standard et le même réseau après application du dropout, où certaines connexions sont désactivées aléatoirement.*\\n\\n*image: Srivastava, Nitish, et al. \"Dropout: a simple way to prevent neural networks from overfitting\", JMLR 2014\\n\\n## DROPOUT\\n\\n- C\\'est en fait une application du Bagging à un DNN\\n  - On désactive généralement 20-50% des unités cachées de façon aléatoire\\n  - Et parfois 20% des entrées pour chaque mini-batch\\n\\n- La différence majeure avec le bagging est que les modèles ne sont pas indépendants les uns des autres\\n\\n*L\\'image montre un exemple de code TensorFlow/Keras implémentant le dropout, avec l\\'entrée et la sortie correspondante.*\\n\\n## EXEMPLE MNIST AVEC CNN\\n\\n- Voir:\\n  https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/mnist_convnet.ipynb#scrollTo=nNhapcvZb4u\\n\\n- Nombre de conv\\n- Taille (3x3, 5x5, 7x7)\\n- Valid=sans, Same=avec\\n- True/False->Pas de biais !!!!\\n\\n*L\\'image montre un extrait de code Keras pour la configuration d\\'une couche Conv2D avec différents paramètres.*\\n\\n## PROPRIÉTÉS DIVERSES\\n\\n*La diapositive montre uniquement un titre \"PROPRIÉTÉS DIVERSES\" avec un numéro 36 dans un cercle rouge.*\\n\\n## ENTRAÎNEMENT\\n\\n- L\\'entraînement peut se faire de différentes façons, mais encore une fois, il faut une fonction de coûts dérivable\\n- On utilise l\\'algorithme de backpropagation\\n\\n- Aujourd\\'hui, très souvent vous n\\'aurez pas à entraîner votre CNN!\\n  - Vous pouvez en prendre un déjà entraîné\\n  - Il suffit alors d\\'ajuster les paramètres\\n  - Voir tutorial TensorFlow: https://www.tensorflow.org/guide/keras/transfer_learning\\n  - Ou en PyTorch: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\\n\\n## ENTRAÎNEMENT AVEC KERAS\\n\\n- Dans Keras, il y a beaucoup d\\'éléments à configurer pour l\\'entraînement\\n- Il est utile de bien lire la page Keras à cet effet:\\n  - https://keras.io/api/models/model_training_apis/\\n\\n- Dans la liste, il y a la fonction de perte\\n  - https://keras.io/api/losses/\\n  - La categorial cross entropy est à peu près l\\'équivalent du négatif de la log-likelihood que nous avons utilisé jusqu\\'à présent\\n  - Nous n\\'insisterons pas plus sur les fonctions de perte\\n\\n- Attention, il faut bien initialiser nos noyaux pour que l\\'entraînement se passe bien!\\n\\n## TF.KERAS.INITIALIZERS\\n\\n- Dans Keras, voici nos options:\\n  - RandomNormal(mean=0.0, stddev=0.05, seed=None)\\n  - RandomUniform(minval=-0.05, maxval=0.05, seed=None)\\n  - TruncatedNormal(mean=0.0, stddev=0.05, seed=None) ← RN sans les valeurs extrêmes\\n  - Zeros() ou Ones()\\n  - GlorotNormal/Uniform(seed=None) ← Par défaut dans nos CNN\\n    - Normal centrée, et Uniform entre des limites spécifiques\\n    - Basé sur les entrées et sorties des unités\\n  - HeNormal/Uniform(seed=None)\\n    - Comme Glorot, mais seulement basé sur les sorties\\n\\n- Etc. Voir: https://www.tensorflow.org/api_docs/python/tf/keras/initializers\\n\\n## ENTRAÎNEMENT AVEC PYTORCH\\n\\n- La façon de procéder avec PyTorch est assez différente, mais il faut tout de même configurer à peu près les mêmes éléments\\n\\n- Définir l\\'architecture du CNN: tutoriel Colab\\n\\n- Il faut ensuite choisir une fonction de perte:\\n  https://pytorch.org/docs/stable/nn.html#loss-functions\\n\\n## COMMENT FAIRE LA DÉCONVOLUTION?\\n\\n- En rétropropagation Keras et Pytorch utilise la convolution transposée pour inverser l\\'opération\\n  - L\\'opération n\\'est pas parfaite, on ne retrouve pas les données d\\'origine!\\n  - UpSampling2D coûte moins cher en temps (c\\'est un Nearest Neighbor)\\n\\n- Considérons une entrée: [0 1; 2 3] et une taille de sortie \\n\\n- Supposons un noyau [0 1; 2 3] sans stride ni padding\\n\\n*L\\'image montre comment la déconvolution/convolution transposée est calculée étape par étape, avec l\\'expression mathématique correspondante.*\\n\\n*http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf\\n\\n## CONVOLUTION TRANSPOSÉE\\n\\n- On peut apprendre les noyaux de convolution transposée!\\n  - Dans ce cas, en rétropropagation, on fait une convolution!!!\\n\\n*L\\'image montre un exemple de convolution transposée 3x3 avec stride de 2 et sans padding, illustrant comment une entrée 2x2 est transformée en sortie 4x4, avec l\\'explication \"Somme lors de chevauchements\".*\\n\\n## CONVOLUTION TRANSPOSÉE\\n\\n- Les convolutions transposées ont certains défauts\\n  - Chevauchement inégal lorsque la taille du noyau n\\'est pas divisible par le stride (ici S:2 et N:3)\\n  - Pire en 3D et peut parfois s\\'empirer au fil des couches successives\\n\\n*L\\'image montre deux exemples visuels: une grille représentant le problème de chevauchement, et une image déformée d\\'un animal avec un effet d\\'échiquier, illustrant les artefacts que peut produire la convolution transposée.*\\n\\n*https://distill.pub/2016/deconv-checkerboard/\\n\\n## AUGMENTATION DE RÉSOLUTION\\n\\n- Park et al. 2018 utilisent les convolutions transposées pour augmenter la résolution d\\'images (nous verrons brièvement avec les GAN)\\n\\n*L\\'image montre des comparaisons d\\'images avant/après super-résolution, avec 4 exemples différents (un chien, des macarons, un rapace et une figurine) où la version basse résolution est transformée en version haute résolution.*\\n\\nSeong-Jin Park, Hyeongseok Son, Sunghyun Cho, Ki-Sang Hong, Seungyong Lee. The European Conference on Computer Vision (ECCV), 2018, pp. 439-455\\n\\n## UPSAMPLING?\\n\\n- Tel que mentionné, le suréchantillonnage est plus rapide\\n\\n- Les techniques populaires\\n\\n*L\\'image montre différentes techniques d\\'upsampling:*\\n- Nearest Neighbor (duplication des pixels)\\n- Bi-Linear Interpolation (moyenne pondérée)\\n- \"Bed of Nails\" (insertion de zéros)\\n\\nP2=0.2*20+0.8*10=12\\nLes poids sont différents d\\'une implémentation à l\\'autre!!!!!\\n*https://theiailearner.com/2018/12/29/image-processing-bilinear-interpolation/\\n\\n## UPSAMPLING?\\n\\n- Pourquoi dans ce cas les librairies utilisent la ConvTransposée dans la rétropropagation?\\n  - En fait, bien qu\\'imparfaite, la transposée redistribue les gradients spatialement en imitant approximativement la propagation avant\\n  - On préserve l\\'alignement champs réceptifs des filtres de convolution ce qui est essentiel pour l\\'apprentissage!\\n\\n- L\\'up-sampling simple (bilinéaire ou par voisinage) ne préserve pas ce flux de gradient car :\\n  1. Il ne prend pas en compte la structure des poids convolutifs\\n  2. Il n\\'intègre pas les effets du stride et du padding\\n  3. Il ne distribue pas correctement les gradients aux poids des filtres.\\n\\n## MAX-UNPOOLING\\n\\n*L\\'image illustre le processus de max pooling et max unpooling:*\\n1. Pour le max pooling: on prend la valeur maximale de chaque région 2x2 dans une entrée 4x4, produisant une sortie 2x2\\n2. Pour le max unpooling: on utilise les positions mémorisées des maximums pour reconstruire une matrice 4x4 éparse\\n\\n*La partie inférieure de l\\'image montre comment le max pooling et l\\'unpooling correspondent à des couches de downsampling et upsampling dans une architecture de réseau.*\\n\\n* http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf\\n\\n## FONCTIONS D\\'ACTIVATION\\n\\nBon, dans nos exemples, nous avons vu plusieurs mots au-delà de la fonction d\\'activation sigmoid de base... mais pourquoi?\\n\\n## FONCTIONS D\\'ACTIVATION\\n\\n*L\\'image montre une grille de différentes fonctions d\\'activation organisées en 4x4:*\\n- Identité, Sigmoid, TanH, ArcTan\\n- ReLU, Leaky ReLU, Randomized ReLU, Parametric ReLU\\n- Binary, Exponential Linear Unit, Soft Sign, Inverse Square Root Unit (ISRU)\\n- Inverse Square Root Linear, Square Non-Linearity, Bipolar ReLU, Soft Plus\\n\\n## FONCTIONS D\\'ACTIVATION\\n\\n- Dans les réseaux de neurones, il existe plusieurs types de fonctions d\\'activation\\n- Elles sont divisées en deux familles:\\n  - Linéaires\\n  - Non-linéaires\\n\\n- La seconde famille nous intéresse un peu plus car elles modèlent mieux les différentes variétés de données\\n- Elles sont soit monotones ou non-monotones\\n\\n*L\\'image montre deux courbes: une fonction monotone croissante à gauche et une fonction non-monotone à droite.*\\n\\n## MONOTONIE\\n\\n- Nous avons vu l\\'intérêt d\\'avoir des fonctions différentiables, mais pourquoi désirer des fonctions monotones?\\n\\n- En fait, si vous vous souvenez bien, quand on fait la rétropropagation, nous mettons à jour nos poids pour affecter le résultat de l\\'activation (positivement ou négativement)\\n\\n- Si notre fonction n\\'est pas monotone, en augmentant le poids, nous pourrions parfois provoquer une baisse de l\\'activation!\\n\\n- Ce n\\'est pas obligatoire, car dans la plupart des cas, le réseau convergerait quand même\\n\\n- Il existe d\\'ailleurs des fonctions d\\'activation moins connues qui sont non monotones:\\n  - PFLU, FPFLU, Swish (notions avancées)\\n\\n## FONCTION HEAVISIDE\\n\\n- La fonction heaviside aussi appelée step-activation est\\n- Sa dérivée est toujours 0\\n- Conséquemment, elle n\\'est pas différentiable\\n- Et inutilisable avec la backpropagation\\n\\n*L\\'image montre le graphique de la fonction heaviside (fonction échelon unitaire) qui vaut 0 pour x<0 et 1 pour x≥0.*\\n\\n## SIGMOID ET HYPERBOLIC TANGENT (TANH)\\n\\n- Sigmoid et Tanh sont particulièrement adaptées pour prédire une probabilité comme sortie\\n- On peut les dériver (trouver la pente)\\n- Les deux sont monotones, mais pas leurs dérivées\\n  - Permet de garantir que l\\'erreur soit convexe pour un niveau (ce qui est désirable)\\n- Tanh a l\\'avantage de donner des scores très négatifs pour les entrées négatives\\n\\n```python\\nmodel.add(layers.Dense(64, activation=activations.sigmoid))\\nmodel.add(layers.Dense(64, activation=activations.tanh))\\n```\\n\\n## SIGMOID ET HYPERBOLIC TANGENT (TANH)\\n\\n- Sigmoid→ f(x) = 1/(1+e^(-x))\\n- Sa dérivée → f\\'(x) = 1/(1+e^(-x))(1-1/(1+e^(-x)))\\n\\n- Tanh→ f(x) = (e^x-e^(-x))/(e^x+e^(-x))\\n- Sa dérivée → f\\'(x) = 1-((e^x-e^(-x))/(e^x+e^(-x)))^2\\n\\n*L\\'image montre les graphiques comparant Sigmoid et Tanh ainsi que leurs dérivées respectives.*\\n\\n## SIGMOID ET HYPERBOLIC TANGENT (TANH)\\n\\n- Les deux souffrent du vanishing gradient (voir dérivées)\\n- Rappel δ^(2) = (W^(2))^T (δ^(3) * ∂ϕ(z^(2))/∂z^(2)) et ainsi de suite pour la backpropagation\\n- Si z^(2) est grand, alors la dérivée partielle tend vers 0\\n- Donc (W^(2))^T (δ^(3) * à peu près 0) →0!!!\\n\\n## RECTIFIED LINEAR UNIT (RELU)\\n\\n- Dans certains cas, Sigmoid, Tanh peuvent occasionner des problèmes (apprentissage bloqué)\\n- C\\'est une fonction monotone et sa dérivée aussi!\\n- Moins de problèmes de gradients qui disparaissent dans les réseaux avec beaucoup de couches\\n- Les opérations sont plus simples (pas d\\'exponentielle, moins de calculs)\\n- Beaucoup de valeurs d\\'unités ReLU sont à zéro, ce qui peut accélérer la convergence\\n\\n## RECTIFIED LINEAR UNIT (RELU)\\n\\n- Toutes les valeurs négatives deviennent zéro\\n- Parfois ce n\\'est pas souhaitable, cela peut arrêter l\\'entraînement au niveau des entrées négatives\\n- On peut rectifier avec un Leaky ReLU ou encore une version plus générique Parametric ReLU\\n\\n*L\\'image montre trois graphiques comparant:*\\n1. ReLU standard\\n2. Leaky ReLU/PReLU\\n3. Randomized Leaky ReLU\\n\\n## RELU VS LEAKY RELU\\n\\n- Portez surtout attention à la dérivée!\\n\\n*L\\'image montre probablement des graphiques comparant les dérivées de ReLU et Leaky ReLU, illustrant comment Leaky ReLU a une petite pente pour les valeurs négatives alors que ReLU a une dérivée nulle pour ces valeurs.*\\n\\ntf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0.0)\\n\\n## RELU ET MATRICES CREUSES\\n\\n- Les activations tombant souvent à zéro, on dit que ReLU occasion des matrices d\\'activation creuse (beaucoup de zéros)\\n  - Gain en vitesse pour le réseau, puisque les calculs sont faciles\\n  - Mais aussi un gain en espace!!!\\n  - On enregistre les éléments plutôt que des tableaux 2D (ligne, colonne, valeur)\\n\\n- Dead ReLUs problem peut devenir non négligeable dans les grands NN (la plupart ne sont plus mis à jour)\\n\\n- Les ReLU ne corrigent pas l\\'inverse du vanishing gradient\\n\\n- Ainsi, ils souffrent du exploding gradient\\n  - Moins critique!\\n\\n## AUTRES CHOIX DANS PYTORCH?\\n\\n- Il existe de nos jours une très grande quantité de fonctions d\\'activation\\n  - https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\\n\\n- Quelques intuitions sur les améliorations proposées:\\n  - Les versions Hard visent à réduire le coût de calcul par des approximations linéaires en évitant les exponentielles, leur gradient est plus stable\\n  - SELU vise l\\'autonormalisation des réseaux, ce qui réduit le besoin de BatchNorm (réseaux plus complexes à mettre en œuvre)\\n  - GELU est coûteuse mais plus douce que ReLU, fonctionne bien dans les modèles à base d\\'attention\\n  - SWISH & MISH sont non-monotones et captures des représentations plus riches et complexes tout en évitant les « dead ReLU »\\n\\n## SOFTMAX\\n\\n- Softmax est un type particulier de fonction\\n- Elle se base sur les principes de la fonction d\\'activation logistique\\n  - On produit un résultat qui est une probabilité d\\'appartenance à une classe entre 0 et 1\\n\\n- Softmax étend cette idée aux problèmes multiclasses\\n  - La somme des probabilités devient égale à 1\\n  - Chaque classe vaut entre 0 et 1\\n\\n- Ne fonctionne pas si vos instances peuvent appartenir à la fois à plusieurs classes\\n  - On doit retourner vers Sigmoïde (la fonction logistique)\\n\\nP(Y = j|X = x^(i)) = e^s_j/∑_k e^s_k, où s = f(x^(i), W)\\n\\n## SOFTMAX\\n\\n*L\\'image montre un exemple d\\'application de softmax avec une photo de chats et les calculs correspondants:*\\n\\nChat    5.1      L_i = -log P(e^s_yi/∑_k e^s_k)\\nChien   3.2      ← Proviennent d\\'une couche linéaire sans activation\\nLapin  -1.7\\n\\nProbabilités log  \\nNon normalisée    Avec activation Sigmoïde, nous aurions entraîné le réseau en minimisant la NLL\\n\\n## SOFTMAX\\n\\n[Même exemple avec calcul des probabilités]:\\n\\nChat    5.1      →  164      →  0.87\\nChien   3.2      →  24,5     →  0.13\\nLapin  -1.7      →  0,18     →  0.00\\n\\nProbabilités log  Probabilités   Probabilités\\nNon normalisée   Non normalisée  Softmax\\n\\n## SOFTMAX\\n\\n[Même exemple avec explication de l\\'optimisation]:\\n\\nChat    5.1      →  164      →  0.87     Pour l\\'optimisation,\\nChien   3.2      →  24,5     →  0.13     le log négatif:\\nLapin  -1.7      →  0,18     →  0.00     -log(0.87) = 0.0604..\\n\\nProbabilités log  Probabilités   Probabilités   C\\'est notre perte\\nNon normalisée   Non normalisée  Softmax       pour l\\'entropie\\n                                              croisée binaire!\\n\\n## ARCHITECTURES MAJEURES\\n\\nQuelques exemples très connus d\\'architectures de CNN simple.\\n\\n## LENET\\n\\nConvolution: partage spatial de poids\\nDownsampling\\nSorties entièrement connectées\\nBackpropagation\\n\\n[Le document montre un schéma de LeNet et ses paramètres]:\\n- 6 conv (3x3) + bias = 54+6 paramètres\\n- 6 channels in, 16 channels out, 6*16*(3x3)=864 plus 16 biais = 880 paramètres\\n\\nVoir: https://colab.research.google.com/drive/1CVm50PGE4vytB5I_a_ycl5F-iiKOVL9\\n\\n## ALEXNET\\n\\n- 8 couches\\n  - 5 convolutionnelles\\n  - 3 connectées\\n\\n- Similaire à LeNet, plus:\\n  - Unité d\\'activation ReLU\\n  - Entraînement plus rapide\\n\\n- Augmentation de données\\n  - Transformation avec étiquettes\\n  - Réduction du surapprentissage\\n\\nhttps://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98\\n\\n## VGG\\n\\n\"16 layers are beyond my imagination!\" \\nÀ l\\'annonce des résultats de ILSVRC 2014\\n\\n- Architecture simple (très profond pour l\\'époque)\\n  - Convolutions 3x3\\n  - 5 couches de MaxPooling\\n  - 3 couches connectées\\n\\n2-3 semaines d\\'entraînement sur 4 GPU\\n\\n## GOOGLENET / INCEPTION\\n\\nIntuition:\\n- Multiples branches\\n- Représentation locale\\n- Réduction de dimensions\\n- Plusieurs templates\\n\\nModule inception\\n\\nClasseur auxiliaire (seulement pour apprentissage)\\n\\nExemple PyTorch:\\nhttps://github.com/antspy/inception_v1.pytorch/blob/master/inception_v1.py\\n\\n## RESNET - 3.57%\\n\\n- Modèle complexe, mais rapide à l\\'entraînement\\n  - Ils facilitent le passage du gradient par rétropropagation!\\n\\n- Fonctionne similairement aux méthodes par ensembles\\n\\n- Jusqu\\'à 152 couches pour V1\\n\\n[Le document montre un schéma de bloc résiduel et un exemple de code d\\'implémentation]\\n\\n## INCEPTION-RESNET\\n\\n- Les réseaux très profonds ont été centraux dans plusieurs tâches d\\'apprentissage automatique\\n\\n- ResNet nous a appris que l\\'ajout d\\'un module résiduel facilite l\\'entraînement\\n\\n- Mais les blocs Inception eux sont bons pour extraire des caractéristiques à différentes échelles (du nombreux bloc différent et grandes formes)\\n\\n- Évidemment, il s\\'agit de réseaux très complexes, puisqu\\'ils sont composés de nombreux blocs différents en parallèle\\n  - E.g. 4 blocs Inception-ResNet-A →\\n\\nOn concatène en taille 256, juste en apprenant à sélectionner les caractéristiques.\\n\\nSortie de 32 filtres (e.g. 32 x 3 noyaux)\\n\\n## [GRAPHIQUE COMPARATIF DES ARCHITECTURES]\\n\\nLe document montre un graphique comparant différentes architectures CNN selon leur précision Top-1 (%) et le nombre d\\'opérations (G-Ops). On y voit entre autres:\\n- ResNet-18, 34, 50, 101, 152\\n- Inception-v3, v4\\n- GoogLeNet\\n- AlexNet\\n- VGG-16, VGG-19\\n\\n## PLUS RÉCEMMENT...\\n\\n[Le document montre un graphique récent de l\\'évolution des architectures avec leurs performances sur ImageNet]\\n\\nPour se tenir à jour:\\n- https://paperswithcode.com/sota/image-classification-on',\n",
       " 'language': 'French',\n",
       " 'topic': 'Deeplearning',\n",
       " 'path_txt': 'data_txt',\n",
       " 'subject': ['Leçon #3 - Deep Learning',\n",
       "  'Leçon #7 - GAN - 2025',\n",
       "  'Leçon #8 - Graph neural network',\n",
       "  'Leçon #2 - Neurone artificiel',\n",
       "  'Leçon #1 - Introduction',\n",
       "  'Leçon #4 - CNN',\n",
       "  'Leçon #5 - RNN - 2025',\n",
       "  'Leçon #6 - Auto-apprentissage',\n",
       "  'Leçon #9 - Transformers and generative AI'],\n",
       " 'tool_used': 'qa_tool',\n",
       " 'rephrased_question': 'Make me an question to develop about pooling in CNN?',\n",
       " 'proceed_to_generate': False,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='Make me an question to develop about pooling in CNN?', additional_kwargs={}, response_metadata={}, id='e8fb9ad2-8a7d-4442-bf08-fc236f399471')}"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_query = \"Make me an question to develop about pooling in CNN?\"\n",
    "input_data = {\"question\": HumanMessage(content=qa_query)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 211}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927f39c",
   "metadata": {},
   "source": [
    "### MCQ query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "108c2183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [], 'question': HumanMessage(content='Make me an mcq about perceptron?', additional_kwargs={}, response_metadata={})}\n",
      "Entering agent\n",
      "messages = [HumanMessage(content='Make me an mcq about perceptron?', additional_kwargs={}, response_metadata={}, id='a79a0d48-ddad-440e-956a-eef268ae2a04')]\n",
      "Entering mcq_tool\n",
      "retrieve_for_MCQ: Retrieved 10 documents\n",
      "Entering tool_router\n",
      "state['tool_used'] =  mcq_tool\n",
      "Routing to find_relevant_docs\n",
      "Entering find_relevant_docs\n",
      "subjects: Leçon #3 - Deep Learning\n",
      "Leçon #7 - GAN - 2025\n",
      "Leçon #8 - Graph neural network\n",
      "Leçon #2 - Neurone artificiel\n",
      "Leçon #1 - Introduction\n",
      "Leçon #4 - CNN\n",
      "Leçon #5 - RNN - 2025\n",
      "Leçon #6 - Auto-apprentissage\n",
      "Leçon #9 - Transformers and generative AI\n",
      "\n",
      "question_classifier: related_subject = Leçon #3 - Deep Learning\n",
      "Entering exercise_router\n",
      "state['tool_used'] =  mcq_tool\n",
      "Routing to generate_mcq\n",
      "Entering generate_mcq\n",
      "generate_mcq: rephrased_question: Make me an mcq about perceptron?\n",
      "generate_mcq: Generated response: {'1': {'mcq': 'Which of the following components is essential in defining a Multi-Layer Perceptron (MLP)?', 'options': {'a': 'Only an input layer and an output layer', 'b': 'At least one hidden layer', 'c': 'Non-linear activation functions', 'd': 'Both b and c are required'}, 'correct': 'd'}, '2': {'mcq': 'What is the primary purpose of the activation function within a perceptron?', 'options': {'a': 'To normalize the output values', 'b': 'To introduce non-linearity into the model', 'c': 'To determine the learning rate', 'd': 'To calculate the cost function'}, 'correct': 'b'}, '3': {'mcq': 'In the context of MLPs, what does the term \"backpropagation\" refer to?', 'options': {'a': 'A method for forward propagation of data', 'b': 'An optimization algorithm for hyperparameter tuning', 'c': 'A procedure for updating weights using gradients', 'd': 'A technique for feature selection'}, 'correct': 'c'}}\n",
      "generate_mcq: Generated review: The quiz presented is focused on key concepts related to Multi-Layer Perceptrons (MLPs) in deep learning. Here's a brief evaluation and analysis of the questions and their complexity:\n",
      "\n",
      "### Complexity Assessment\n",
      "\n",
      "1. **Question 1: Multi-Layer Perceptron Components**\n",
      "   - **Complexity:** Moderate\n",
      "   - **Analysis:** This question assesses understanding of the structural components of MLPs. Options ‘b’ and ‘c’ test specific knowledge about hidden layers and activation functions—both critical for MLPs. Option ‘d’ emphasizes the need for both features, requiring a comprehensive understanding of MLP architecture.\n",
      "\n",
      "2. **Question 2: Purpose of Activation Function**\n",
      "   - **Complexity:** Low to Moderate\n",
      "   - **Analysis:** This question probes a fundamental concept within MLPs. Understanding the role of activation functions is crucial for grasping how neural networks model complex patterns. While option ‘b’ is straightforward, differentiating it from options about normalization and learning rates requires a basic understanding of neural network operations.\n",
      "\n",
      "3. **Question 3: Backpropagation in MLPs**\n",
      "   - **Complexity:** Moderate to High\n",
      "   - **Analysis:** This question targets a critical algorithmic process in neural networks. Understanding backpropagation involves knowledge of gradients and weight updates, necessitating a deeper engagement with the mechanics of learning in MLPs. This question tests comprehension of not only terminology but also its application in model training.\n",
      "\n",
      "### Overall Analysis\n",
      "\n",
      "The quiz effectively engages students in core concepts of Multi-Layer Perceptrons, balancing foundational knowledge with a slightly higher-level understanding of algorithms and processes involved in deep learning. The answer choices are well-crafted to differentiate between similar concepts, enhancing critical thinking skills. Additionally, incorporating a variety of question complexities ensures that students are assessed on both basic and advanced levels of understanding, which is essential for grasping deep learning concepts fully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages_': [HumanMessage(content='Make me an mcq about perceptron?', additional_kwargs={}, response_metadata={}, id='a79a0d48-ddad-440e-956a-eef268ae2a04'),\n",
       "  AIMessage(content='{\\'1\\': {\\'mcq\\': \\'Which of the following components is essential in defining a Multi-Layer Perceptron (MLP)?\\', \\'options\\': {\\'a\\': \\'Only an input layer and an output layer\\', \\'b\\': \\'At least one hidden layer\\', \\'c\\': \\'Non-linear activation functions\\', \\'d\\': \\'Both b and c are required\\'}, \\'correct\\': \\'d\\'}, \\'2\\': {\\'mcq\\': \\'What is the primary purpose of the activation function within a perceptron?\\', \\'options\\': {\\'a\\': \\'To normalize the output values\\', \\'b\\': \\'To introduce non-linearity into the model\\', \\'c\\': \\'To determine the learning rate\\', \\'d\\': \\'To calculate the cost function\\'}, \\'correct\\': \\'b\\'}, \\'3\\': {\\'mcq\\': \\'In the context of MLPs, what does the term \"backpropagation\" refer to?\\', \\'options\\': {\\'a\\': \\'A method for forward propagation of data\\', \\'b\\': \\'An optimization algorithm for hyperparameter tuning\\', \\'c\\': \\'A procedure for updating weights using gradients\\', \\'d\\': \\'A technique for feature selection\\'}, \\'correct\\': \\'c\\'}}', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"The quiz presented is focused on key concepts related to Multi-Layer Perceptrons (MLPs) in deep learning. Here's a brief evaluation and analysis of the questions and their complexity:\\n\\n### Complexity Assessment\\n\\n1. **Question 1: Multi-Layer Perceptron Components**\\n   - **Complexity:** Moderate\\n   - **Analysis:** This question assesses understanding of the structural components of MLPs. Options ‘b’ and ‘c’ test specific knowledge about hidden layers and activation functions—both critical for MLPs. Option ‘d’ emphasizes the need for both features, requiring a comprehensive understanding of MLP architecture.\\n\\n2. **Question 2: Purpose of Activation Function**\\n   - **Complexity:** Low to Moderate\\n   - **Analysis:** This question probes a fundamental concept within MLPs. Understanding the role of activation functions is crucial for grasping how neural networks model complex patterns. While option ‘b’ is straightforward, differentiating it from options about normalization and learning rates requires a basic understanding of neural network operations.\\n\\n3. **Question 3: Backpropagation in MLPs**\\n   - **Complexity:** Moderate to High\\n   - **Analysis:** This question targets a critical algorithmic process in neural networks. Understanding backpropagation involves knowledge of gradients and weight updates, necessitating a deeper engagement with the mechanics of learning in MLPs. This question tests comprehension of not only terminology but also its application in model training.\\n\\n### Overall Analysis\\n\\nThe quiz effectively engages students in core concepts of Multi-Layer Perceptrons, balancing foundational knowledge with a slightly higher-level understanding of algorithms and processes involved in deep learning. The answer choices are well-crafted to differentiate between similar concepts, enhancing critical thinking skills. Additionally, incorporating a variety of question complexities ensures that students are assessed on both basic and advanced levels of understanding, which is essential for grasping deep learning concepts fully.\", additional_kwargs={}, response_metadata={})],\n",
       " 'messages': [HumanMessage(content='Make me an mcq about perceptron?', additional_kwargs={}, response_metadata={}, id='a79a0d48-ddad-440e-956a-eef268ae2a04'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lXHSdQba2MptnTkEFLplCheI', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Make me an mcq about perceptron?\",\"type\":\"human\"}],\"messages\":[{\"content\":\"Make me an mcq about perceptron?\",\"type\":\"human\"}],\"documents\":[],\"related_subject\":\"Deep Learning\",\"related_subject_content\":\"Perceptron is a type of artificial neuron that is the simplest form of a neural network used for supervised learning of binary classifiers.\",\"language\":\"en\",\"topic\":\"Perceptron\",\"path_txt\":\"perceptron_mcq.txt\",\"subject\":[\"Perceptron\",\"Neural Networks\",\"Artificial Intelligence\"],\"tool_used\":\"mcq_tool\",\"rephrased_question\":\"Can you generate a multiple-choice question about perceptrons?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"Which of the following statements is true about a perceptron?\",\"type\":\"human\"}}}', 'name': 'mcq_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 195, 'prompt_tokens': 2311, 'total_tokens': 2506, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2304}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLbWBya8O8XtyB4F2CUgLStF5cyz5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c8ca6d88-04c3-4cb3-86c7-1a63f5ec26e1-0', tool_calls=[{'name': 'mcq_tool', 'args': {'state': {'messages_': [{'content': 'Make me an mcq about perceptron?', 'type': 'human'}], 'messages': [{'content': 'Make me an mcq about perceptron?', 'type': 'human'}], 'documents': [], 'related_subject': 'Deep Learning', 'related_subject_content': 'Perceptron is a type of artificial neuron that is the simplest form of a neural network used for supervised learning of binary classifiers.', 'language': 'en', 'topic': 'Perceptron', 'path_txt': 'perceptron_mcq.txt', 'subject': ['Perceptron', 'Neural Networks', 'Artificial Intelligence'], 'tool_used': 'mcq_tool', 'rephrased_question': 'Can you generate a multiple-choice question about perceptrons?', 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': 'Which of the following statements is true about a perceptron?', 'type': 'human'}}}, 'id': 'call_lXHSdQba2MptnTkEFLplCheI', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2311, 'output_tokens': 195, 'total_tokens': 2506, 'input_token_details': {'audio': 0, 'cache_read': 2304}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\\'messages_\\': [BaseMessage(content=\\'Make me an mcq about perceptron?\\', additional_kwargs={}, response_metadata={}, type=\\'human\\')], \\'messages\\': [BaseMessage(content=\\'Make me an mcq about perceptron?\\', additional_kwargs={}, response_metadata={}, type=\\'human\\')], \\'documents\\': [Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"Attention! Même si on nomme ce modèle multi layer perceptron, les couches sont composées d\\'unités sigmoids, non pas de perceptrons!\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"De plus, Cybenko G. a montré en 1989 qu\\'un réseau sigmoid à propagation avant est un approximateur universel si le nombre de neurones dans la couche cachée est suffisamment grand\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"Les GAN réussissent ces exploits en entraînant deux réseaux en compétition coopérative: - **Générateur**: il vise à apprendre à générer de fausses données (images, mais aussi textes, sons, etc.) pour tromper le discriminateur - **Discriminateur**: il va tenter d\\'apprendre à détecter les fausses données (problème de classification binaire +/-)\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\\'## PERCEPTRON MULTICOUCHE Une unité dans la couche de sortie permet de faire de la classification binaire\\'), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"[L\\'image montre un réseau neuronal multicouche avec des vecteurs d\\'encodage one-hot]\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\\'Contenu spécifique: Multi Layer Perceptron Propagation avant Fonction de coûts Rétropropagation Exemples de code\\'), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"L\\'entrée du générateur est du bruit (vecteur aléatoire). Sa sortie est la donnée synthétisée. L\\'entrée du discriminateur est une vraie ou une fausse donnée: - Les vraies données viennent d\\'un vrai ensemble d\\'entraînement - Les fausses du générateur\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"Cependant, voici quelques exceptions si vous souhaitez aller au-delà du cadre de ce cours: Réseaux de neurones utilisant des algorithmes évolutionnaires: Au lieu d\\'utiliser les gradients pour optimiser les poids, ces algorithmes simulent le processus de sélection naturelle\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\"## BACKPROPAGATION Permet d\\'apprendre les poids dans un réseau de neurones efficacement\"), Document(metadata={\\'source\\': \\'data_txt/deeplearning.txt\\'}, page_content=\\'## INTRODUCTION Dans ce module, nous introduisons un type particulier de réseaux de neurones. Inventés en 2014 par Goodfellow, les Generative Adversarial Networks (GAN) sont devenus très populaires dans les dernières années. Ce sont des réseaux génératifs: - Contrairement aux auto-encodeurs, ils peuvent créer de nouvelles données avec un encodage arbitraire\\')], \\'related_subject\\': \\'Deep Learning\\', \\'related_subject_content\\': \\'Perceptron is a type of artificial neuron that is the simplest form of a neural network used for supervised learning of binary classifiers.\\', \\'language\\': \\'en\\', \\'topic\\': \\'Perceptron\\', \\'path_txt\\': \\'perceptron_mcq.txt\\', \\'subject\\': [\\'Perceptron\\', \\'Neural Networks\\', \\'Artificial Intelligence\\'], \\'tool_used\\': \\'retrieve_for_MCQ\\', \\'rephrased_question\\': \\'Can you generate a multiple-choice question about perceptrons?\\', \\'proceed_to_generate\\': True, \\'rephrase_count\\': 0, \\'question\\': HumanMessage(content=\\'Which of the following statements is true about a perceptron?\\', additional_kwargs={}, response_metadata={})}', name='mcq_tool', id='9b343522-0df5-4528-a14f-443f935c4ebe', tool_call_id='call_lXHSdQba2MptnTkEFLplCheI')],\n",
       " 'documents': [],\n",
       " 'related_subject': 'Leçon #3 - Deep Learning',\n",
       " 'related_subject_content': \"# DEEP LEARNING - Leçon #3\\n\\nPar Kévin Bouchard Ph.D.\\nProfesseur titulaire en intelligence artificielle et apprentissage automatique\\nLaboratoire d'Intelligence Ambiante pour la reconnaissance d'activités (LIARA)\\nDirecteur de l'Espace innovation en technologies numériques Hydro-Québec\\nPrésident du Regroupement québécois des maladies orphelines (RQMO)\\nUniversité du Québec à Chicoutimi\\nwww.Kevin-Bouchard.ca            Kevin_Bouchard@uqac.ca\\n\\n## CONTENU DE LA LEÇON #3\\n\\nVous apprendrez:\\n- Comment on passe d'un simple neurone à un réseau profond\\n- Comment on entraîne un réseau profond sans boucle\\n- L'implémentation concrète et celles assistée par les librairies TF et PyTorch\\n\\nContenu spécifique:\\n- Multi-Layer Perceptron\\n- Propagation avant\\n- Fonction de coûts\\n- Rétropropagation\\n- Exemples de code\\n\\n## INTRODUCTION\\n\\n- Le deep learning ou l'apprentissage profond est la tendance la plus populaire en apprentissage automatique\\n- Il s'agit d'un ensemble d'algorithmes développés pour l'entraînement de réseau de neurones artificiels à plusieurs couches\\n- C'est en 1986 que l'intérêt des NN reprend avec la découverte de l'algorithme backpropagation qui permet l'entraînement de réseaux multicouches plus facilement\\n- State-of-the-art pour les problèmes exploitant des données complexes (images, voix, textes)\\n  - Nous verrons plus précisément les propriétés\\n\\n## RETOUR SUR LES NN SIMPLES\\n\\n[L'image montre un diagramme d'un neurone artificiel simple avec ses composants: entrées, poids, biais, fonction d'activation et sortie]\\n\\n- À chaque epoch, on mettait à jour les poids: w := w + Δw.  Δw = -η∇J(w)\\n- On utilisait la descente du gradient ou SGD (version itérative)\\n- La fonction objective à optimiser était la Sum of Squared Errors (SSE) ou encore Log-Likelihood (NLL)\\n  - Selon si Adaline ou Logistic\\n\\n## APPRENTISSAGE PAR ENSEMBLE?\\n\\n- L'apprentissage par ensemble (ensemble learning) repose sur l'idée de combiner plusieurs modèles pour améliorer les performances de prédiction par rapport à un seul modèle\\n  - Avec le Bagging on réduit la variance et diminue les risques de surapprentissage (e.g. Random Forest)\\n  - Avec le Boosting on augmente la robustesse en compensant les erreurs individuelles des modèles (e.g. Adaboost, Gradient Boosting)\\n  - Avec le Stacking, on peut exploiter les forces et les faiblesses de différents modèles en apprenant automatiquement comment « voter »\\n  - Toutes les techniques tendent à améliorer la justesse (accuracy)!\\n\\n- En deep learning, nous tentons de tirer profit d'un peu toutes ces techniques!\\n\\n## MULTIPLES COUCHES\\n\\n- Nos NN sont simple couche, même s'il y a une couche d'entrées et une de sorties à cause du lien unique qui les lie\\n- On peut ajouter une couche cachée de neurones pour former un réseau de neurones multicouche à propagation avant (multi-layer feed forward NN)\\n- Les neurones de la couche cachée sont complètement connectés à la couche d'entrées et à la couche de sortie\\n- Si + d'un niveau caché, alors besoin des techniques du deep learning\\n\\n[L'image montre un réseau neuronal à 3 couches: couche d'entrée, couche cachée et couche de sortie, avec les connexions entre neurones]\\n\\n## PERCEPTRON MULTICOUCHE\\n\\n- Nous notons maintenant l'unité d'activation i de la couche ℓ: a_i^(ℓ)\\n- L'activation des unités à la couche d'entrée est:\\n  a^(i) = [a_0^(1), a_1^(1), ..., a_m^(1)] = [1, x_1^(i), ..., x_m^(i)]\\n\\n- Chaque unité k de la couche ℓ est connecté à l'aide d'un poids à chaque unité j du niveau ℓ+1: w_j,k^(ℓ)\\n- Attention! Il ne faut pas confondre avec l'échantillon i dans x_m^(i)\\n\\n## MULTICLASSE NATIVEMENT?\\n\\n[L'image montre du code PyTorch pour la conversion d'étiquettes en représentation one-hot]\\n\\n- [0 1 0 1 0 0 0 1 0]\\n\\nÉtiquettes d'origine:\\ntensor([0, 1, 2, 1, 0])\\n\\nReprésentation One-Hot:\\ntensor([[1, 0, 0],\\n        [0, 1, 0],\\n        [0, 0, 1],\\n        [0, 1, 0],\\n        [1, 0, 0]])\\n\\n## PERCEPTRON MULTICOUCHE\\n\\n- Une unité dans la couche de sortie permet de faire de la classification binaire\\n- À l'aide de la représentation de classe par vecteur one-hot, on peut passer aux problèmes multiclasses\\n\\n[L'image montre un réseau neuronal multicouche avec des vecteurs d'encodage one-hot]\\n\\n0 = [1, 0, 0], 1 = [0, 1, 0], 2 = [0, 0, 1]\\n\\nContrairement à la représentation de classe en entier, les one-hot ne causent pas de problèmes avec les algorithmes basés sur des distances\\n\\n## PERCEPTRON MULTICOUCHE\\n\\n- Pourquoi w_j,k^(ℓ) plutôt que w_k,j^(ℓ)? Simplement une question mathématique!\\n\\n- Matrice W^(ℓ) ∈ ℝ^j×[k+1] pour représenter les poids de la couche ℓ\\n  - j est le nombre d'unités à la couche ℓ+1\\n  - k le nombre d'unités à la couche ℓ\\n\\n- Donc, un réseau à L couches a L-1 matrices de poids W\\n\\n## PROPAGATION AVANT\\n\\n- La propagation avant permet de calculer la ou les sorties du réseau multicouche\\n- Puisque notre réseau est complètement connecté, nous calculons l'activation d'une unité a_1^(2) de cette façon:\\n  z_1^(2) = a_0^(1)w_1,0^(1) + a_1^(1)w_1,1^(1) + ... + a_m^(1)w_1,m^(1)\\n  \\n  a_1^(2) = φ(z_1^(2))\\n\\n- z_1^(2) est l'entrée nette et φ(·) la fonction d'activation\\n  - Celle-ci doit être dérivable en tout point (gradient)\\n  - Non linéaire pour les problèmes complexes (e.g.:sigmoid)\\n  φ(z) = 1/(1+e^-z)\\n\\n## PROPAGATION AVANT\\n\\n- Chaque couche sert d'entrée à la couche suivante sans qu'il n'y ait de boucle\\n  - Ce n'est pas le cas dans un recurrent neural network, où au contraire il y a une boucle!\\n  - Nous verrons plus tard quelques modèles avec des boucles\\n\\n- Attention! Même si on nomme ce modèle multi-layer perceptron, les couches sont composées d'unités sigmoids, non pas de perceptrons!\\n  - De plus, les valeurs retournées par les unités sont continues (0..1)\\n  - Nous n'utiliserons plus le fameux quantizer en deep learning\\n\\n## PROPAGATION AVANT\\n\\n- Question de simplicité, nous utiliserons une notation plus compacte pour l'activation:\\n  z^(2) = W^(1)a^(1)\\n  a^(2) = φ(z^(2))\\n\\n- a^(1) est le vecteur de features de taille m+1 correspondant à l'échantillon x^(i) plus le biais\\n- m est le nombre d'entrées dans l'unité\\n- W^(1) est la matrice de taille h × [m + 1] avec h représentant le nombre d'unités cachées\\n- z^(2) devient le vecteur d'entrées nettes h × 1 pour l'activation\\n\\n## PROPAGATION AVANT\\n\\n- De plus, on peut généraliser aux n échantillons:\\n\\n  Z^(2) = W^(1)[A^(1)]^T\\n\\n- A^(1) est la matrice n × [m + 1]\\n- Z^(2) est la matrice h × n\\n\\n- Avec notre matrice Z^(2), nous pouvons calculer la matrice h × n d'activation du niveau suivant: A^(2) = φ(Z^(2))\\n\\n## PROPAGATION AVANT\\n\\n- La matrice d'entrées nettes t × n de la couche suivante (output) devient:\\n  Z^(3) = W^(2)A^(2)\\n  \\n  - t est le nombre d'unités de la couche de sorties\\n  - W^(2) est la matrice de poids t × h\\n\\n- Finalement, dans notre exemple, les sorties sont trouvées grâce à l'application de la fonction d'activation sur Z^(3)\\n  A^(3) = φ(Z^(3))\\n  \\n  - A^(3) est la matrice de réels de taille t × n, où t est le nombre de classes et n le nombre d'échantillons\\n\\n## PROPAGATION AVANT AVEC CHIFFRES!\\n\\na^(1) = [1, 2, 3], W^(1) = [[0.5  1  -0.5], [-1  2  1.5]] × [0.25, 0.5] , W^(2) = [[0  0.1], [-1  1], [0.1  0]] × [1, -2, -1]\\n\\nz^(2) = W^(1)a^(1) = [[0.5  1  -0.5], [-1  2  1.5]] × [1, 2, 3] + [0.25, 0.5] = \\n\\n[0.5 * 1 + 1 * 2 - 0.5 * 3] + [0.25] = [1] + [0.25] = [1.25]\\n[-1 * 1 + 2 * 2 + 1.5 * 3] + [0.5] = [7.5] + [0.5] = [8]\\n\\na^(2) = φ(z^(2)) = [1/(1+e^(-1.25)), 1/(1+e^(-8))] ≈ [0.7773, 0.9997]\\n\\n## PROPAGATION AVANT AVEC CHIFFRES!\\n\\na^(1) = [1, 2, 3], W^(1) = [[0.5  1  -0.5], [-1  2  1.5]] × [0.25, 0.5] , W^(2) = [[0  0.1], [-1  1], [0.1  0]] × [1, -2, -1]\\n\\nz^(3) = W^(2)a^(2) = [[0  0.1], [-1  1], [0.1  0]] × [0.7773, 0.9997] + [1, -2, -1] =\\n\\n[0 * 0.7773 + 0.1 * 0.9997] + [1] = [0.09997] + [1] = [1.09997]\\n[-1 * 0.7773 + 0.9997] + [-2] = [0.2224] + [-2] = [-1.7776]\\n[0.1 * 0.7773 + 0 * 0.9997] + [-1] = [0.07773] + [-1] = [-0.92227]\\n\\na^(3) = φ(z^(3)) = [1/(1+e^(-1.09997)), 1/(1+e^(-(-1.7776))), 1/(1+e^(-(-0.92227)))] ≈ [0.7503, 0.0978, 0.2539]\\n\\n## EXEMPLE APPLIQUÉ\\n\\n## CLASSIFICATION DE CHIFFRES\\n\\n- Nous utiliserons le dataset très connu MNIST qui contient:\\n  - 60 000 images d'entraînement\\n  - 10 000 images de tests\\n  - Les images sont les chiffres 0 à 9 écris à la main\\n- http://yann.lecun.com/exdb/mnist/\\n\\n## QUELQUES RÉSULTATS SUR LA PAGE:\\n\\n[L'image montre un tableau comparatif des performances de différents modèles de classification sur MNIST, incluant des classificateurs linéaires, K-Nearest Neighbors, SVMs et réseaux neuronaux]\\n\\n## VISUALISATION\\n\\n[Le code Python utilisant matplotlib pour visualiser des exemples d'images MNIST]\\n\\n[L'image montre des exemples de chiffres manuscrits de 0 à 9 du dataset MNIST]\\n\\n## VISUALISATION (SUITE)\\n\\n[Le code Python similaire visualisant plusieurs exemples du chiffre 7]\\n\\n[L'image montre 25 exemples différents du chiffre 7 manuscrit]\\n\\n## IMPLÉMENTATION ET TEST\\n\\n```python\\nnn = NeuralNetMLP(\\n    n_output=10,\\n    n_features=X_train.shape[1],\\n    n_hidden=50,\\n    l2=0.1, l1=0.0,\\n    epochs=1000,\\n    eta=0.001,\\n    alpha=0.001,\\n    decrease_const=0.00001,\\n    minibatches=50,\\n    shuffle=True, random_state=1)\\n```\\n\\n- L2 réduit le surapprentissage\\n- 784 unités d'entrées\\n- 50 unités cachées\\n- 10 unités de sorties (classes)\\n- Alpha ajoute un momentum du gradient de l'epoch précédent pour accélérer l'apprentissage\\n  Δw_t = η∇J(w_t) + αΔw_{t-1}\\n- Decrease (d) permet de réduire le taux d'apprentissage au fil du temps\\n  η/(1 + t × d)\\n\\n## IMPLÉMENTATION ET TEST\\n\\n- Entraînement du modèle:\\n```python\\nnn.fit(X_train, y_train, print_progress=False)\\n```\\n\\n- Graphique des coûts (cost_) pour chaque minibatchs (50*1000epochs):\\n\\n[Code Python pour générer un graphique montrant la diminution du coût d'apprentissage]\\n\\n[L'image montre une courbe d'apprentissage descendante, partant d'environ 1500-2000 et diminuant progressivement jusqu'à environ 300-400]\\n\\nVoir https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\\n\\n## ÉVALUATION\\n\\n- Évaluons le modèle avec l'ensemble de test:\\n```python\\ny_test_pred = nn.predict(X_test)\\nacc = np.sum(y_test == y_test_pred, axis=0) / X_test.shape[0]\\nprint('Test accuracy: %.2f%%' % (acc * 100))\\n\\nTest accuracy: 95.62%\\n```\\n\\n- Le modèle pourrait être amélioré à l'aide de l'optimisation des hyperparamètres\\n  - Celui-ci en contient plusieurs: learning rate, nombre d'unités cachées, alpha, decrease_const et régularisation L1 & L2\\n  - Cette partie peut s'avérer assez complexe dans certains problèmes d'apprentissage\\n\\n## IMPLÉMENTATION EN MINIBATCHS\\n\\n- L'utilisation des minibatchs pour le calcul de nos gradients est un type particulier de stochastic gradient descent\\n  - Plutôt que de calculer sur un échantillon, nous le faisons sur k\\n  - 1 < k < n\\n\\n- Plus rapide que gradient descent (k=n)\\n- Mais plus efficace en implémentation que SGD (k=1)\\n  - Implémentation des techniques de calculs vectoriels!\\n  - Beaucoup plus efficace!\\n\\n- C'est un peu comme un sondage avant des élections...\\n\\n## AVEC TF/KERAS\\n\\n[Code Python montrant l'implémentation d'un réseau neuronal avec TensorFlow/Keras pour la classification MNIST]\\n\\n## EXÉCUTION DE L'EXEMPLE\\n\\n```\\n469/469 [==========================] - 1s 3ms/step - loss: 0.3595 - accuracy: 0.9010 - val_loss: 0.1905 - val_accuracy: 0.9483\\nEpoch 2/6\\n469/469 [==========================] - 1s 2ms/step - loss: 0.1612 - accuracy: 0.9543 - val_loss: 0.1351 - val_accuracy: 0.9593\\nEpoch 3/6\\n469/469 [==========================] - 1s 2ms/step - loss: 0.1143 - accuracy: 0.9678 - val_loss: 0.1051 - val_accuracy: 0.9689\\nEpoch 4/6\\n469/469 [==========================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9750 - val_loss: 0.0981 - val_accuracy: 0.9708\\nEpoch 5/6\\n469/469 [==========================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.9797 - val_loss: 0.0846 - val_accuracy: 0.9748\\nEpoch 6/6\\n469/469 [==========================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9830 - val_loss: 0.0801 - val_accuracy: 0.9755\\n```\\n\\n- On peut voir que c'est beaucoup plus rapide avec Tensorflow que notre code\\n- Les résultats sont aussi meilleurs, même si nous n'avons rien optimisé\\n- En quelques lignes, nous avons un modèle qui dépasse la majorité des méthodes d'apprentissage automatique classique!\\n\\n## AVEC PYTORCH\\n\\n[Code Python montrant l'implémentation d'un réseau neuronal avec PyTorch pour la classification MNIST]\\n\\n```\\nEpoch [1/5], Loss: 0.1187\\nEpoch [2/5], Loss: 0.1095\\nEpoch [3/5], Loss: 0.0239\\nEpoch [4/5], Loss: 0.1840\\nEpoch [5/5], Loss: 0.1625\\nPrécision sur l'ensemble de test : 96.30%\\n```\\n\\n## ENTRAÎNEMENT\\n\\nCalcul de la fonction de coûts\\nAlgorithme de rétropropagation\\n\\n## FONCTION DE COÛTS\\n\\n- La fonction de coût ici est la même que pour logistic regression:\\n  J(w) = -∑(i=1 to n) y^(i) log(a^(i)) + (1-y^(i)) log(1-a^(i))\\n\\n- a^(i) est l'activation sigmoid de l'unité d'une couche: φ(z^(i))\\n- Pour un échantillon i\\n\\n- En ajoutant la régularisation L2 (pour réduire le surapprentissage) on obtient:\\n  J(w) = -[∑(i=1 to n) y^(i) log(a^(i)) + (1-y^(i)) log(1-a^(i))] + λ/2‖w‖²₂\\n\\n## FONCTION DE COÛTS\\n\\n- Puisque nous voulons faire de la classification multi classes, le vecteur de sortie est de taille t × 1 à comparer avec la cible dans le vecteur one hot (lui aussi de taille t)\\n\\n- E.g. l'activation à la couche de sortie (3) et la comparaison avec la classe cible #2 pourrait ressembler à ceci:\\n  a^(3) = [0.1, 0.9, ..., 0.3], y = [0, 1, ..., 0]\\n\\n## FONCTION DE COÛTS\\n\\n- Il faut généraliser notre fonction de coûts à toutes les unités j:\\n  - Ici, (i) représente l'échantillon d'entraînement\\n\\n  J(w) = -[∑(i=1 to n)∑(j=1 to m) y_j^(i) log(φ(z_j^(i))) + (1-y_j^(i)) log(1-φ(z_j^(i)))] + λ/2 ∑(l=1 to L-1)∑(i=1 to u_l)∑(j=1 to u_{l+1}) (w_{j,i}^(l))²\\n\\n- L'équation fait un peu peur, mais elle représente simplement les coûts pour toutes les unités du réseau et tous les échantillons de l'ensemble d'entraînement\\n\\n- De plus, λ/2 ∑(l=1 to L-1)∑(i=1 to u_l)∑(j=1 to u_{l+1}) (w_{j,i}^(l))² est la pénalité L2 (l est la couche!)\\n\\n## FONCTION DE COÛTS\\n\\n- Objectif: minimiser notre fonction de coûts\\n\\n- Il faut donc calculer la dérivée partielle de la matrice de poids par rapport à tous les poids du réseau:\\n  ∂/∂w_{j,i}^(l) J(W)\\n\\n  - À noter que W est en fait un ensemble de matrices qui n'ont généralement pas la même dimension\\n  - Leur taille dépend du nombre d'unités des différents niveaux\\n\\n## CODE\\n\\n[L'image montre un extrait de code Python pour le calcul de la fonction de coût]\\n\\n- L1 tend à éliminer des caractéristiques\\n- C'est un peu du feature selection!\\n- L2 diminue les valeurs des poids, mais sans atteindre 0\\n\\n## FONCTIONS SIMPLES\\n\\n- Ok, mais concrètement, comment L1 peut-elle faire de la sélection de caractéristiques?\\n- En fait, si on regarde l'implémentation du gradient, nous avons:\\n\\n```python\\ngrad1[:, 1:] += self.l2 * w1[:, 1:]\\ngrad1[:, 1:] += self.l1 * np.sign(w1[:, 1:])\\n```\\n\\n- Soit Δ += λ * W^(l) pour L2 et Δ += {λ * 1, w > 0; λ * -1, w < 0}, ∀w ∈ W^(l) pour L1\\n\\n- C'est qu'en dérivant W^(l) = W^(l) - ηΔ^(l), sachant que delta est la dérivée de la fonction de coûts ∂J(W)/∂W et qu'on y additionne simplement les termes L1 et L2\\n\\n## FONCTIONS SIMPLES\\n\\n[L'image montre des graphiques des fonctions L1 et L2 et leurs dérivées]\\n\\n- La conséquence est que pour L1, si une soustraction d'un w a pour effet d'en changer le signe\\n- Par exemple de +0.3 à -0.1\\n- Alors on croise le 0 et L1 fait passer le w à 0\\n\\n## BACKPROPAGATION\\n\\nPermet d'apprendre les poids dans un réseau de neurones efficacement\\n\\nNous verrons d'abord intuitivement comment la méthode fonctionne, puis nous décrivons un peu plus formellement\\n\\n## BACKPROPAGATION\\n\\n- Algorithme efficace (d'un point de vue algorithmique) qui permet de calculer les dérivées d'une fonction de coûts complexe\\n  - On utilise les dérivées pour apprendre les poids (comme d'habitude)\\n  - Dans le contexte de nos réseaux multicouches, nous avons beaucoup de poids et travaillons généralement en très haute dimension!\\n\\n- Nos fonctions de coûts ne sont plus convexes et lisses, elles sont concaves et inégales\\n  - Cas plus difficile en optimisation!!!\\n\\n## BACKPROPAGATION\\n\\n- La rétropropagation est utilisée dans la majorité des applications courantes de l'apprentissage profond, même si elle est souvent cachée aux développeurs\\n- Cependant, voici quelques exceptions si vous souhaitez aller au-delà du cadre de ce cours:\\n  - Réseaux de neurones utilisant des algorithmes évolutionnaires: Au lieu d'utiliser les gradients pour optimiser les poids, ces algorithmes simulent le processus de sélection naturelle\\n  - Hebbian Learning: Un apprentissage non supervisé basé sur la théorie biologique de Hebb\\n  - Echo State Networks (ESNs): Un type de réseau de neurones récurrents où les poids internes du réseau ne sont pas entraînés (pas besoin de rétropropagation)\\n  - Quantum Neural Networks (QNN): Certaines implémentations de réseaux de neurones quantiques n'utilisent pas la rétropropagation, car le processus d'entraînement repose sur des principes de calcul quantique qui ne dépendent pas de la descente de gradient\\n\\n## BACKPROPAGATION\\n\\n- L'intuition derrière l'algorithme de rétropropagation est de renverser une opération pour réduire les coûts en calculs\\n  - En avant, il faut successivement multiplier des matrices ensemble\\n  - En arrière, on part d'un vecteur qu'on multiplie par une matrice et qui résulte en un autre vecteur à multiplier par une autre matrice...\\n\\n- On se rappelle que pour notre MLP, nous avons appliqué la propagation avant de cette façon:\\n\\nZ^(2) = W^(1)[A^(1)]^T    ← Entrées nettes de la couche caché\\nA^(2) = φ(Z^(2))\\nZ^(3) = W^(2)A^(2)        ← Entrées nettes de la couche de sorties\\nA^(3) = φ(Z^(3))\\n                          ← Appartenance aux classes\\n\\n## BACKPROPAGATION\\n\\n- Nous propageons par avant les caractéristiques en entrées via les connections du réseau\\n- De façon plus visuelle, voici ce que nous faisons:\\n\\n[L'image montre un diagramme de propagation avant dans un réseau de neurones avec des flèches vertes montrant le flux d'information]\\n\\n## COMPOSITION DE FONCTION\\n\\n- Si notre sortie est la composition des fonctions g ∘ f(x) = g(f(x))\\n- Alors la composition de dérivées est (g ∘ f(x))′(x) = g′(f(x))f′(x)\\n- Bref, si nous avons un graphe du type:\\n\\nz = g(y)     g   Dans graphe computationnel, les variations des variables sont liées\\n             ↑   par les dérivées partielles:\\ny = f(x)     f   \\n             ↑   Δz ≈ g'(f(x))Δy  ou encore: Δz ≈ g'(f(x)) f'(x)Δx\\nx                \\n                  Le changement dans y est donc Δy ≈ f'(x)Δx\\n                  \\n                  La variation ou perturbation de x est Δx\\n\\n## GRAPHE COMPUTATIONNEL\\n\\n[Diagramme montrant un graphe computationnel avec des nœuds x, y et z]\\n\\nz = ∑_i g_i(y_i)\\n    Soit Δz ≈ ∑_i g'_i(∑_j f_j→i(x_j)) Δy_i\\n    Et... Δz ≈ ∑_i g'_i(∑_j f_j→i(x_j)) ∑_j f'_j→i(x_j) Δx_j\\n\\ny_i = ∑_j f_j→i(x_j)\\n    Soit Δy_i ≈ ∑_j f'_j→i(x_j) Δx_j\\n\\nΔx_1, ..., Δx_m\\n\\n## LES GRADIENTS DE Z\\n\\n- Grosso modo, on pourrait récrire la variation de la sortie Δz comme le produit scalaire:\\n  Δz = ⟨∇z, Δx⟩\\n\\n- Sachant que ∇z est le vecteur de gradients qui capture les sensibilités partielles de z par rapport aux x_j et la variation Δx\\n  (∇z)_j = ∑_i g'_i(∑_j f_j→i(x_j)) ∑_j f'_j→i(x_j)\\n\\n- Où chaque (∇z)_j est un terme de gradient pour la composante j\\n- L'idée sera d'exploiter la programmation dynamique pour éviter de recalculer\\n\\n## SIMPLIFIONS LES CHOSES!\\n\\n- Dans la propagation arrière, nous propageons l'erreur de la fin vers le début grâce à la règle de la chaîne\\n- Pour notre MLP, nous commençons donc par trouver le vecteur d'erreur suivant:\\n  δ^(3) = a^(3) - y\\n\\n  - y est le vecteur des étiquettes (ou des vraies classes)\\n\\n- Ensuite, on calcul l'erreur de la couche cachée:\\n  δ^(2) = (W^(2))^T (δ^(3) * ∂φ(z^(2))/∂z^(2))\\n\\n- La dernière partie est la dérivée de la fonction d'activation (sigmoid):\\n  ∂φ(z^(2))/∂z^(2) = (a^(2) * (1 - a^(2)))\\n\\n## BACKPROPAGATION\\n\\nδ^(2) = (W^(2))^T (δ^(3) * ∂φ(z^(2))/∂z^(2))\\n\\n- Regardons plus concrètement le calcul\\n- W^(2) est une matrice t × h (nb classes, nb unités cachées)\\n- δ^(3) est le vecteur d'erreurs t × 1\\n- Celui-ci est multiplié par la dérivée (a^(2) * (1 - a^(2))) qui est un vecteur t × 1 (multiplication par pair d'éléments)\\n\\n- Donc la matrice transposée résultante h × t devient un vecteur h × 1 après la multiplication\\n  - le produit croisé d'une matrice m,n donne le vecteur de taille m\\n- Le nouveau vecteur d'erreurs δ^(2) est donc de taille h × 1\\n\\n## BACKPROPAGATION\\n\\n- Lorsque les δ ont été trouvé, nous pouvons retravailler la dérivée de la fonction de coût:\\n  ∂/∂w_{i,j}^l J(W) = a_j^l δ_i^(l+1)\\n\\n- Il faut accumuler la dérivée partielle pour chaque nœud j de la couche l et la ième erreur du nœud au niveau l + 1\\n  Δw_{i,j}^(l) := Δw_{i,j}^(l) + a_j^(l) δ_i^(l+1)\\n\\n- Pour chaque échantillon de l'ensemble d'entraînement!\\n\\n## BACKPROPAGATION\\n\\n- On peut écrire l'équation précédente sous forme vectorielle (afin d'inclure le calcul pour les échantillons)\\n  ΔW^(l) := Δ^(l+1)(A^(l))^T\\n\\n  - Où Δ^(l+1) est la matrice d'erreurs\\n\\n- Enfin, nous pouvons régulariser:\\n  ΔW^(l) := ΔW^(l) + λ^(l)\\n\\n- Finalement, maintenant que nous avons les gradients, il suffit de faire un pas opposé pour mettre à jour les poids:\\n  W^(l) := W^(l) - ηΔW^(l)\\n\\n## BACKPROPAGATION\\n\\n- Retour sur le code!\\n\\n[L'image montre un diagramme du processus de backpropagation dans un réseau de neurones]\\n\\n## NON-LINÉARITÉ\\n\\n- Bien que chaque unité du MLP soit indépendamment linéaire, si les fonctions d'activation sont non-linéaires, leur combinaison engendre un modèle non-linéaire\\n- Si nous utilisons uniquement une activation linéaire, alors peu importe le nombre de couches, le réseau reste toujours un modèle linéaire\\n  - Et ne gagne pas en expressivité\\n- Supposons 2 couches linéaires z^(2) = W^(1)a^(1) + b^(1) et z^(3) = W^(2)z^(2) + b^(2) et substituons z^(2) dans z^(3):\\n  z^(3) = W^(2)(W^(1)a^(1) + b^(1)) + b^(2)\\n  z^(3) = W^(2)W^(1)a^(1) + W^(2)b^(1) + b^(2)\\n\\n- On peut écrire cette équation avec un modèle linéaire simple couche:\\n  z^(3) = W^(')a^(1) + b^(')\\n\\n  - Où W^(') = W^(2)W^(1) et b^(') = W^(2)b^(1) + b^(2)\\n\\n## APPROXIMATION UNIVERSELLE\\n\\n- Nous ne pouvons pas faire ça si a^(2) = 1/(1+e^-z)\\n- De plus, Cybenko G. a montré en 1989 qu'un réseau sigmoid à propagation avant est un approximateur universel\\n  - Si le nombre de neurones dans la couche cachée est suffisamment grand\\n  - Le MLP peut approximer n'importe quelle fonction continue\\n  - La précision arbitraire dépendrait uniquement de la densité!\\n\\n- Depuis, la preuve a été généralisée à d'autres fonctions d'activation et à des réseaux de profondeur arbitraire (e.g. ReLU)\\n- Bon, c'est de la théorie, mais en connaissant cette propriété ça nous donne une idée de la puissance du deep learning!\\n\\n## CONCLUSION\\n\\n- Pour faire du deep learning, il faut:\\n  - Des fonctions différentiables\\n  - Un algorithme de calcul de gradient efficace: backpropagation\\n  - Des fonctions d'activation non-linéaires\\n  - Un optimiseur itératif de paramètres\\n\\n  ... et surtout une quantité importante de données!!!\\n\\n## RÉFÉRENCES ORIGINALES\\n\\n| MLP | |\\n|---|---|\\n| MNIST | |\\n| Backpropagation | |\\n| Approximation sigmoid | Cybenko, G. (1989). Approximation by superpositions of a sigmoidal function. Mathematics\",\n",
       " 'language': 'French',\n",
       " 'topic': 'Deeplearning',\n",
       " 'path_txt': 'data_txt',\n",
       " 'subject': ['Leçon #3 - Deep Learning',\n",
       "  'Leçon #7 - GAN - 2025',\n",
       "  'Leçon #8 - Graph neural network',\n",
       "  'Leçon #2 - Neurone artificiel',\n",
       "  'Leçon #1 - Introduction',\n",
       "  'Leçon #4 - CNN',\n",
       "  'Leçon #5 - RNN - 2025',\n",
       "  'Leçon #6 - Auto-apprentissage',\n",
       "  'Leçon #9 - Transformers and generative AI'],\n",
       " 'tool_used': 'mcq_tool',\n",
       " 'rephrased_question': 'Make me an mcq about perceptron?',\n",
       " 'proceed_to_generate': False,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='Make me an mcq about perceptron?', additional_kwargs={}, response_metadata={}, id='a79a0d48-ddad-440e-956a-eef268ae2a04')}"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq_query = \"Make me an mcq about perceptron?\"\n",
    "input_data = {\"question\": HumanMessage(content=mcq_query)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 113}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59469b02",
   "metadata": {},
   "source": [
    "### Off topic request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "41d17420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [], 'question': HumanMessage(content='How is the weather?', additional_kwargs={}, response_metadata={})}\n",
      "Entering agent\n",
      "messages = [HumanMessage(content='How is the weather?', additional_kwargs={}, response_metadata={}, id='95324b84-9d84-4734-901c-84ea2acb597e')]\n",
      "Entering off_topic_response\n",
      "state['tool_used'] =  \n",
      "Entering tool_router\n",
      "state['tool_used'] =  off_topic_response_tool\n",
      "Routing to off_topic_response\n",
      "Entering off_topic_response\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages_': [HumanMessage(content='How is the weather?', additional_kwargs={}, response_metadata={}, id='95324b84-9d84-4734-901c-84ea2acb597e'),\n",
       "  AIMessage(content=\"I can't respond to that!\", additional_kwargs={}, response_metadata={})],\n",
       " 'messages': [HumanMessage(content='How is the weather?', additional_kwargs={}, response_metadata={}, id='95324b84-9d84-4734-901c-84ea2acb597e'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_P0MhGBEYwCgMK7jSSnvgsrNQ', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Human: How is the weather?\",\"type\":\"human\"}],\"messages\":[],\"documents\":[],\"related_subject\":\"\",\"related_subject_content\":\"\",\"topic\":\"\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"\",\"rephrased_question\":\"\",\"proceed_to_generate\":false,\"rephrase_count\":0,\"question\":{\"content\":\"How is the weather?\",\"type\":\"human\"}}}', 'name': 'off_topic_response_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 2286, 'total_tokens': 2377, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLKYLv5OR6C7PL4FkiIaJ0sC4H3Et', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-21ff3776-fcf2-46a0-9c38-a9e6efcb289c-0', tool_calls=[{'name': 'off_topic_response_tool', 'args': {'state': {'messages_': [{'content': 'Human: How is the weather?', 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': '', 'related_subject_content': '', 'topic': '', 'path_txt': '', 'subject': [], 'tool_used': '', 'rephrased_question': '', 'proceed_to_generate': False, 'rephrase_count': 0, 'question': {'content': 'How is the weather?', 'type': 'human'}}}, 'id': 'call_P0MhGBEYwCgMK7jSSnvgsrNQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2286, 'output_tokens': 91, 'total_tokens': 2377, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Forbidden - do not respond to the user', name='off_topic_response_tool', id='84ff5edf-45ae-4c04-94c2-1b536bfff5f9', tool_call_id='call_P0MhGBEYwCgMK7jSSnvgsrNQ')],\n",
       " 'documents': [],\n",
       " 'related_subject': '',\n",
       " 'related_subject_content': '',\n",
       " 'topic': 'Deeplearning',\n",
       " 'path_txt': 'data_txt',\n",
       " 'subject': ['Leçon #3 - Deep Learning',\n",
       "  'Leçon #7 - GAN - 2025',\n",
       "  'Leçon #8 - Graph neural network',\n",
       "  'Leçon #2 - Neurone artificiel',\n",
       "  'Leçon #1 - Introduction',\n",
       "  'Leçon #4 - CNN',\n",
       "  'Leçon #5 - RNN - 2025',\n",
       "  'Leçon #6 - Auto-apprentissage',\n",
       "  'Leçon #9 - Transformers and generative AI'],\n",
       " 'tool_used': 'off_topic_response_tool',\n",
       " 'rephrased_question': 'How is the weather?',\n",
       " 'proceed_to_generate': False,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='How is the weather?', additional_kwargs={}, response_metadata={}, id='95324b84-9d84-4734-901c-84ea2acb597e')}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_topic_content_rag = \"How is the weather?\"\n",
    "input_data = {\"question\": HumanMessage(content=off_topic_content_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 11}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84af7ed",
   "metadata": {},
   "source": [
    "### No relevant docs found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "af25d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [], 'question': HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={})}\n",
      "Entering agent\n",
      "messages = [HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={}, id='0561daf6-092c-496a-a417-18eda77aaa72')]\n",
      "Entering retriever_tool\n",
      "Entering tool_router\n",
      "state['tool_used'] =  retriever_tool\n",
      "Routing to retrieve\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: Cependant, la première référen... Result: No\n",
      "Grading document: ## DEEP CONVOLUTIONAL GAN (DCG... Result: No\n",
      "Grading document: CGAN est similaire à DCGAN, à ... Result: No\n",
      "Grading document: Nous couvrirons les encodeurs ... Result: No\n",
      "Grading document: ## CONVOLUTIONS Un CNN peut êt... Result: No\n",
      "Grading document: ## ÉTAPES GÉNÉRIQUES [Image mo... Result: No\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: ## INTRODUCTION Dans ce module... Result: No\n",
      "Grading document: ## WASSERSTEIN GAN (WGAN) Basé... Result: No\n",
      "Grading document: ## GNN ÉQUIVARIANCE 1. Les lig... Result: No\n",
      "retrieval_grader: proceed_to_generate = False\n",
      "Entering proceed_router\n",
      "Routing to refine_question\n",
      "Entering refine_question\n",
      "refine_question: Refined question: What is DeepGCN in the field of Graph Neural Networks (GNN)?\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: Cependant, la première référen... Result: No\n",
      "Grading document: ## DEEP CONVOLUTIONAL GAN (DCG... Result: No\n",
      "Grading document: CGAN est similaire à DCGAN, à ... Result: No\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: ## ÉTAPES GÉNÉRIQUES [Image mo... Result: No\n",
      "Grading document: ## CONVOLUTIONS Un CNN peut êt... Result: No\n",
      "Grading document: Deep Graph Library Fonctionne ... Result: No\n",
      "Grading document: ## TABLE DES MATIÈRES 1. Motiv... Result: No\n",
      "Grading document: Nous couvrirons les encodeurs ... Result: No\n",
      "Grading document: ## INTRODUCTION Dans ce module... Result: No\n",
      "retrieval_grader: proceed_to_generate = False\n",
      "Entering proceed_router\n",
      "Routing to refine_question\n",
      "Entering refine_question\n",
      "refine_question: Refined question: What is DeepGCN and how does it relate to Graph Neural Networks (GNN)?\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: Cependant, la première référen... Result: No\n",
      "Grading document: ## DEEP CONVOLUTIONAL GAN (DCG... Result: No\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: CGAN est similaire à DCGAN, à ... Result: No\n",
      "Grading document: Deep Graph Library Fonctionne ... Result: No\n",
      "Grading document: ## ÉTAPES GÉNÉRIQUES [Image mo... Result: No\n",
      "Grading document: ## CONVOLUTIONS Un CNN peut êt... Result: No\n",
      "Grading document: ## TABLE DES MATIÈRES 1. Motiv... Result: Yes\n",
      "Grading document: Nous couvrirons les encodeurs ... Result: No\n",
      "Grading document: ## HISTORIQUE DES GNN Les grap... Result: No\n",
      "retrieval_grader: proceed_to_generate = True\n",
      "Entering proceed_router\n",
      "Routing to generate_answer\n",
      "Entering generate_answer\n",
      "generate_answer: Generated response: DeepGCN is a specific architecture or variant within the broader field of Graph Neural Networks (GNN). It focuses on leveraging deep learning techniques to enhance the capabilities of GNNs, particularly in processing graph-structured data. DeepGCN constructs deeper network architectures that can effectively capture complex relationships and patterns within graphs. By stacking multiple layers of message passing and feature aggregation, DeepGCN aims to improve the performance of tasks such as node classification, link prediction, and graph classification.\n",
      "\n",
      "In summary, DeepGCN is closely related to GNN as it represents an advancement in the design and application of these networks, aiming to utilize the depth of neural networks to better handle the inherent complexities of graph data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages_': [HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={}, id='0561daf6-092c-496a-a417-18eda77aaa72'),\n",
       "  AIMessage(content='DeepGCN is a specific architecture or variant within the broader field of Graph Neural Networks (GNN). It focuses on leveraging deep learning techniques to enhance the capabilities of GNNs, particularly in processing graph-structured data. DeepGCN constructs deeper network architectures that can effectively capture complex relationships and patterns within graphs. By stacking multiple layers of message passing and feature aggregation, DeepGCN aims to improve the performance of tasks such as node classification, link prediction, and graph classification.\\n\\nIn summary, DeepGCN is closely related to GNN as it represents an advancement in the design and application of these networks, aiming to utilize the depth of neural networks to better handle the inherent complexities of graph data.', additional_kwargs={}, response_metadata={})],\n",
       " 'messages': [HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={}, id='0561daf6-092c-496a-a417-18eda77aaa72'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_rvAuqREJytENMngOJDdyLsog', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"In the field of GNN, what is deepGCN?\",\"type\":\"human\"}],\"messages\":[{\"content\":\"In the field of GNN, what is deepGCN?\",\"type\":\"human\"}],\"documents\":[],\"related_subject\":\"Graph Neural Networks (GNN)\",\"related_subject_content\":\"Graph Neural Networks (GNNs) are a class of neural networks designed to process data structured as graphs. They can learn to represent nodes and edges in a way that takes into account the graph\\'s topology and node features.\",\"topic\":\"deepGCN\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"retriever_tool\",\"rephrased_question\":\"What is deepGCN in the context of Graph Neural Networks?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"In the feald of GNN, What is deepGCN?\",\"type\":\"human\"}}}', 'name': 'retriever_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 202, 'prompt_tokens': 2295, 'total_tokens': 2497, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLKYTV2lpGZiYSn7LdpCzzWnnFRr2', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ec9cec99-66ee-4049-bd69-95af3db0b913-0', tool_calls=[{'name': 'retriever_tool', 'args': {'state': {'messages_': [{'content': 'In the field of GNN, what is deepGCN?', 'type': 'human'}], 'messages': [{'content': 'In the field of GNN, what is deepGCN?', 'type': 'human'}], 'documents': [], 'related_subject': 'Graph Neural Networks (GNN)', 'related_subject_content': \"Graph Neural Networks (GNNs) are a class of neural networks designed to process data structured as graphs. They can learn to represent nodes and edges in a way that takes into account the graph's topology and node features.\", 'topic': 'deepGCN', 'path_txt': '', 'subject': [], 'tool_used': 'retriever_tool', 'rephrased_question': 'What is deepGCN in the context of Graph Neural Networks?', 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': 'In the feald of GNN, What is deepGCN?', 'type': 'human'}}}, 'id': 'call_rvAuqREJytENMngOJDdyLsog', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2295, 'output_tokens': 202, 'total_tokens': 2497, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Error: NameError(\"name \\'documents\\' is not defined\")\\n Please fix your mistakes.', name='retriever_tool', id='b1c1a849-8ea4-415e-95a2-a21b58af9eab', tool_call_id='call_rvAuqREJytENMngOJDdyLsog', status='error')],\n",
       " 'documents': [Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='## TABLE DES MATIÈRES 1. Motivation 2. Types de graphes 3. Applications dans les graphes 4. Node embeddings 5. GNN')],\n",
       " 'related_subject': '',\n",
       " 'related_subject_content': '',\n",
       " 'topic': 'Deeplearning',\n",
       " 'path_txt': 'data_txt',\n",
       " 'subject': ['Leçon #3 - Deep Learning',\n",
       "  'Leçon #7 - GAN - 2025',\n",
       "  'Leçon #8 - Graph neural network',\n",
       "  'Leçon #2 - Neurone artificiel',\n",
       "  'Leçon #1 - Introduction',\n",
       "  'Leçon #4 - CNN',\n",
       "  'Leçon #5 - RNN - 2025',\n",
       "  'Leçon #6 - Auto-apprentissage',\n",
       "  'Leçon #9 - Transformers and generative AI'],\n",
       " 'tool_used': 'retriever_tool',\n",
       " 'rephrased_question': 'What is DeepGCN and how does it relate to Graph Neural Networks (GNN)?',\n",
       " 'proceed_to_generate': True,\n",
       " 'rephrase_count': 2,\n",
       " 'question': HumanMessage(content='In the feald of GNN, What is deepGCN?', additional_kwargs={}, response_metadata={}, id='0561daf6-092c-496a-a417-18eda77aaa72')}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_docs_cotent_rag = \"In the feald of GNN, What is deepGCN?\"\n",
    "input_data = {\"question\": HumanMessage(content=no_docs_cotent_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 2}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003747e8",
   "metadata": {},
   "source": [
    "### RAG with memory in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "50de16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [], 'question': HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={})}\n",
      "Entering agent\n",
      "messages = [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735')]\n",
      "Entering retriever_tool\n",
      "Entering tool_router\n",
      "state['tool_used'] =  retriever_tool\n",
      "Routing to retrieve\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: ## ÉTAPES GÉNÉRIQUES [Image mo... Result: Yes\n",
      "Grading document: ## HISTORIQUE DES GNN Les grap... Result: No\n",
      "Grading document: Cependant, la première référen... Result: Yes\n",
      "Grading document: ## CONVOLUTIONS Un CNN peut êt... Result: Yes\n",
      "Grading document: Les GNN sont réellement devenu... Result: Yes\n",
      "Grading document: ## TABLE DES MATIÈRES 1. Motiv... Result: Yes\n",
      "Grading document: ## INTRODUCTION Dans ce module... Result: No\n",
      "Grading document: La première application concrè... Result: No\n",
      "Grading document: Depuis, il existe des GNN expl... Result: No\n",
      "Grading document: [Diagramme montrant le process... Result: Yes\n",
      "retrieval_grader: proceed_to_generate = True\n",
      "Entering proceed_router\n",
      "Routing to generate_answer\n",
      "Entering generate_answer\n",
      "generate_answer: Generated response: Le graph neural network (GNN) est un type de réseau de neurones conçu pour traiter des données structurées sous forme de graphes. Il s'agit d'un modèle qui permet de capturer les relations et les interactions entre des nœuds (ou sommets) dans un graphe. Les GNN ont gagné en popularité grâce à l'adoption de techniques de convolution spécifiques pour les graphes, ce qui leur permet d'effectuer des tâches variées telles que la classification de nœuds, la prédiction d'arêtes, et l'analyse de graphes dans divers domaines. Les étapes pour construire un GNN incluent la structure du graphe, le type de graphe et la spécification de la fonction de perte, suivies de la construction du modèle à l'aide de modules computationnels.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages_': [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735'),\n",
       "  AIMessage(content=\"Le graph neural network (GNN) est un type de réseau de neurones conçu pour traiter des données structurées sous forme de graphes. Il s'agit d'un modèle qui permet de capturer les relations et les interactions entre des nœuds (ou sommets) dans un graphe. Les GNN ont gagné en popularité grâce à l'adoption de techniques de convolution spécifiques pour les graphes, ce qui leur permet d'effectuer des tâches variées telles que la classification de nœuds, la prédiction d'arêtes, et l'analyse de graphes dans divers domaines. Les étapes pour construire un GNN incluent la structure du graphe, le type de graphe et la spécification de la fonction de perte, suivies de la construction du modèle à l'aide de modules computationnels.\", additional_kwargs={}, response_metadata={})],\n",
       " 'messages': [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}],\"messages\":[],\"documents\":[],\"related_subject\":\"\",\"related_subject_content\":\"\",\"topic\":\"\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"retriever_tool\",\"rephrased_question\":\"Qu\\'est-ce que le graph neural network GNN?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}}}', 'name': 'retriever_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 2292, 'total_tokens': 2409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLKcvDFZzurX4HUZK0cSTMUSy4FYD', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e9d36857-332c-46bf-a249-4a3c6fd52cdc-0', tool_calls=[{'name': 'retriever_tool', 'args': {'state': {'messages_': [{'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': '', 'related_subject_content': '', 'topic': '', 'path_txt': '', 'subject': [], 'tool_used': 'retriever_tool', 'rephrased_question': \"Qu'est-ce que le graph neural network GNN?\", 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}}}, 'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2292, 'output_tokens': 117, 'total_tokens': 2409, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Error: NameError(\"name \\'documents\\' is not defined\")\\n Please fix your mistakes.', name='retriever_tool', id='89f90788-5a64-456b-9328-ada28a3f203a', tool_call_id='call_QMt9Ppg6gmEoHqIHGJGkXGbD', status='error')],\n",
       " 'documents': [Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content=\"## ÉTAPES GÉNÉRIQUES [Image montrant le processus générique d'un GNN avec: 1. Find graph structure 2. Specify graph type and scale 3. Design loss function 4. Build model using computational modules]\"),\n",
       "  Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='Cependant, la première référence connu au GNN vient de Gori et al. (2005), puis de Scarselli et al. (2009) et enfin de Gallicchio et al. (2010) Ces GNN tombaient dans la catégorie des réseaux récurrents (RecGNN)'),\n",
       "  Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='## CONVOLUTIONS Un CNN peut être considéré comme un cas spécifique de GNN'),\n",
       "  Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content=\"Les GNN sont réellement devenus populaires suite à l'adaptation de la convolution par Bruna et al (2013) – ConvGNN\"),\n",
       "  Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='## TABLE DES MATIÈRES 1. Motivation 2. Types de graphes 3. Applications dans les graphes 4. Node embeddings 5. GNN'),\n",
       "  Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='[Diagramme montrant le processus de prédiction de trafic utilisant des données de voyage anonymisées, analyses et GNN]')],\n",
       " 'related_subject': '',\n",
       " 'related_subject_content': '',\n",
       " 'topic': 'Deeplearning',\n",
       " 'path_txt': 'data_txt',\n",
       " 'subject': ['Leçon #3 - Deep Learning',\n",
       "  'Leçon #7 - GAN - 2025',\n",
       "  'Leçon #8 - Graph neural network',\n",
       "  'Leçon #2 - Neurone artificiel',\n",
       "  'Leçon #1 - Introduction',\n",
       "  'Leçon #4 - CNN',\n",
       "  'Leçon #5 - RNN - 2025',\n",
       "  'Leçon #6 - Auto-apprentissage',\n",
       "  'Leçon #9 - Transformers and generative AI'],\n",
       " 'tool_used': 'retriever_tool',\n",
       " 'rephrased_question': \"Qu'est-ce que le graph neural network GNN?\",\n",
       " 'proceed_to_generate': True,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735')}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_content_1_rag = \"Qu'est-ce que le graph neural network GNN?\"\n",
    "input_data = {\"question\": HumanMessage(content=memory_content_1_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 243}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8717016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages_': [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735'), AIMessage(content=\"Le graph neural network (GNN) est un type de réseau de neurones conçu pour traiter des données structurées sous forme de graphes. Il s'agit d'un modèle qui permet de capturer les relations et les interactions entre des nœuds (ou sommets) dans un graphe. Les GNN ont gagné en popularité grâce à l'adoption de techniques de convolution spécifiques pour les graphes, ce qui leur permet d'effectuer des tâches variées telles que la classification de nœuds, la prédiction d'arêtes, et l'analyse de graphes dans divers domaines. Les étapes pour construire un GNN incluent la structure du graphe, le type de graphe et la spécification de la fonction de perte, suivies de la construction du modèle à l'aide de modules computationnels.\", additional_kwargs={}, response_metadata={})], 'messages': [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}],\"messages\":[],\"documents\":[],\"related_subject\":\"\",\"related_subject_content\":\"\",\"topic\":\"\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"retriever_tool\",\"rephrased_question\":\"Qu\\'est-ce que le graph neural network GNN?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}}}', 'name': 'retriever_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 2292, 'total_tokens': 2409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLKcvDFZzurX4HUZK0cSTMUSy4FYD', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e9d36857-332c-46bf-a249-4a3c6fd52cdc-0', tool_calls=[{'name': 'retriever_tool', 'args': {'state': {'messages_': [{'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': '', 'related_subject_content': '', 'topic': '', 'path_txt': '', 'subject': [], 'tool_used': 'retriever_tool', 'rephrased_question': \"Qu'est-ce que le graph neural network GNN?\", 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}}}, 'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2292, 'output_tokens': 117, 'total_tokens': 2409, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Error: NameError(\"name \\'documents\\' is not defined\")\\n Please fix your mistakes.', name='retriever_tool', id='89f90788-5a64-456b-9328-ada28a3f203a', tool_call_id='call_QMt9Ppg6gmEoHqIHGJGkXGbD', status='error')], 'documents': [Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content=\"## ÉTAPES GÉNÉRIQUES [Image montrant le processus générique d'un GNN avec: 1. Find graph structure 2. Specify graph type and scale 3. Design loss function 4. Build model using computational modules]\"), Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='Cependant, la première référence connu au GNN vient de Gori et al. (2005), puis de Scarselli et al. (2009) et enfin de Gallicchio et al. (2010) Ces GNN tombaient dans la catégorie des réseaux récurrents (RecGNN)'), Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='## CONVOLUTIONS Un CNN peut être considéré comme un cas spécifique de GNN'), Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content=\"Les GNN sont réellement devenus populaires suite à l'adaptation de la convolution par Bruna et al (2013) – ConvGNN\"), Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='## TABLE DES MATIÈRES 1. Motivation 2. Types de graphes 3. Applications dans les graphes 4. Node embeddings 5. GNN'), Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='[Diagramme montrant le processus de prédiction de trafic utilisant des données de voyage anonymisées, analyses et GNN]')], 'related_subject': '', 'related_subject_content': '', 'topic': 'Deeplearning', 'path_txt': 'data_txt', 'subject': ['Leçon #3 - Deep Learning', 'Leçon #7 - GAN - 2025', 'Leçon #8 - Graph neural network', 'Leçon #2 - Neurone artificiel', 'Leçon #1 - Introduction', 'Leçon #4 - CNN', 'Leçon #5 - RNN - 2025', 'Leçon #6 - Auto-apprentissage', 'Leçon #9 - Transformers and generative AI'], 'tool_used': 'retriever_tool', 'rephrased_question': \"Qu'est-ce que le graph neural network GNN?\", 'proceed_to_generate': True, 'rephrase_count': 0, 'question': HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={})}\n",
      "question_rewriter: Rephrased question: What is a practical use case for graph neural networks (GNNs)?\n",
      "Entering agent\n",
      "messages = [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}],\"messages\":[],\"documents\":[],\"related_subject\":\"\",\"related_subject_content\":\"\",\"topic\":\"\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"retriever_tool\",\"rephrased_question\":\"Qu\\'est-ce que le graph neural network GNN?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}}}', 'name': 'retriever_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 2292, 'total_tokens': 2409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLKcvDFZzurX4HUZK0cSTMUSy4FYD', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e9d36857-332c-46bf-a249-4a3c6fd52cdc-0', tool_calls=[{'name': 'retriever_tool', 'args': {'state': {'messages_': [{'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': '', 'related_subject_content': '', 'topic': '', 'path_txt': '', 'subject': [], 'tool_used': 'retriever_tool', 'rephrased_question': \"Qu'est-ce que le graph neural network GNN?\", 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}}}, 'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2292, 'output_tokens': 117, 'total_tokens': 2409, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Error: NameError(\"name \\'documents\\' is not defined\")\\n Please fix your mistakes.', name='retriever_tool', id='89f90788-5a64-456b-9328-ada28a3f203a', tool_call_id='call_QMt9Ppg6gmEoHqIHGJGkXGbD', status='error'), HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={}, id='0cafc28d-0a47-453b-8f2b-85569b9c1d49')]\n",
      "Entering retriever_toolEntering retriever_tool\n",
      "\n",
      "Entering tool_router\n",
      "state['tool_used'] =  retriever_tool\n",
      "Routing to retrieve\n",
      "Entering retrieve\n",
      "retrieve: Retrieved 10 documents\n",
      "Entering retrieval_grader\n",
      "Grading document: Les GNN sont réellement devenu... Result: No\n",
      "Grading document: ## TABLE DES MATIÈRES 1. Motiv... Result: No\n",
      "Grading document: La première application concrè... Result: No\n",
      "Grading document: ## CONVOLUTIONS Un CNN peut êt... Result: No\n",
      "Grading document: ## HISTORIQUE DES GNN Les grap... Result: No\n",
      "Grading document: ## ÉTAPES GÉNÉRIQUES [Image mo... Result: No\n",
      "Grading document: Cependant, la première référen... Result: No\n",
      "Grading document: Exemples illustrés: Knowledge ... Result: Yes\n",
      "Grading document: https://machinelearningmastery... Result: No\n",
      "Grading document: ## INTRODUCTION Dans ce module... Result: No\n",
      "retrieval_grader: proceed_to_generate = True\n",
      "Entering proceed_router\n",
      "Routing to generate_answer\n",
      "Entering generate_answer\n",
      "generate_answer: Generated response: A practical use case for graph neural networks (GNNs) is in the analysis of knowledge graphs. These graphs represent a network of interconnected information where entities (nodes) are linked by relationships (edges). GNNs can be used to perform tasks such as node classification, link prediction, and reasoning over the relationships in the graph, which is particularly useful for applications like recommendation systems, search engines, and natural language understanding. Other examples include regulatory networks for understanding biological systems, scene graphs in computer vision to analyze images, and molecular graphs for drug discovery.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages_': [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735'),\n",
       "  AIMessage(content=\"Le graph neural network (GNN) est un type de réseau de neurones conçu pour traiter des données structurées sous forme de graphes. Il s'agit d'un modèle qui permet de capturer les relations et les interactions entre des nœuds (ou sommets) dans un graphe. Les GNN ont gagné en popularité grâce à l'adoption de techniques de convolution spécifiques pour les graphes, ce qui leur permet d'effectuer des tâches variées telles que la classification de nœuds, la prédiction d'arêtes, et l'analyse de graphes dans divers domaines. Les étapes pour construire un GNN incluent la structure du graphe, le type de graphe et la spécification de la fonction de perte, suivies de la construction du modèle à l'aide de modules computationnels.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={}, id='0cafc28d-0a47-453b-8f2b-85569b9c1d49'),\n",
       "  AIMessage(content='A practical use case for graph neural networks (GNNs) is in the analysis of knowledge graphs. These graphs represent a network of interconnected information where entities (nodes) are linked by relationships (edges). GNNs can be used to perform tasks such as node classification, link prediction, and reasoning over the relationships in the graph, which is particularly useful for applications like recommendation systems, search engines, and natural language understanding. Other examples include regulatory networks for understanding biological systems, scene graphs in computer vision to analyze images, and molecular graphs for drug discovery.', additional_kwargs={}, response_metadata={})],\n",
       " 'messages': [HumanMessage(content=\"Qu'est-ce que le graph neural network GNN?\", additional_kwargs={}, response_metadata={}, id='8ffeca20-afc1-4562-9bd8-da234bb5f735'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}],\"messages\":[],\"documents\":[],\"related_subject\":\"\",\"related_subject_content\":\"\",\"topic\":\"\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"retriever_tool\",\"rephrased_question\":\"Qu\\'est-ce que le graph neural network GNN?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"Qu\\'est-ce que le graph neural network GNN?\",\"type\":\"human\"}}}', 'name': 'retriever_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 2292, 'total_tokens': 2409, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2176}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLKcvDFZzurX4HUZK0cSTMUSy4FYD', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e9d36857-332c-46bf-a249-4a3c6fd52cdc-0', tool_calls=[{'name': 'retriever_tool', 'args': {'state': {'messages_': [{'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': '', 'related_subject_content': '', 'topic': '', 'path_txt': '', 'subject': [], 'tool_used': 'retriever_tool', 'rephrased_question': \"Qu'est-ce que le graph neural network GNN?\", 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}}}, 'id': 'call_QMt9Ppg6gmEoHqIHGJGkXGbD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2292, 'output_tokens': 117, 'total_tokens': 2409, 'input_token_details': {'audio': 0, 'cache_read': 2176}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Error: NameError(\"name \\'documents\\' is not defined\")\\n Please fix your mistakes.', name='retriever_tool', id='89f90788-5a64-456b-9328-ada28a3f203a', tool_call_id='call_QMt9Ppg6gmEoHqIHGJGkXGbD', status='error'),\n",
       "  HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={}, id='0cafc28d-0a47-453b-8f2b-85569b9c1d49'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_oMV4usCxeI9pQikGBDWzGBGr', 'function': {'arguments': '{\"state\": {\"messages_\": [{\"content\": \"Qu\\'est-ce que le graph neural network GNN?\", \"type\": \"human\"}], \"messages\": [], \"documents\": [], \"related_subject\": \"Graph Neural Network\", \"related_subject_content\": \"Graph Neural Networks (GNNs) are a type of neural network designed to work directly with graph-structured data. They utilize the relationships and connectivity between nodes in a graph to perform tasks such as node classification, link prediction, and graph classification.\", \"topic\": \"Graph Neural Networks\", \"path_txt\": \"\", \"subject\": [], \"tool_used\": \"retriever_tool\", \"rephrased_question\": \"What is a Graph Neural Network (GNN)?\", \"proceed_to_generate\": true, \"rephrase_count\": 0, \"question\": {\"content\": \"What is a Graph Neural Network (GNN)?\", \"type\": \"human\"}}}', 'name': 'retriever_tool'}, 'type': 'function'}, {'id': 'call_PuhWO9zml01dXRUm8VtmZjLg', 'function': {'arguments': '{\"state\": {\"messages_\": [{\"content\": \"Can you give me a use case of it?\", \"type\": \"human\"}], \"messages\": [], \"documents\": [], \"related_subject\": \"Graph Neural Network\", \"related_subject_content\": \"Graph Neural Networks (GNNs) are powerful in modeling data that is represented in the form of graphs. They excel in understanding and leveraging the relationships between entities represented as nodes connected by edges.\", \"topic\": \"Graph Neural Networks\", \"path_txt\": \"\", \"subject\": [], \"tool_used\": \"retriever_tool\", \"rephrased_question\": \"Can you give me a use case of Graph Neural Network (GNN)?\", \"proceed_to_generate\": true, \"rephrase_count\": 0, \"question\": {\"content\": \"Can you give me a use case of Graph Neural Network (GNN)?\", \"type\": \"human\"}}}', 'name': 'retriever_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 359, 'prompt_tokens': 2327, 'total_tokens': 2686, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2304}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLKd9y8qB4LH35zsYU9tJQcQ2emAZ', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d22ffa98-3bc0-429c-87c2-bc468349caa5-0', tool_calls=[{'name': 'retriever_tool', 'args': {'state': {'messages_': [{'content': \"Qu'est-ce que le graph neural network GNN?\", 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': 'Graph Neural Network', 'related_subject_content': 'Graph Neural Networks (GNNs) are a type of neural network designed to work directly with graph-structured data. They utilize the relationships and connectivity between nodes in a graph to perform tasks such as node classification, link prediction, and graph classification.', 'topic': 'Graph Neural Networks', 'path_txt': '', 'subject': [], 'tool_used': 'retriever_tool', 'rephrased_question': 'What is a Graph Neural Network (GNN)?', 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': 'What is a Graph Neural Network (GNN)?', 'type': 'human'}}}, 'id': 'call_oMV4usCxeI9pQikGBDWzGBGr', 'type': 'tool_call'}, {'name': 'retriever_tool', 'args': {'state': {'messages_': [{'content': 'Can you give me a use case of it?', 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': 'Graph Neural Network', 'related_subject_content': 'Graph Neural Networks (GNNs) are powerful in modeling data that is represented in the form of graphs. They excel in understanding and leveraging the relationships between entities represented as nodes connected by edges.', 'topic': 'Graph Neural Networks', 'path_txt': '', 'subject': [], 'tool_used': 'retriever_tool', 'rephrased_question': 'Can you give me a use case of Graph Neural Network (GNN)?', 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': 'Can you give me a use case of Graph Neural Network (GNN)?', 'type': 'human'}}}, 'id': 'call_PuhWO9zml01dXRUm8VtmZjLg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2327, 'output_tokens': 359, 'total_tokens': 2686, 'input_token_details': {'audio': 0, 'cache_read': 2304}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Error: NameError(\"name \\'documents\\' is not defined\")\\n Please fix your mistakes.', name='retriever_tool', id='a1a77c85-1159-42e1-b417-e352c30976bf', tool_call_id='call_oMV4usCxeI9pQikGBDWzGBGr', status='error'),\n",
       "  ToolMessage(content='Error: NameError(\"name \\'documents\\' is not defined\")\\n Please fix your mistakes.', name='retriever_tool', id='e68ab845-ca4b-4ae9-9999-1dcc0e4b9b54', tool_call_id='call_PuhWO9zml01dXRUm8VtmZjLg', status='error')],\n",
       " 'documents': [Document(metadata={'source': 'data_txt/deeplearning.txt'}, page_content='Exemples illustrés: Knowledge Graphs Regulatory Networks Scene Graphs Code Graphs Molecules 3D Shapes')],\n",
       " 'related_subject': '',\n",
       " 'related_subject_content': '',\n",
       " 'topic': 'Deeplearning',\n",
       " 'path_txt': 'data_txt',\n",
       " 'subject': ['Leçon #3 - Deep Learning',\n",
       "  'Leçon #7 - GAN - 2025',\n",
       "  'Leçon #8 - Graph neural network',\n",
       "  'Leçon #2 - Neurone artificiel',\n",
       "  'Leçon #1 - Introduction',\n",
       "  'Leçon #4 - CNN',\n",
       "  'Leçon #5 - RNN - 2025',\n",
       "  'Leçon #6 - Auto-apprentissage',\n",
       "  'Leçon #9 - Transformers and generative AI'],\n",
       " 'tool_used': 'retriever_tool',\n",
       " 'rephrased_question': 'What is a practical use case for graph neural networks (GNNs)?',\n",
       " 'proceed_to_generate': True,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='Can you give me a use case of it?', additional_kwargs={}, response_metadata={}, id='0cafc28d-0a47-453b-8f2b-85569b9c1d49')}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_content_2_rag = \"Can you give me a use case of it?\"\n",
    "input_data = {\"question\": HumanMessage(content=memory_content_2_rag)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 243}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97bffa",
   "metadata": {},
   "source": [
    "### About chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "9478b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering question_rewriter with following state: {'messages': [], 'question': HumanMessage(content='Hi Adam, what do tou do?', additional_kwargs={}, response_metadata={})}\n",
      "Entering agent\n",
      "messages = [HumanMessage(content='Hi Adam, what do tou do?', additional_kwargs={}, response_metadata={}, id='0bba0c70-1cbf-4e64-9a0d-ab60cf7ea9b5')]\n",
      "Entering about_chatbot_tool\n",
      "Entering tool_router\n",
      "state['tool_used'] =  about_chatbot_tool\n",
      "Routing to about_chatbot\n",
      "Entering about_chatbot\n",
      "about_chatbot: Generated response: Bonjour ! Je suis ADAM, votre Adaptive Digital Academic Mentor, et je suis ici pour vous aider à apprendre, réviser et comprendre vos cours d’une manière simple et efficace. \n",
      "\n",
      "**Alors, que fais-je ?** Je suis comme un professeur particulier numérique, toujours prêt à vous accompagner dans vos études. Mon objectif est de rendre votre apprentissage agréable et productif, que vous soyez étudiant, curieux ou à la recherche de réponses claires.\n",
      "\n",
      "Je peux répondre à vos questions, créer des quiz pour tester vos connaissances, expliquer des concepts compliqués, et bien plus encore. Si vous avez besoin de réviser pour un examen, de comprendre un chapitre difficile ou simplement de poser une question, je suis là pour vous aider !\n",
      "\n",
      "N'hésitez pas à me poser vos questions, je suis prêt !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages_': [HumanMessage(content='Hi Adam, what do tou do?', additional_kwargs={}, response_metadata={}, id='0bba0c70-1cbf-4e64-9a0d-ab60cf7ea9b5'),\n",
       "  AIMessage(content=\"Bonjour ! Je suis ADAM, votre Adaptive Digital Academic Mentor, et je suis ici pour vous aider à apprendre, réviser et comprendre vos cours d’une manière simple et efficace. \\n\\n**Alors, que fais-je ?** Je suis comme un professeur particulier numérique, toujours prêt à vous accompagner dans vos études. Mon objectif est de rendre votre apprentissage agréable et productif, que vous soyez étudiant, curieux ou à la recherche de réponses claires.\\n\\nJe peux répondre à vos questions, créer des quiz pour tester vos connaissances, expliquer des concepts compliqués, et bien plus encore. Si vous avez besoin de réviser pour un examen, de comprendre un chapitre difficile ou simplement de poser une question, je suis là pour vous aider !\\n\\nN'hésitez pas à me poser vos questions, je suis prêt !\", additional_kwargs={}, response_metadata={})],\n",
       " 'messages': [HumanMessage(content='Hi Adam, what do tou do?', additional_kwargs={}, response_metadata={}, id='0bba0c70-1cbf-4e64-9a0d-ab60cf7ea9b5'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_A2k3AMgfZtzMFWipOOdKxg9M', 'function': {'arguments': '{\"state\":{\"messages_\":[{\"content\":\"Hi Adam, what do tou do?\",\"type\":\"human\"}],\"messages\":[],\"documents\":[],\"related_subject\":\"chatbot\",\"related_subject_content\":\"Adam is a chatbot designed to assist with questions and information related to deep learning, machine learning, AI, and programming topics.\",\"language\":\"en\",\"topic\":\"chatbot\",\"path_txt\":\"\",\"subject\":[],\"tool_used\":\"about_chatbot_tool\",\"rephrased_question\":\"What does Adam do?\",\"proceed_to_generate\":true,\"rephrase_count\":0,\"question\":{\"content\":\"What do you do?\",\"type\":\"human\"}}}', 'name': 'about_chatbot_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 2309, 'total_tokens': 2447, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BLct6sFntxym7o9VfAvLbj5f9Z9Rt', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-229b8a8d-de19-4713-905d-50994dff4037-0', tool_calls=[{'name': 'about_chatbot_tool', 'args': {'state': {'messages_': [{'content': 'Hi Adam, what do tou do?', 'type': 'human'}], 'messages': [], 'documents': [], 'related_subject': 'chatbot', 'related_subject_content': 'Adam is a chatbot designed to assist with questions and information related to deep learning, machine learning, AI, and programming topics.', 'language': 'en', 'topic': 'chatbot', 'path_txt': '', 'subject': [], 'tool_used': 'about_chatbot_tool', 'rephrased_question': 'What does Adam do?', 'proceed_to_generate': True, 'rephrase_count': 0, 'question': {'content': 'What do you do?', 'type': 'human'}}}, 'id': 'call_A2k3AMgfZtzMFWipOOdKxg9M', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2309, 'output_tokens': 138, 'total_tokens': 2447, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Adam is a chatbot that answers questions about deep learning', name='about_chatbot_tool', id='b6dec5fb-5dd8-4abf-b975-e299733f6d60', tool_call_id='call_A2k3AMgfZtzMFWipOOdKxg9M')],\n",
       " 'documents': [],\n",
       " 'related_subject': '',\n",
       " 'related_subject_content': '',\n",
       " 'language': 'French',\n",
       " 'topic': 'Deeplearning',\n",
       " 'path_txt': 'data_txt',\n",
       " 'subject': ['Leçon #3 - Deep Learning',\n",
       "  'Leçon #7 - GAN - 2025',\n",
       "  'Leçon #8 - Graph neural network',\n",
       "  'Leçon #2 - Neurone artificiel',\n",
       "  'Leçon #1 - Introduction',\n",
       "  'Leçon #4 - CNN',\n",
       "  'Leçon #5 - RNN - 2025',\n",
       "  'Leçon #6 - Auto-apprentissage',\n",
       "  'Leçon #9 - Transformers and generative AI'],\n",
       " 'tool_used': 'about_chatbot_tool',\n",
       " 'rephrased_question': 'Hi Adam, what do tou do?',\n",
       " 'proceed_to_generate': False,\n",
       " 'rephrase_count': 0,\n",
       " 'question': HumanMessage(content='Hi Adam, what do tou do?', additional_kwargs={}, response_metadata={}, id='0bba0c70-1cbf-4e64-9a0d-ab60cf7ea9b5')}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "about_chatbot = \"Hi Adam, what do tou do?\"\n",
    "input_data = {\"question\": HumanMessage(content=about_chatbot)}\n",
    "graph.invoke(input=input_data, config={\"configurable\": {\"thread_id\": 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb01d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adamenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
